{"query": "LLM agent orchestration, tool use, reliability, evals, security", "work": {"openalex_id": "https://openalex.org/W4412877164", "openalex_id_short": "W4412877164", "title": "Evaluation and Benchmarking of LLM Agents: A Survey", "authors": ["Mahmoud Mohammadi", "Yipeng Li", "Jane Lo", "Wendy Yip"], "published": "2025-08-03", "abstract": "The rise of LLM-based agents has opened new frontiers in AI applications, yet evaluating these agents remains a complex and underdeveloped area. This survey provides an in-depth overview of the emerging field of LLM agent evaluation, introducing a two-dimensional taxonomy that organizes existing work along (1) evaluation objectives -- what to evaluate, such as agent behavior, capabilities, reliability, and safety -- and (2) evaluation process -- how to evaluate, including interaction modes, datasets and benchmarks, metric computation methods, and tooling. In addition to taxonomy, we highlight enterprise-specific challenges, such as role-based access to data, the need for reliability guarantees, dynamic and long-horizon interactions, and compliance, which are often overlooked in current research. We also identify future research directions, including holistic, more realistic, and scalable evaluation. This work aims to bring clarity to the fragmented landscape of agent evaluation and provide a framework for systematic assessment, enabling researchers and practitioners to evaluate LLM agents for real-world deployment.", "doi": "https://doi.org/10.1145/3711896.3736570", "journal": null, "cited_by_count": 5, "pdf_url": "https://dl.acm.org/doi/pdf/10.1145/3711896.3736570", "pdf_urls": ["https://dl.acm.org/doi/pdf/10.1145/3711896.3736570", "https://arxiv.org/pdf/2507.21504"], "landing_page_url": "https://doi.org/10.1145/3711896.3736570", "is_oa": true, "oa_status": "gold"}}
{"query": "LLM agent orchestration, tool use, reliability, evals, security", "work": {"openalex_id": "https://openalex.org/W4413380618", "openalex_id_short": "W4413380618", "title": "Artificial Intelligence Agent-Enabled Predictive Maintenance: Conceptual Proposal and Basic Framework", "authors": ["Wenyu Jiang", "Fuwen Hu"], "published": "2025-08-15", "abstract": "Predictive maintenance (PdM) represents a significant evolution in maintenance strategies. However, challenges such as system integration complexity, data quality, and data availability are intricately intertwined, collectively impacting the successful deployment of PdM systems. Recently, large model-based agents, or agentic artificial intelligence (AI), have evolved from simple task automation to active problem-solving and strategic decision-making. As such, we propose an AI agent-enabled PdM method that leverages an agentic AI development platform to streamline the development of a multimodal data-based fault detection agent, a RAG (retrieval-augmented generation)-based fault classification agent, a large model-based fault diagnosis agent, and a digital twin-based fault handling simulation agent. This approach breaks through the limitations of traditional PdM, which relies heavily on single models. This combination of “AI workflow + large reasoning models + operational knowledge base + digital twin” integrates the concepts of BaaS (backend as a service) and LLMOps (large language model operations), constructing an end-to-end intelligent closed loop from data perception to decision execution. Furthermore, a tentative prototype is demonstrated to show the technology stack and the system integration methods of the agentic AI-based PdM.", "doi": "https://doi.org/10.3390/computers14080329", "journal": "Computers", "cited_by_count": 4, "pdf_url": "https://www.mdpi.com/2073-431X/14/8/329/pdf?version=1755247301", "pdf_urls": ["https://www.mdpi.com/2073-431X/14/8/329/pdf?version=1755247301"], "landing_page_url": "https://doi.org/10.3390/computers14080329", "is_oa": true, "oa_status": "gold"}}
{"query": "LLM agent orchestration, tool use, reliability, evals, security", "work": {"openalex_id": "https://openalex.org/W4410304152", "openalex_id_short": "W4410304152", "title": "Factors Affecting Human–AI Collaboration Performances in Financial Sector: Sustainable Service Development Perspective", "authors": ["Chao Xu", "Sung Eui Cho"], "published": "2025-05-10", "abstract": "Recent advances in generative artificial intelligence (Gen AI) enable financial services firms to enhance operational efficiency and foster innovation through human–AI collaboration, yet also pose technical and managerial challenges. Drawing on collaboration theory and prior research, this study examines how employee skills, data reliability, trusted systems, and effective management jointly influence innovation capability and managerial performance in Gen AI-supported work environments. Through survey design, data were collected from China’s financial sector and analyzed using multiple regression analyses and fuzzy-set qualitative comparative analysis (fsQCA). The findings show that all four factors exert a positive influence on innovation capability and managerial performance, with innovation capability acting as a partial mediator. Complementarily, fsQCA identifies distinct configurations of these factors that lead to high levels of innovation capability and managerial performance. To fully leverage human–Gen AI collaboration, financial services firms should upskill employees, strengthen data reliability through robust governance, establish trusted AI systems, and effectively integrate Gen AI into workflows through strong managerial oversight. These findings provide actionable insights for talent development, data governance, and workflow optimization, ultimately enhancing firms’ resilience, adaptability, and long-term sustainability in financial services.", "doi": "https://doi.org/10.3390/su17104335", "journal": "Sustainability", "cited_by_count": 5, "pdf_url": "https://www.mdpi.com/2071-1050/17/10/4335/pdf?version=1746872948", "pdf_urls": ["https://www.mdpi.com/2071-1050/17/10/4335/pdf?version=1746872948"], "landing_page_url": "https://doi.org/10.3390/su17104335", "is_oa": true, "oa_status": "gold"}}
{"query": "LLM agent orchestration, tool use, reliability, evals, security", "work": {"openalex_id": "https://openalex.org/W4412787296", "openalex_id_short": "W4412787296", "title": "AI-driven disinformation: policy recommendations for democratic resilience", "authors": ["Alexander Romanishyn", "Olena Malytska", "V. A. Goncharuk"], "published": "2025-07-31", "abstract": "The increasing integration of artificial intelligence (AI) into digital communication platforms has significantly transformed the landscape of information dissemination. Recent evidence indicates that AI-enabled tools, particularly generative models and engagement-optimization algorithms, play a central role in the production and amplification of disinformation. This phenomenon poses a direct challenge to democratic processes, as algorithmically amplified falsehoods systematically distort political information environments, erode public trust in institutions, and foster polarization – conditions that degrade democratic decision-making. The regulatory asymmetry between traditional media – historically subject to public oversight – and digital platforms exacerbates these vulnerabilities. This policy and practice review has three primary aims: (1) to document and analyze the role of AI in recent disinformation campaigns, (2) to assess the effectiveness and limitations of existing AI governance frameworks in mitigating disinformation risks, and (3) to formulate evidence-informed policy recommendations to strengthen institutional resilience. Drawing on qualitative analysis of case studies and regulatory trends, we argue for the urgent need to embed AI-specific oversight mechanisms within democratic governance systems. We recommend a multi-stakeholder approach involving platform accountability, enforceable regulatory harmonization across jurisdictions, and sustained civic education to foster digital literacy and cognitive resilience as defenses against malign information. Without such interventions, democratic processes risk becoming increasingly susceptible to manipulation, delegitimization, and systemic erosion.", "doi": "https://doi.org/10.3389/frai.2025.1569115", "journal": "Frontiers in Artificial Intelligence", "cited_by_count": 7, "pdf_url": "https://www.frontiersin.org/journals/artificial-intelligence/articles/10.3389/frai.2025.1569115/pdf", "pdf_urls": ["https://www.frontiersin.org/journals/artificial-intelligence/articles/10.3389/frai.2025.1569115/pdf"], "landing_page_url": "https://doi.org/10.3389/frai.2025.1569115", "is_oa": true, "oa_status": "gold"}}
{"query": "LLM agent orchestration, tool use, reliability, evals, security", "work": {"openalex_id": "https://openalex.org/W4411361610", "openalex_id_short": "W4411361610", "title": "Scaling Generative AI for Self-Healing DevOps Pipelines: Technical Analysis", "authors": ["Bipul Bhattarai"], "published": "2025-06-17", "abstract": "This comprehensive technical analysis examines the emerging field of AI-driven self-healing DevOps pipelines, focusing on the architectural implementation, multi-agent orchestration systems, and governance mechanisms that enable autonomous infrastructure management. The study analyzes breakthrough advancements in LLM-based log parsing frameworks achieving 98% precision in root-cause analysis, sophisticated multi-agent remediation systems demonstrating 5.76x performance improvements over traditional approaches, and robust governance architectures with confidence-based decision making at 0.85 thresholds.The analysis reveals that modern self-healing systems employ sophisticated detection stages utilizing LogParser-LLM frameworks processing 3.6 million logs with minimal LLM invocations, while maintaining 90.6% F1 scores for grouping accuracy. Multi-agent orchestration patterns leverage specialized agents across functional domains with hierarchical communication protocols, implementing event-driven workflows and state machine orchestration for distributed transaction management. Governance mechanisms integrate policy engines with blast radius controls, automated audit trails, and LLM-generated natural-language rationales for explainable AI decision-making.Empirical validation demonstrates significant operational improvements including 55% reduction in Mean Time to Recovery (MTTR), 208x increase in code deployment frequency for DevOps-mature organizations, and over 90% developer trust retention across enterprise implementations. The market evolution shows exceptional growth from $942.5 million in 2022 to projected $22.1 billion by 2032, with 74% organizational DevOps adoption and 51% code copilot utilization representing the highest AI tool adoption rates.Integration with modern cloud platforms including AWS SageMaker, Kubernetes orchestration, and Terraform infrastructure-as-code demonstrates mature production-ready implementations. The analysis connects theoretical frameworks to practical deployments across major enterprise environments, revealing standardized multi-agent communication protocols and sophisticated resilience patterns including circuit breakers, retry mechanisms with exponential backoff, and graceful degradation capabilities.The study concludes that AI-driven self-healing DevOps represents a paradigm shift from reactive to predictive infrastructure management, with proven capabilities for transforming software delivery processes through autonomous anomaly detection, intelligent remediation, and comprehensive governance frameworks that ensure safety, explainability, and regulatory compliance in enterprise-scale deployments.", "doi": "https://doi.org/10.20944/preprints202506.1436.v1", "journal": "Preprints.org", "cited_by_count": 1, "pdf_url": "https://www.preprints.org/frontend/manuscript/31987ebf32ae0d7ef875f4970f738b2e/download_pub", "pdf_urls": ["https://www.preprints.org/frontend/manuscript/31987ebf32ae0d7ef875f4970f738b2e/download_pub"], "landing_page_url": "https://doi.org/10.20944/preprints202506.1436.v1", "is_oa": true, "oa_status": "green"}}
{"query": "LLM agent orchestration, tool use, reliability, evals, security", "work": {"openalex_id": "https://openalex.org/W4412931371", "openalex_id_short": "W4412931371", "title": "Multimodal Sensing-Enabled Large Language Models for Automated Emotional Regulation: A Review of Current Technologies, Opportunities, and Challenges", "authors": ["Liangyue Yu", "Yao Ge", "Shuja Ansari", "Muhammad Ali Imran", "Wasim Ahmad"], "published": "2025-08-01", "abstract": "Emotion regulation is essential for mental health. However, many people ignore their own emotional regulation or are deterred by the high cost of psychological counseling, which poses significant challenges to making effective support widely available. This review systematically examines the convergence of multimodal sensing technologies and large language models (LLMs) for the development of Automated Emotional Regulation (AER) systems. The review draws upon a comprehensive analysis of the existing literature, encompassing research papers, technical reports, and relevant theoretical frameworks. Key findings indicate that multimodal sensing offers the potential for rich, contextualized data pertaining to emotional states, while LLMs provide improved capabilities for interpreting these inputs and generating nuanced, empathetic, and actionable regulatory responses. The integration of these technologies, including physiological sensors, behavioral tracking, and advanced LLM architectures, presents the improvement of application, moving AER beyond simpler, rule-based systems towards more adaptive, context-aware, and human-like interventions. Opportunities for personalized interventions, real-time support, and novel applications in mental healthcare and other domains are considerable. However, these prospects are counterbalanced by significant challenges and limitations. In summary, this review synthesizes current technological advancements, identifies substantial opportunities for innovation and application, and critically analyzes the multifaceted technical, ethical, and practical challenges inherent in this domain. It also concludes that while the integration of multimodal sensing and LLMs holds significant potential for AER, the field is nascent and requires concerted research efforts to realize its full capacity to enhance human well-being.", "doi": "https://doi.org/10.3390/s25154763", "journal": "Sensors", "cited_by_count": 1, "pdf_url": "https://www.mdpi.com/1424-8220/25/15/4763/pdf?version=1754056980", "pdf_urls": ["https://www.mdpi.com/1424-8220/25/15/4763/pdf?version=1754056980"], "landing_page_url": "https://doi.org/10.3390/s25154763", "is_oa": true, "oa_status": "gold"}}
{"query": "LLM agent orchestration, tool use, reliability, evals, security", "work": {"openalex_id": "https://openalex.org/W4410508625", "openalex_id_short": "W4410508625", "title": "Towards Artificial General or Personalized Intelligence? A Survey on Foundation Models for Personalized Federated Intelligence", "authors": ["Yu Qiao", "Huy Quang Lê", "Avi Deb Raha", "Pham-Tue-Hung Tran", "Apurba Adhikary", "Mengchun Zhang", "Lim Nguyen", "Eui‐Nam Huh", "Dusit Niyato", "Choong Seon Hong"], "published": "2025-05-19", "abstract": null, "doi": "https://doi.org/10.36227/techrxiv.174762883.35612385/v1", "journal": null, "cited_by_count": 1, "pdf_url": "https://www.techrxiv.org/doi/pdf/10.36227/techrxiv.174762883.35612385/v1", "pdf_urls": ["https://www.techrxiv.org/doi/pdf/10.36227/techrxiv.174762883.35612385/v1"], "landing_page_url": "https://doi.org/10.36227/techrxiv.174762883.35612385/v1", "is_oa": true, "oa_status": "gold"}}
{"query": "LLM agent orchestration, tool use, reliability, evals, security", "work": {"openalex_id": "https://openalex.org/W4411152803", "openalex_id_short": "W4411152803", "title": "A Unified Framework for Automated Testing of Robotic Process Automation Workflows Using Symbolic and Concolic Analysis", "authors": ["Ciprian Păduraru", "Marina Cernat", "Adelina-Nicoleta Staicu"], "published": "2025-06-09", "abstract": "Robotic Process Automation is a technology that replicates human interactions with user interfaces across various applications. However, testing Robotic Process Automation implementations remains challenging due to the dynamic nature of workflows. This paper presents a novel testing framework that first integrates symbolic execution and concolic testing strategies to enhance Robotic Process Automation workflow validation. Building on insights from these methods, we introduce a hybrid approach that optimizes test coverage and efficiency in specific cases. Our open-source implementation demonstrates that automated testing in the Robotic Process Automation domain significantly improves coverage, reduces manual effort, and enhances reliability. Furthermore, the proposed solution supports multiple Robotic Process Automation platforms and aligns with industry best practices for user interface automation testing. Experimental evaluation, conducted in collaboration with industry, validates the effectiveness of our approach.", "doi": "https://doi.org/10.3390/machines13060504", "journal": "Machines", "cited_by_count": 1, "pdf_url": "https://www.mdpi.com/2075-1702/13/6/504/pdf?version=1749550271", "pdf_urls": ["https://www.mdpi.com/2075-1702/13/6/504/pdf?version=1749550271"], "landing_page_url": "https://doi.org/10.3390/machines13060504", "is_oa": true, "oa_status": "gold"}}
