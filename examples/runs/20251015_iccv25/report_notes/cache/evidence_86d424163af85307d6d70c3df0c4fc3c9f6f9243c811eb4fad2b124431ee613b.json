{
  "content": "\ub2e4\uc74c\uc740 ICCV 2025\uc640 \uad00\ub828\ub41c \uc790\ub8cc\uc5d0\uc11c \ucd94\ucd9c\ud55c \uc911\uc694\ud55c \uc815\ubcf4\uc785\ub2c8\ub2e4. \uc774 \uc815\ubcf4\ub294 \uc6f9 \uae30\ubc18 \uc790\ub8cc\ub97c \ud3ec\ud568\ud558\uba70, \ucd9c\ucc98\uc640 \ud568\uaed8 \uc81c\uacf5\ub429\ub2c8\ub2e4.\n\n### \uc6f9 \uc790\ub8cc\n- **[ICCV 2025 - Amazon Science](https://www.amazon.science/conferences-and-events/iccv-2025)**  \n  ICCV 2025\uc640 \uad00\ub828\ub41c \uc5f0\uad6c \uae30\ud68c \ubc0f \ubc1c\ud45c \ub0b4\uc6a9 \uc815\ub9ac.\n\n- **[All Papers - ICCV 2025 Open Access Repository](https://openaccess.thecvf.com/ICCV2025?day=all)**  \n  ICCV 2025\uc5d0\uc11c \ubc1c\ud45c\ub41c \ubaa8\ub4e0 \ub17c\ubb38\uc5d0 \ub300\ud55c \uc18c\uac1c \ubc0f \uc811\uadfc \uc815\ubcf4 \uc81c\uacf5.\n\n- **[ICCV 2025 Accepted Papers - MMLab@NTU](https://www.mmlab-ntu.com/conference/iccv2025/index.html)**  \n  ICCV 2025\uc5d0\uc11c \uc2b9\uc778\ub41c \ubaa8\ub4e0 \ub17c\ubb38 \ubaa9\ub85d \uc81c\uacf5.\n\n- **[Important Dates and Deadlines - ICCV 2025](https://iccv.thecvf.com/Conferences/2025/Dates)**  \n  ICCV 2025\uc758 \uc8fc\uc694 \uc77c\uc815 \ubc0f \ub9c8\uac10\uc77c \uc815\ubcf4.\n\n- **[Vision-Language Modeling Meets Remote Sensing](http://arxiv.org/abs/2505.14361)**  \n  \uc774\ubbf8\uc9c0\uc640 \uc790\uc5f0\uc5b4 \uac04\uc758 \uc815\ubcf4 \uac04\uadf9\uc744 \uc904\uc774\ub294 \ubc29\ubc95\ub860\uc5d0 \ub300\ud55c \ub17c\uc758.\n\n- **[Trajectory Prediction via Proposal Guided Transformer](https://doi.org/10.1038/s41598-025-97244-4)**  \n  \ube44\ub514\uc624 \uac1d\uccb4 \ucd94\uc801\uc744 \uc704\ud55c \uc0c8\ub85c\uc6b4 \uc811\uadfc \ubc29\uc2dd \uc124\uba85.\n\n- **[OpenCV for Computer Vision Applications](https://doi.org/10.36948/ijfmr.2025.v07i03.44280)**  \n  OpenCV\uc758 \ub2e4\uc591\ud55c \uc2e4\uc2dc\uac04 \uc751\uc6a9 \ud504\ub85c\uadf8\ub7a8\uc5d0\uc11c\uc758 \ud65c\uc6a9 \uc124\uba85.\n\n### \uc8fc\uc694 \ub17c\ubb38 \ubc0f PDF \ub9c1\ud06c\n1. **[Trajectory Prediction via Proposal Guided Transformer](https://doi.org/10.1038/s41598-025-97244-4)** (PDF: [Link](https://www.nature.com/articles/s41598-025-97244-4.pdf), Citations: 4)\n2. **[OpenCV for Computer Vision Applications](https://doi.org/10.36948/ijfmr.2025.v07i03.44280)** (PDF: [Link](https://www.ijfmr.com/papers/2025/3/44280.pdf), Citations: 59)\n3. **[Vision-Language Modeling Meets Remote Sensing](http://arxiv.org/abs/2505.14361)** (PDF: [Link](https://arxiv.org/pdf/2505.14361), Citations: 5)\n4. **[VQualA 2025 Challenge on Engagement Prediction for Short Videos: Methods and Results](https://doi.org/10.1162/coli.a.16)** (PDF: [Link](https://link.springer.com/content/pdf/10.1007/s11528-025-01100-1.pdf), Citations: 22)\n\n\uc774 \uc815\ubcf4\ub294 ICCV 2025\uc5d0 \ub300\ud55c \ud589\uc0ac \ubc0f \uad00\ub828 \uc5f0\uad6c \uc790\ub8cc\ub97c \uc774\ud574\ud558\ub294\ub370 \ub3c4\uc6c0\uc774 \ub429\ub2c8\ub2e4. \ud544\uc694\ud55c \ucd94\uac00 \uc218\uc815\uc774\ub098 \uc9c8\ubb38\uc774 \uc788\uc73c\uc2dc\uba74 \ub9d0\uc500\ud574 \uc8fc\uc138\uc694!",
  "meta": {
    "stage": "evidence",
    "model": "gpt-4o-mini",
    "prompt_hash": "e988ac673b93509adfba0cd1574426e87dae5ad8d65e00875a141aa12af4d38a",
    "input_hash": "ec1a62ab40e43548151b5c8f8300c0d58ac9e9e8b578984cf099ce8db8069207"
  },
  "created_at": "2026-01-26T22:17:53.210938"
}