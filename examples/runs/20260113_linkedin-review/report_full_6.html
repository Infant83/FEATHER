<!doctype html>
<html lang="en">
<head>
  <meta charset="utf-8" />
  <title>Federlicht Report - 20260113_linkedin-review</title>
  <script>
    window.MathJax = {
      tex: { inlineMath: [['$', '$'], ['\\(', '\\)']], displayMath: [['$$', '$$'], ['\\[', '\\]']] },
      svg: { fontCache: 'global' }
    };
  </script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-svg.js"></script>
  <style>
    :root {
      --ink: #1d1c1a;
      --muted: #5a5956;
      --accent: #b24a2f;
      --paper: #ffffff;
      --paper-alt: #f6f1e8;
      --rule: #e7dfd2;
      --shadow: rgba(0, 0, 0, 0.08);
      --link: #1d4e89;
      --link-hover: #0d2b4a;
      --page-bg: radial-gradient(1200px 600px at 20% -10%, #f2efe8 0%, #f7f4ee 45%, #fdfcf9 100%);
      --body-font: "Iowan Old Style", "Charter", "Palatino Linotype", "Book Antiqua", Georgia, serif;
      --heading-font: "Avenir Next", "Gill Sans", "Trebuchet MS", "Helvetica Neue", sans-serif;
      --ui-font: "Avenir Next", "Gill Sans", "Trebuchet MS", "Helvetica Neue", sans-serif;
      --mono-font: "SFMono-Regular", "Consolas", "Liberation Mono", "Courier New", monospace;
    }
    * { box-sizing: border-box; }
    body {
      margin: 0;
      color: var(--ink);
      background: var(--page-bg);
      font-family: var(--body-font);
      line-height: 1.6;
    }
    .page {
      max-width: 980px;
      margin: 48px auto 80px;
      padding: 0 24px;
    }
    .masthead {
      border-bottom: 1px solid var(--rule);
      padding-bottom: 16px;
      margin-bottom: 32px;
    }
    .kicker {
      font-family: var(--ui-font);
      font-size: 0.82rem;
      letter-spacing: 0.22em;
      text-transform: uppercase;
      color: var(--accent);
    }
    .report-title {
      font-family: var(--heading-font);
      font-size: 2.4rem;
      margin: 8px 0 6px;
    }
    .report-deck {
      color: var(--muted);
      font-size: 1.05rem;
    }
    .article {
      background: var(--paper);
      border: 1px solid var(--rule);
      border-radius: 16px;
      padding: 36px 40px;
      box-shadow: 0 18px 45px var(--shadow);
    }
    .article h1, .article h2, .article h3, .article h4 {
      font-family: var(--heading-font);
      color: var(--ink);
    }
    .article h1 { font-size: 2rem; margin-top: 0; }
    .article h2 {
      font-size: 1.5rem;
      margin-top: 2.4rem;
      padding-top: 0.6rem;
      border-top: 1px solid var(--rule);
    }
    .article h3 { font-size: 1.2rem; margin-top: 1.6rem; }
    .article p { font-size: 1.05rem; }
    .article ul, .article ol { padding-left: 1.4rem; }
    .article blockquote {
      border-left: 3px solid var(--accent);
      margin: 1.6rem 0;
      padding: 0.5rem 1.2rem;
      background: var(--paper-alt);
      color: var(--muted);
      font-style: italic;
    }
    .article a {
      color: var(--link);
      text-decoration: none;
      border-bottom: 1px solid rgba(29, 78, 137, 0.35);
    }
    .article a:hover { color: var(--link-hover); border-bottom-color: var(--link-hover); }
    .article code {
      background: #f7f6f3;
      padding: 2px 4px;
      border-radius: 6px;
      font-family: var(--mono-font);
      font-size: 0.95em;
    }
    .article pre {
      background: #f7f6f3;
      border: 1px solid var(--rule);
      border-radius: 12px;
      padding: 14px;
      overflow-x: auto;
      white-space: pre-wrap;
      font-family: var(--mono-font);
    }
    .article table { border-collapse: collapse; width: 100%; margin: 1.2rem 0; }
    .article th, .article td { border: 1px solid var(--rule); padding: 8px 10px; }
    .article th { background: var(--paper-alt); text-align: left; }
    .article hr { border: none; border-top: 1px solid var(--rule); margin: 2rem 0; }
    .misc-block {
      font-size: 0.85rem;
      color: var(--muted);
      margin-top: 0.6rem;
    }
    .misc-block ul { margin: 0.6rem 0 0.8rem 1.2rem; }
    .misc-block li { margin: 0.2rem 0; }
    .report-figure {
      margin: 1.4rem 0;
      padding: 0.8rem 1rem;
      border: 1px solid var(--rule);
      border-radius: 12px;
      background: var(--paper-alt);
    }
    .report-figure img { max-width: 100%; height: auto; display: block; margin: 0 auto; }
    .report-figure figcaption { font-size: 0.9rem; color: var(--muted); margin-top: 0.4rem; }
    .figure-callout { font-size: 0.95rem; color: var(--muted); margin: 0.8rem 0 1rem; font-style: italic; }
    .viewer-overlay {
      position: fixed;
      inset: 0;
      background: rgba(19, 18, 16, 0.35);
      opacity: 0;
      pointer-events: none;
      transition: opacity 0.2s ease;
    }
    .viewer-overlay.open { opacity: 1; pointer-events: auto; }
    .viewer-panel {
      position: fixed;
      top: 20px;
      right: 20px;
      width: min(560px, 92vw);
      height: calc(100% - 40px);
      background: #ffffff;
      border: 1px solid var(--rule);
      border-radius: 16px;
      box-shadow: 0 24px 60px rgba(0, 0, 0, 0.2);
      transform: translateX(120%);
      transition: transform 0.25s ease;
      display: flex;
      flex-direction: column;
      z-index: 30;
    }
    .viewer-panel.open { transform: translateX(0); }
    .viewer-header {
      display: flex;
      align-items: center;
      justify-content: space-between;
      padding: 12px 16px;
      border-bottom: 1px solid var(--rule);
      font-family: var(--ui-font);
      gap: 12px;
    }
    .viewer-title { font-size: 0.95rem; color: var(--ink); flex: 1; }
    .viewer-actions { display: flex; gap: 8px; align-items: center; }
    .viewer-actions a {
      font-size: 0.85rem;
      color: var(--link);
      text-decoration: none;
    }
    .viewer-close {
      border: none;
      background: #f4efe6;
      color: var(--ink);
      border-radius: 999px;
      width: 28px;
      height: 28px;
      cursor: pointer;
    }
    .viewer-frame { flex: 1; border: none; width: 100%; border-radius: 0 0 16px 16px; }
    @media (max-width: 720px) {
      .page { margin: 32px auto 56px; }
      .article { padding: 24px; }
      .report-title { font-size: 1.9rem; }
    }
body.template-default,
body.template-arxiv_preprint,
body.template-acs_review {
  --ink: #1d1b17;
  --muted: #59524a;
  --accent: #8b3f2d;
  --paper-alt: #f2ede3;
  --page-bg: radial-gradient(1200px 600px at 18% -12%, #efe9e0 0%, #f6f2ea 45%, #fdfcf9 100%);
  --body-font: "Iowan Old Style", "Charter", "Palatino Linotype", "Book Antiqua", Georgia, serif;
  --heading-font: "Avenir Next", "Gill Sans", "Trebuchet MS", "Helvetica Neue", sans-serif;
  --ui-font: "Avenir Next", "Gill Sans", "Trebuchet MS", "Helvetica Neue", sans-serif;
}

body.template-default .kicker,
body.template-arxiv_preprint .kicker,
body.template-acs_review .kicker {
  letter-spacing: 0.26em;
}

  </style>
</head>
<body class="template-default">
  <div class="page">
    <header class="masthead">
      <div class="kicker">Federlicht</div>
      <div class="report-title">Federlicht Report - 20260113_linkedin-review</div>
      <div class="report-deck">Research review and tech survey</div>
    </header>
    <main class="article">
<p>Federlicht assisted and prompted by "Hyun-Jung Kim / AI Governance Team" — 2026-01-16 00:55</p>
<h2>Executive Summary</h2>
<p>EGGROLL(Evolution Guided General Optimization via Low-rank Learning)은 “대규모(population)로 스케일 가능한 backprop-free(gradient-free) 최적화”를 표방하며, 전통적 Evolution Strategies(ES)의 병목을 <strong>low-rank perturbation</strong>으로 치환해 메모리·연산 복잡도를 낮추는 접근을 제시한다는 점에서 주목할 만하다. arXiv 초록은 naïve ES가 대규모에서 비싸지는 이유를 “섭동 행렬 $E\in\mathbb{R}^{m\times n}$ 생성/저장”과 “per-member forward pass를 위한 batched matmul”로 명시하고, 이를 $A\in\mathbb{R}^{m\times r}, B\in\mathbb{R}^{n\times r}$로 생성한 $AB^\top$로 대체하여 auxiliary storage를 $mn \rightarrow r(m+n)$, forward 비용을 $\mathcal{O}(mn)\rightarrow \mathcal{O}(r(m+n))$로 줄인다고 주장한다(“when compared to full-rank ES”) <a href="report_views/archive_tavily_extract_0002_https_arxiv.org_abs_2511.16652.txt-ea7fa5eb.html" data-viewer="report_views/archive_tavily_extract_0002_https_arxiv.org_abs_2511.16652.txt-ea7fa5eb.html" data-raw="archive/tavily_extract/0002_https_arxiv.org_abs_2511.16652.txt" class="viewer-link">[1]</a>. 또한 low-rank update가 full-rank update로 $\mathcal{O}(1/r)$ 속도로 수렴한다는 이론적 분석을 언급한다 <a href="report_views/archive_tavily_extract_0002_https_arxiv.org_abs_2511.16652.txt-ea7fa5eb.html" data-viewer="report_views/archive_tavily_extract_0002_https_arxiv.org_abs_2511.16652.txt-ea7fa5eb.html" data-raw="archive/tavily_extract/0002_https_arxiv.org_abs_2511.16652.txt" class="viewer-link">[1]</a>.</p>
<p>반면, LinkedIn 포스트는 “미분 없이도, backprop 없이도, 거대한 모델을 충분히 잘 훈련”할 수 있다는 강한 메시지와 함께, <strong>통신 비용을 사실상 0으로 만드는 구현 아이디어(perturbation 전달 대신 counter-based RNG로 재현)</strong>, 그리고 “population 262,144” 및 “기존 ES 스케일링의 200배 이상” 같은 수치를 제시한다 <a href="report_views/archive_tavily_extract_0001_https_www.linkedin.com_feed_update_urn_li_activity_7-c43d834b.html" data-viewer="report_views/archive_tavily_extract_0001_https_www.linkedin.com_feed_update_urn_li_activity_7-c43d834b.html" data-raw="archive/tavily_extract/0001_https_www.linkedin.com_feed_update_urn_li_activity_7399939023072358401.txt" class="viewer-link">[2]</a>. 그러나 현재 아카이브는 arXiv <strong>abs(초록) 텍스트 스냅샷만 포함</strong>하고 논문 PDF 본문/표/실험 세팅이 없어, LinkedIn의 구체 수치 및 실험 디테일을 교차검증하기 어렵다 <a href="report_views/archive_20260113_linkedin-review-index.md-ec349456.html" data-viewer="report_views/archive_20260113_linkedin-review-index.md-ec349456.html" data-raw="archive/20260113_linkedin-review-index.md" class="viewer-link">[3]</a>. Tistory 블로그는 논문과 코드 사이트(eshyperscale)를 링크하며, $AB^\top$를 직접 만들지 않고 $(xB)A^\top$ 순서로 계산하는 구현 관점을 설명하고, 여러 실험 항목을 요약하지만 역시 본 아카이브 내에서는 원문 대조가 제한된다 <a href="report_views/archive_tavily_extract_0003_https_muni-dev.tistory.com_entry_Evolution-Strategie-9c07f789.html" data-viewer="report_views/archive_tavily_extract_0003_https_muni-dev.tistory.com_entry_Evolution-Strategie-9c07f789.html" data-raw="archive/tavily_extract/0003_https_muni-dev.tistory.com_entry_Evolution-Strategies-at-the-Hyperscale.txt" class="viewer-link">[4]</a>.</p>
<p>결론적으로, <strong>“저랭크 섭동으로 ES의 계산/메모리 병목을 구조적으로 줄인다”는 주장</strong>은 arXiv 초록 수준에서 명확히 확인되지만, <strong>“hyperscale 수치(예: 262k population), 경쟁 기법 대비 정량 성능, 실전 배포 난이도/ROI”</strong> 등은 본문 근거가 없어 현 단계에서는 보수적으로 해석해야 한다.</p>
<hr />
<h2>Scope &amp; Methodology</h2>
<ul>
<li><strong>분석 범위(아카이브 실사 기준)</strong>: 본 런은 URL 3개에 대한 Tavily Extract 텍스트 스냅샷(LinkedIn, arXiv abs, Tistory)만 포함한다 <a href="report_views/archive_20260113_linkedin-review-index.md-ec349456.html" data-viewer="report_views/archive_20260113_linkedin-review-index.md-ec349456.html" data-raw="archive/20260113_linkedin-review-index.md" class="viewer-link">[3]</a>. 인덱스의 실행 커맨드에는 <code>--download-pdf</code>가 포함되어 있으나, 실제 아카이브 목록은 extract 텍스트 3개만 기재되어 있어 PDF 본문은 부재하다 <a href="report_views/archive_20260113_linkedin-review-index.md-ec349456.html" data-viewer="report_views/archive_20260113_linkedin-review-index.md-ec349456.html" data-raw="archive/20260113_linkedin-review-index.md" class="viewer-link">[3]</a>.</li>
<li><strong>주요 1차/2차 근거</strong>  </li>
<li>1차: arXiv abs(초록/메타), LinkedIn 포스트 원문 스냅샷 <a href="report_views/archive_tavily_extract_0002_https_arxiv.org_abs_2511.16652.txt-ea7fa5eb.html" data-viewer="report_views/archive_tavily_extract_0002_https_arxiv.org_abs_2511.16652.txt-ea7fa5eb.html" data-raw="archive/tavily_extract/0002_https_arxiv.org_abs_2511.16652.txt" class="viewer-link">[1]</a>, <a href="report_views/archive_tavily_extract_0001_https_www.linkedin.com_feed_update_urn_li_activity_7-c43d834b.html" data-viewer="report_views/archive_tavily_extract_0001_https_www.linkedin.com_feed_update_urn_li_activity_7-c43d834b.html" data-raw="archive/tavily_extract/0001_https_www.linkedin.com_feed_update_urn_li_activity_7399939023072358401.txt" class="viewer-link">[2]</a>  </li>
<li>2차: Tistory 리뷰(해설/재서술) <a href="report_views/archive_tavily_extract_0003_https_muni-dev.tistory.com_entry_Evolution-Strategie-9c07f789.html" data-viewer="report_views/archive_tavily_extract_0003_https_muni-dev.tistory.com_entry_Evolution-Strategie-9c07f789.html" data-raw="archive/tavily_extract/0003_https_muni-dev.tistory.com_entry_Evolution-Strategies-at-the-Hyperscale.txt" class="viewer-link">[4]</a></li>
<li><strong>내부 산출물 점검(품질/근거성 평가)</strong>: 아카이브에는 <code>final</code> 및 <code>final-v2~v5</code>가 존재하나(파일 크기 동일), 내부 내용은 “커뮤니티 채택/비즈니스 적용” 등 아카이브 근거로 직접 확인하기 어려운 일반론을 포함한다 <a href="report_views/archive_20260113_linkedin-review-final.md-25459c4d.html" data-viewer="report_views/archive_20260113_linkedin-review-final.md-25459c4d.html" data-raw="archive/20260113_linkedin-review-final.md" class="viewer-link">[5]</a>. 본 보고서는 이를 <strong>근거-주장 매핑 관점에서 비판적으로 교정</strong>한다.</li>
</ul>
<hr />
<h2>Key Findings</h2>
<h3>1) EGGROLL의 핵심 기여: “full-rank 섭동을 low-rank로 치환”해 ES를 대규모로 스케일</h3>
<p>arXiv 초록은 EGGROLL을 “backprop-free optimization을 large population sizes로 스케일”하는 ES 알고리즘으로 소개하며, 병목을 <strong>섭동 행렬 $E\in\mathbb{R}^{m\times n}$ 생성/저장 비용</strong>과 <strong>batched matmul 기반 per-member forward pass 비용</strong>으로 특정한다 <a href="report_views/archive_tavily_extract_0002_https_arxiv.org_abs_2511.16652.txt-ea7fa5eb.html" data-viewer="report_views/archive_tavily_extract_0002_https_arxiv.org_abs_2511.16652.txt-ea7fa5eb.html" data-raw="archive/tavily_extract/0002_https_arxiv.org_abs_2511.16652.txt" class="viewer-link">[1]</a>. 해결책은 $A\in\mathbb{R}^{m\times r}, B\in\mathbb{R}^{n\times r}$를 생성해 $AB^\top$ 형태의 low-rank perturbation을 사용(단 $r\ll \min(m,n)$)하는 것이다 <a href="report_views/archive_tavily_extract_0002_https_arxiv.org_abs_2511.16652.txt-ea7fa5eb.html" data-viewer="report_views/archive_tavily_extract_0002_https_arxiv.org_abs_2511.16652.txt-ea7fa5eb.html" data-raw="archive/tavily_extract/0002_https_arxiv.org_abs_2511.16652.txt" class="viewer-link">[1]</a>.</p>
<p>이 구조는 LoRA가 “가중치 업데이트를 저랭크로 제한”해 효율을 얻는 것과 개념적으로 닮았으나(블로그가 LoRA 아이디어 차용을 언급), EGGROLL은 “섭동/추정 과정 자체”를 저랭크로 만드는 점에서 <strong>학습 역학과 시스템 비용(특히 샘플링/추론 경로)의 형태</strong>가 달라질 수 있다 <a href="report_views/archive_tavily_extract_0003_https_muni-dev.tistory.com_entry_Evolution-Strategie-9c07f789.html" data-viewer="report_views/archive_tavily_extract_0003_https_muni-dev.tistory.com_entry_Evolution-Strategie-9c07f789.html" data-raw="archive/tavily_extract/0003_https_muni-dev.tistory.com_entry_Evolution-Strategies-at-the-Hyperscale.txt" class="viewer-link">[4]</a>.</p>
<h3>2) 복잡도 주장: auxiliary storage와 forward 비용을 $mn$에서 $r(m+n)$로 축소</h3>
<p>arXiv 초록은 full-rank ES 대비, per layer auxiliary storage가 $mn \rightarrow r(m+n)$로 감소하고, forward pass 비용이 $\mathcal{O}(mn)\rightarrow\mathcal{O}(r(m+n))$로 줄어든다고 명시한다 <a href="report_views/archive_tavily_extract_0002_https_arxiv.org_abs_2511.16652.txt-ea7fa5eb.html" data-viewer="report_views/archive_tavily_extract_0002_https_arxiv.org_abs_2511.16652.txt-ea7fa5eb.html" data-raw="archive/tavily_extract/0002_https_arxiv.org_abs_2511.16652.txt" class="viewer-link">[1]</a>. 이는 “ES가 스케일링이 안 된다”는 실무자 인식(LinkedIn의 “너무 비싸고, 너무 느리고, 스케일링이 되지 않았다”)에 대해, 병목을 알고리즘적으로 겨냥한 응답으로 읽힌다 <a href="report_views/archive_tavily_extract_0001_https_www.linkedin.com_feed_update_urn_li_activity_7-c43d834b.html" data-viewer="report_views/archive_tavily_extract_0001_https_www.linkedin.com_feed_update_urn_li_activity_7-c43d834b.html" data-raw="archive/tavily_extract/0001_https_www.linkedin.com_feed_update_urn_li_activity_7399939023072358401.txt" class="viewer-link">[2]</a>.</p>
<p>다만 여기서의 절감은 <strong>$r$ 선택에 크게 좌우</strong>되며, 초록만으로는 (i) 실사용에서 필요한 $r$의 크기, (ii) 레이어별 형태($m,n$ 정의가 정확히 무엇인지), (iii) 실제 GPU 커널 효율(메모리 대역폭 vs 연산)까지 확정하기 어렵다.</p>
<h3>3) “개별 섭동은 low-rank지만, 집단 평균 업데이트는 high-rank”라는 직관의 제도화</h3>
<p>arXiv 초록은 “overall update is an average across a population of $N$ workers”이므로 low-rank perturbation을 쓰더라도 최종 업데이트가 high-rank가 된다고 설명한다 <a href="report_views/archive_tavily_extract_0002_https_arxiv.org_abs_2511.16652.txt-ea7fa5eb.html" data-viewer="report_views/archive_tavily_extract_0002_https_arxiv.org_abs_2511.16652.txt-ea7fa5eb.html" data-raw="archive/tavily_extract/0002_https_arxiv.org_abs_2511.16652.txt" class="viewer-link">[1]</a>. LinkedIn 포스트도 유사하게 “population 전체에서 low-rank update를 평균내면 full-rank ES 업데이트처럼 작동”한다는 취지로 요약한다 [[6]](<a href=".&lt;a href=" . archive tavily_extract 0001_https_www.linkedin.com_feed_update_urn_li_activity_7399939023072358401.txt">/archive/tavily_extract/0001_https_www.linkedin.com_feed_update_urn_li_activity_7399939023072358401.txt</a>">.<a href="report_views/archive_tavily_extract_0001_https_www.linkedin.com_feed_update_urn_li_activity_7-c43d834b.html" data-viewer="report_views/archive_tavily_extract_0001_https_www.linkedin.com_feed_update_urn_li_activity_7-c43d834b.html" data-raw="archive/tavily_extract/0001_https_www.linkedin.com_feed_update_urn_li_activity_7399939023072358401.txt" class="viewer-link">/archive/tavily_extract/0001_https_www.linkedin.com_feed_update_urn_li_activity_7399939023072358401.txt</a></a>].<br />
이 관점은 “표현력(업데이트 랭크)을 유지하면서, 생성/전달/곱셈 비용을 낮춘다”는 EGGROLL의 설득력 있는 내러티브를 구성한다.</p>
<h3>4) 이론 주장: low-rank update가 full-rank update로 $\mathcal{O}(1/r)$로 수렴</h3>
<p>arXiv 초록은 “theoretical analysis reveals our low-rank update converges to the full-rank update at a fast $\mathcal{O}(1/r)$ rate”라고 명시한다 <a href="report_views/archive_tavily_extract_0002_https_arxiv.org_abs_2511.16652.txt-ea7fa5eb.html" data-viewer="report_views/archive_tavily_extract_0002_https_arxiv.org_abs_2511.16652.txt-ea7fa5eb.html" data-raw="archive/tavily_extract/0002_https_arxiv.org_abs_2511.16652.txt" class="viewer-link">[1]</a>. 블로그도 동일한 $O(1/r)$ 요지를 강조한다 <a href="report_views/archive_tavily_extract_0003_https_muni-dev.tistory.com_entry_Evolution-Strategie-9c07f789.html" data-viewer="report_views/archive_tavily_extract_0003_https_muni-dev.tistory.com_entry_Evolution-Strategie-9c07f789.html" data-raw="archive/tavily_extract/0003_https_muni-dev.tistory.com_entry_Evolution-Strategies-at-the-Hyperscale.txt" class="viewer-link">[4]</a>.<br />
다만, 어떤 노이즈 가정/목적함수 조건에서의 수렴인지, 그리고 “update 근사”가 실제 최적화 성능(샘플 효율, 안정성)과 어떤 상관을 갖는지는 본문이 없어 현재는 구조만 확인 가능한 상태다.</p>
<h3>5) 실험 주장(초록 수준): RL, LLM reasoning, integer datatype RNN pre-training</h3>
<p>arXiv 초록은 (1) tabula-rasa RL에서 성능을 해치지 않으면서 더 빠름, (2) LLM reasoning 개선에서 GRPO와 경쟁력, (3) integer datatypes로 동작하는 nonlinear recurrent language model의 안정적 pre-training 가능을 실험으로 제시한다 <a href="report_views/archive_tavily_extract_0002_https_arxiv.org_abs_2511.16652.txt-ea7fa5eb.html" data-viewer="report_views/archive_tavily_extract_0002_https_arxiv.org_abs_2511.16652.txt-ea7fa5eb.html" data-raw="archive/tavily_extract/0002_https_arxiv.org_abs_2511.16652.txt" class="viewer-link">[1]</a>.<br />
LinkedIn 포스트는 이를 더 강하게 해석해 “미분/Backprop 없이도 거대 모델을 충분히 잘 훈련” 가능하다고 서술한다 <a href="report_views/archive_tavily_extract_0001_https_www.linkedin.com_feed_update_urn_li_activity_7-c43d834b.html" data-viewer="report_views/archive_tavily_extract_0001_https_www.linkedin.com_feed_update_urn_li_activity_7-c43d834b.html" data-raw="archive/tavily_extract/0001_https_www.linkedin.com_feed_update_urn_li_activity_7399939023072358401.txt" class="viewer-link">[2]</a>. 여기에는 “초록 요약”에서 “일반적 결론”으로 확장되는 과감한 프레이밍이 존재한다는 점을 분리해 읽을 필요가 있다.</p>
<hr />
<h2>Trends &amp; Implications</h2>
<h3>1) “학습 알고리즘 혁신”과 “시스템 설계 혁신”의 결합으로서의 EGGROLL</h3>
<p>LinkedIn 포스트는 EGGROLL의 의미를 단순 알고리즘 개선이 아니라 “패러다임 전환”으로 제시하며, 특히 <strong>통신을 줄이는 구현(perturbation 전달 없이 counter-based RNG로 각 worker가 재현)</strong>을 강조한다 <a href="report_views/archive_tavily_extract_0001_https_www.linkedin.com_feed_update_urn_li_activity_7-c43d834b.html" data-viewer="report_views/archive_tavily_extract_0001_https_www.linkedin.com_feed_update_urn_li_activity_7-c43d834b.html" data-raw="archive/tavily_extract/0001_https_www.linkedin.com_feed_update_urn_li_activity_7399939023072358401.txt" class="viewer-link">[2]</a>. 이는 hyperscale 환경에서 병목이 “연산”뿐 아니라 “통신/메모리 이동”이라는 현실적 문제의식에 맞닿는다.<br />
블로그 또한 $AB^\top$를 직접 구성하지 않고 $(xB)A^\top$로 계산 순서를 바꾸는 구현 관점을 제시한다 <a href="report_views/archive_tavily_extract_0003_https_muni-dev.tistory.com_entry_Evolution-Strategie-9c07f789.html" data-viewer="report_views/archive_tavily_extract_0003_https_muni-dev.tistory.com_entry_Evolution-Strategie-9c07f789.html" data-raw="archive/tavily_extract/0003_https_muni-dev.tistory.com_entry_Evolution-Strategies-at-the-Hyperscale.txt" class="viewer-link">[4]</a>. 즉, EGGROLL의 확장성 주장은 알고리즘과 커널/연산 그래프 최적화가 함께 성립할 때 설득력이 커진다.</p>
<h3>2) 적용 유망 영역: 비미분/불연속/정수 연산 모델 및 “탐색이 중요한” 설정</h3>
<p>arXiv 초록이 “non-differentiable or noisy objectives”에 강점을 갖는 ES 맥락을 재확인하고 <a href="report_views/archive_tavily_extract_0002_https_arxiv.org_abs_2511.16652.txt-ea7fa5eb.html" data-viewer="report_views/archive_tavily_extract_0002_https_arxiv.org_abs_2511.16652.txt-ea7fa5eb.html" data-raw="archive/tavily_extract/0002_https_arxiv.org_abs_2511.16652.txt" class="viewer-link">[1]</a>, integer datatype RNN pre-training을 성과로 제시한 점은 <a href="report_views/archive_tavily_extract_0002_https_arxiv.org_abs_2511.16652.txt-ea7fa5eb.html" data-viewer="report_views/archive_tavily_extract_0002_https_arxiv.org_abs_2511.16652.txt-ea7fa5eb.html" data-raw="archive/tavily_extract/0002_https_arxiv.org_abs_2511.16652.txt" class="viewer-link">[1]</a>, 향후 (i) 정수/양자화 친화 학습, (ii) 시뮬레이터·조합최적화·프로그램 탐색 등에서의 <strong>대규모 병렬 탐색 기반 학습</strong>으로의 확장을 시사한다. 블로그의 “한 번에 1,024개 vs 32개 생성”과 같은 병렬 탐색 서사는 이러한 흐름을 강화하지만, 본 아카이브에서는 원문 실험표 대조가 불가하므로 “가능한 해석” 수준으로 제한해야 한다 <a href="report_views/archive_tavily_extract_0003_https_muni-dev.tistory.com_entry_Evolution-Strategie-9c07f789.html" data-viewer="report_views/archive_tavily_extract_0003_https_muni-dev.tistory.com_entry_Evolution-Strategie-9c07f789.html" data-raw="archive/tavily_extract/0003_https_muni-dev.tistory.com_entry_Evolution-Strategies-at-the-Hyperscale.txt" class="viewer-link">[4]</a>.</p>
<h3>3) 기술 리더 관점의 실무 함의: “backprop 대체”보다 “옵션 추가”로 보는 것이 현실적</h3>
<p>자료들이 공유하는 공통점은 “ES가 다시 경쟁력을 가질 수 있다”는 점이지만, 초록이 제시한 실험 범주(RL, reasoning, integer RNN)만으로 “일반적 대규모 LLM 프리트레이닝을 backprop 없이 대체”까지 결론 내리기는 이르다 <a href="report_views/archive_tavily_extract_0002_https_arxiv.org_abs_2511.16652.txt-ea7fa5eb.html" data-viewer="report_views/archive_tavily_extract_0002_https_arxiv.org_abs_2511.16652.txt-ea7fa5eb.html" data-raw="archive/tavily_extract/0002_https_arxiv.org_abs_2511.16652.txt" class="viewer-link">[1]</a>.<br />
따라서 조직 차원에서는 EGGROLL을 “대체재”라기보다, <strong>(a) 비미분/불연속 부품이 포함된 시스템, (b) 탐색·병렬성이 중요한 파이프라인</strong>에서의 전략적 옵션으로 포지셔닝하고, 비용/안정성/재현성 검증을 병행하는 접근이 합리적이다.</p>
<hr />
<h2>Risks &amp; Gaps</h2>
<h3>1) 가장 큰 공백: 논문 PDF 본문 부재로 인한 검증 불능</h3>
<p>인덱스에는 <code>--download-pdf</code> 옵션이 있으나, 실제 아카이브는 Tavily Extract 텍스트 3개만 포함한다 <a href="report_views/archive_20260113_linkedin-review-index.md-ec349456.html" data-viewer="report_views/archive_20260113_linkedin-review-index.md-ec349456.html" data-raw="archive/20260113_linkedin-review-index.md" class="viewer-link">[3]</a>. 그 결과 다음이 구조적으로 검증 불가다.</p>
<ul>
<li>실험 세팅(모델 크기, 데이터, 하이퍼파라미터, $r$ 선택, population $N$), 표/그림의 정량 결과</li>
<li>LinkedIn의 구체 수치(예: population 262,144, 200x scaling)와 그 정의(throughput 기준, 하드웨어 조건) <a href="report_views/archive_tavily_extract_0001_https_www.linkedin.com_feed_update_urn_li_activity_7-c43d834b.html" data-viewer="report_views/archive_tavily_extract_0001_https_www.linkedin.com_feed_update_urn_li_activity_7-c43d834b.html" data-raw="archive/tavily_extract/0001_https_www.linkedin.com_feed_update_urn_li_activity_7399939023072358401.txt" class="viewer-link">[2]</a></li>
<li>블로그가 요약한 비교 수치(예: 1,024 vs 32) 및 “성능이 더 뛰어남”의 근거 그래프/측정치 <a href="report_views/archive_tavily_extract_0003_https_muni-dev.tistory.com_entry_Evolution-Strategie-9c07f789.html" data-viewer="report_views/archive_tavily_extract_0003_https_muni-dev.tistory.com_entry_Evolution-Strategie-9c07f789.html" data-raw="archive/tavily_extract/0003_https_muni-dev.tistory.com_entry_Evolution-Strategies-at-the-Hyperscale.txt" class="viewer-link">[4]</a></li>
</ul>
<h3>2) 수사적 과장 리스크: “가능성”을 “일반적 결론”으로 확대</h3>
<p>LinkedIn 포스트는 “미분/backprop 없이도 거대한 모델을 충분히 잘 훈련” 가능하다고 강하게 말한다 <a href="report_views/archive_tavily_extract_0001_https_www.linkedin.com_feed_update_urn_li_activity_7-c43d834b.html" data-viewer="report_views/archive_tavily_extract_0001_https_www.linkedin.com_feed_update_urn_li_activity_7-c43d834b.html" data-raw="archive/tavily_extract/0001_https_www.linkedin.com_feed_update_urn_li_activity_7399939023072358401.txt" class="viewer-link">[2]</a>. 초록이 제공하는 것은 특정 실험에서의 경쟁력/가능성 신호이며 <a href="report_views/archive_tavily_extract_0002_https_arxiv.org_abs_2511.16652.txt-ea7fa5eb.html" data-viewer="report_views/archive_tavily_extract_0002_https_arxiv.org_abs_2511.16652.txt-ea7fa5eb.html" data-raw="archive/tavily_extract/0002_https_arxiv.org_abs_2511.16652.txt" class="viewer-link">[1]</a>, 이를 넘어서는 일반화는 추가 근거가 필요하다.</p>
<h3>3) 내부 산출물(final.md)의 근거성 문제: “Community Adoption/비즈니스 적용”은 근거 부족</h3>
<p>아카이브 내부 산출물은 “Community Adoption: Early implementations … positive feedback”, “businesses can deploy …” 같은 문장을 포함하지만, 본 아카이브의 1차/2차 스냅샷에서 이를 직접 뒷받침하는 커뮤니티 반응 데이터나 사례는 확인되지 않는다 <a href="report_views/archive_20260113_linkedin-review-final.md-25459c4d.html" data-viewer="report_views/archive_20260113_linkedin-review-final.md-25459c4d.html" data-raw="archive/20260113_linkedin-review-final.md" class="viewer-link">[5]</a>. 이는 보고서 신뢰도를 떨어뜨릴 수 있으므로, 향후에는 (i) 출처 추가, 또는 (ii) 문장 강도 완화/삭제가 필요하다.</p>
<h3>4) 엔지니어링/안전·거버넌스 관점의 미기재</h3>
<p>현재 근거 텍스트들에는 (i) 분산 실행 시 실패/결함 허용성, (ii) RNG 재현의 보안·감사 가능성, (iii) 모델 안전성(예: RL/탐색 기반 학습에서의 예측 불가능성) 등 운영 관점 리스크가 직접 논의되지 않는다. 특히 대규모 병렬 탐색은 <strong>의도치 않은 행동/정책을 빠르게 증폭</strong>시킬 수 있어, 안전성 평가·추적성(로그/seed 관리) 설계가 중요하지만, 본 아카이브는 그 단서를 제공하지 않는다 <a href="report_views/archive_tavily_extract_0001_https_www.linkedin.com_feed_update_urn_li_activity_7-c43d834b.html" data-viewer="report_views/archive_tavily_extract_0001_https_www.linkedin.com_feed_update_urn_li_activity_7-c43d834b.html" data-raw="archive/tavily_extract/0001_https_www.linkedin.com_feed_update_urn_li_activity_7399939023072358401.txt" class="viewer-link">[2]</a>.</p>
<hr />
<h2>Critics</h2>
<h3>“ES의 귀환” 서사는 매력적이지만, 증거는 아직 ‘초록+해설’ 수준이다</h3>
<p>EGGROLL은 전통 ES의 구조적 병목($mn$ 섭동, batched matmul)을 $r(m+n)$로 바꾸는 간결한 아이디어로 큰 임팩트를 노린다 <a href="report_views/archive_tavily_extract_0002_https_arxiv.org_abs_2511.16652.txt-ea7fa5eb.html" data-viewer="report_views/archive_tavily_extract_0002_https_arxiv.org_abs_2511.16652.txt-ea7fa5eb.html" data-raw="archive/tavily_extract/0002_https_arxiv.org_abs_2511.16652.txt" class="viewer-link">[1]</a>. 그러나 현 아카이브에서는 본문 검증이 불가해, “hyperscale”이라는 단어가 요구하는 수준(수십~수백k population, 실제 클러스터 조건, 정량 효율)을 확정할 수 없다 <a href="report_views/archive_20260113_linkedin-review-index.md-ec349456.html" data-viewer="report_views/archive_20260113_linkedin-review-index.md-ec349456.html" data-raw="archive/20260113_linkedin-review-index.md" class="viewer-link">[3]</a>.</p>
<ul>
<li><strong>과장 가능성</strong>: LinkedIn의 “population 262,144”, “200배 이상”은 현 자료에서 교차검증되지 않는다 <a href="report_views/archive_tavily_extract_0001_https_www.linkedin.com_feed_update_urn_li_activity_7-c43d834b.html" data-viewer="report_views/archive_tavily_extract_0001_https_www.linkedin.com_feed_update_urn_li_activity_7-c43d834b.html" data-raw="archive/tavily_extract/0001_https_www.linkedin.com_feed_update_urn_li_activity_7399939023072358401.txt" class="viewer-link">[2]</a>.</li>
<li><strong>실무 적용의 숨은 비용</strong>: low-rank로 줄인 것은 “섭동 생성/적용”의 비용이지, 목적함수 평가 자체(환경 rollout, 데이터 로딩, 긴 컨텍스트 추론 등)의 비용까지 자동으로 사라지지 않는다(이는 본문 없이 확인 불가한 구조적 질문).</li>
<li><strong>안전/규제 시각</strong>: 대규모 탐색 기반 최적화는 행동 공간 탐색을 가속한다는 점에서, 모델의 예측가능성·설명가능성·감사 가능성 요구(예: 고위험 영역에서의 규제 대응)에 더 까다로운 요구를 만들 수 있다. 현재 스냅샷 근거는 이 부분을 다루지 않는다.</li>
</ul>
<hr />
<h2>Appendix</h2>
<h3>A. 아카이브 구성(검증 가능한 파일)</h3>
<ul>
<li>인덱스: <a href="report_views/archive_20260113_linkedin-review-index.md-ec349456.html" data-viewer="report_views/archive_20260113_linkedin-review-index.md-ec349456.html" data-raw="archive/20260113_linkedin-review-index.md" class="viewer-link">[3]</a> — URL 3개, Tavily Extract 3개만 존재, PDF 부재 정황 포함</li>
<li>1차 근거(텍스트 스냅샷)</li>
<li>LinkedIn: <a href="report_views/archive_tavily_extract_0001_https_www.linkedin.com_feed_update_urn_li_activity_7-c43d834b.html" data-viewer="report_views/archive_tavily_extract_0001_https_www.linkedin.com_feed_update_urn_li_activity_7-c43d834b.html" data-raw="archive/tavily_extract/0001_https_www.linkedin.com_feed_update_urn_li_activity_7399939023072358401.txt" class="viewer-link">[2]</a></li>
<li>arXiv abs: <a href="report_views/archive_tavily_extract_0002_https_arxiv.org_abs_2511.16652.txt-ea7fa5eb.html" data-viewer="report_views/archive_tavily_extract_0002_https_arxiv.org_abs_2511.16652.txt-ea7fa5eb.html" data-raw="archive/tavily_extract/0002_https_arxiv.org_abs_2511.16652.txt" class="viewer-link">[1]</a></li>
<li>Tistory: <a href="report_views/archive_tavily_extract_0003_https_muni-dev.tistory.com_entry_Evolution-Strategie-9c07f789.html" data-viewer="report_views/archive_tavily_extract_0003_https_muni-dev.tistory.com_entry_Evolution-Strategie-9c07f789.html" data-raw="archive/tavily_extract/0003_https_muni-dev.tistory.com_entry_Evolution-Strategies-at-the-Hyperscale.txt" class="viewer-link">[4]</a></li>
<li>내부 산출물(품질 점검 대상)</li>
<li><a href="report_views/archive_20260113_linkedin-review-final.md-25459c4d.html" data-viewer="report_views/archive_20260113_linkedin-review-final.md-25459c4d.html" data-raw="archive/20260113_linkedin-review-final.md" class="viewer-link">[5]</a> (및 final-v2~v5 동일 크기)</li>
<li><a href="report_views/archive_20260113_linkedin-review.md-29f5d440.html" data-viewer="report_views/archive_20260113_linkedin-review.md-29f5d440.html" data-raw="archive/20260113_linkedin-review.md" class="viewer-link">[7]</a></li>
</ul>
<h3>B. 추가 검증 To-Do(현 아카이브 밖에서만 가능)</h3>
<ul>
<li>arXiv PDF 본문(“48 pages, 12 figures”로 표기) 확보 후 실험 표/그림의 수치, $r$-성능 트레이드오프, population 규모와 하드웨어 조건을 확인 <a href="report_views/archive_tavily_extract_0002_https_arxiv.org_abs_2511.16652.txt-ea7fa5eb.html" data-viewer="report_views/archive_tavily_extract_0002_https_arxiv.org_abs_2511.16652.txt-ea7fa5eb.html" data-raw="archive/tavily_extract/0002_https_arxiv.org_abs_2511.16652.txt" class="viewer-link">[1]</a>.</li>
<li>코드/재현(eshyperscale) 아카이브 수집 후:</li>
<li>counter-based RNG 설계와 분산 동기화 방식(재현성/결함 허용성)</li>
<li>실제 통신량(gradient-free라도 fitness 집계/정렬 등에서 발생하는 통신) 측정</li>
<li>LinkedIn 주장 수치(262,144, 200x)의 정의를 원문(논문/웹사이트)에서 확인하고, 동일 조건에서의 비교 기준을 명시적으로 정리 <a href="report_views/archive_tavily_extract_0001_https_www.linkedin.com_feed_update_urn_li_activity_7-c43d834b.html" data-viewer="report_views/archive_tavily_extract_0001_https_www.linkedin.com_feed_update_urn_li_activity_7-c43d834b.html" data-raw="archive/tavily_extract/0001_https_www.linkedin.com_feed_update_urn_li_activity_7399939023072358401.txt" class="viewer-link">[2]</a>.</li>
</ul>
<h2>References</h2>
<ol>
<li>0002_https_arxiv.org_abs_2511.16652.txt — <a href="report_views/archive_tavily_extract_0002_https_arxiv.org_abs_2511.16652.txt-ea7fa5eb.html" data-viewer="report_views/archive_tavily_extract_0002_https_arxiv.org_abs_2511.16652.txt-ea7fa5eb.html" data-raw="archive/tavily_extract/0002_https_arxiv.org_abs_2511.16652.txt" class="viewer-link">file</a></li>
<li>0001_https_www.linkedin.com_feed_update_urn_li_activity_7399939023072358401.txt — <a href="report_views/archive_tavily_extract_0001_https_www.linkedin.com_feed_update_urn_li_activity_7-c43d834b.html" data-viewer="report_views/archive_tavily_extract_0001_https_www.linkedin.com_feed_update_urn_li_activity_7-c43d834b.html" data-raw="archive/tavily_extract/0001_https_www.linkedin.com_feed_update_urn_li_activity_7399939023072358401.txt" class="viewer-link">file</a></li>
<li>20260113_linkedin-review-index.md — <a href="report_views/archive_20260113_linkedin-review-index.md-ec349456.html" data-viewer="report_views/archive_20260113_linkedin-review-index.md-ec349456.html" data-raw="archive/20260113_linkedin-review-index.md" class="viewer-link">file</a></li>
<li>0003_https_muni-dev.tistory.com_entry_Evolution-Strategies-at-the-Hyperscale.txt — <a href="report_views/archive_tavily_extract_0003_https_muni-dev.tistory.com_entry_Evolution-Strategie-9c07f789.html" data-viewer="report_views/archive_tavily_extract_0003_https_muni-dev.tistory.com_entry_Evolution-Strategie-9c07f789.html" data-raw="archive/tavily_extract/0003_https_muni-dev.tistory.com_entry_Evolution-Strategies-at-the-Hyperscale.txt" class="viewer-link">file</a></li>
<li>20260113_linkedin-review-final.md — <a href="report_views/archive_20260113_linkedin-review-final.md-25459c4d.html" data-viewer="report_views/archive_20260113_linkedin-review-final.md-25459c4d.html" data-raw="archive/20260113_linkedin-review-final.md" class="viewer-link">file</a></li>
<li>0001_https_www.linkedin.com_feed_update_urn_li_activity_7399939023072358401.txt].<br />
이 관점은 “표현력(업데이트 랭크 — [file](<a href=".&lt;a href=" . archive tavily_extract 0001_https_www.linkedin.com_feed_update_urn_li_activity_7399939023072358401.txt">/archive/tavily_extract/0001_https_www.linkedin.com_feed_update_urn_li_activity_7399939023072358401.txt</a>">.<a href="report_views/archive_tavily_extract_0001_https_www.linkedin.com_feed_update_urn_li_activity_7-c43d834b.html" data-viewer="report_views/archive_tavily_extract_0001_https_www.linkedin.com_feed_update_urn_li_activity_7-c43d834b.html" data-raw="archive/tavily_extract/0001_https_www.linkedin.com_feed_update_urn_li_activity_7399939023072358401.txt" class="viewer-link">/archive/tavily_extract/0001_https_www.linkedin.com_feed_update_urn_li_activity_7399939023072358401.txt</a></a>].<br />
이 관점은 “표현력(업데이트 랭크)</li>
<li>20260113_linkedin-review.md — <a href="report_views/archive_20260113_linkedin-review.md-29f5d440.html" data-viewer="report_views/archive_20260113_linkedin-review.md-29f5d440.html" data-raw="archive/20260113_linkedin-review.md" class="viewer-link">file</a></li>
</ol>
<h2>Miscellaneous</h2>
<div class="misc-block">
<ul>
<li>Generated at: 2026-01-16 00:55:53</li>
<li>Duration: 00:05:14 (314.94s)</li>
<li>Model: gpt-5.2</li>
<li>Quality strategy: none</li>
<li>Quality iterations: 0</li>
<li>Template: default</li>
<li>Output format: html</li>
<li>PDF compile: disabled</li>
<li>Run overview: <a href="report_views/report_run_overview.md-40ef65a9.html" data-viewer="report_views/report_run_overview.md-40ef65a9.html" data-raw="report/run_overview.md" class="viewer-link">./report/run_overview.md</a></li>
<li>Archive index: <a href="report_views/archive_20260113_linkedin-review-index.md-ec349456.html" data-viewer="report_views/archive_20260113_linkedin-review-index.md-ec349456.html" data-raw="archive/20260113_linkedin-review-index.md" class="viewer-link">./archive/20260113_linkedin-review-index.md</a></li>
<li>Instruction file: <a href="report_views/instruction_20260113_linkedin-review.txt-561509f8.html" data-viewer="report_views/instruction_20260113_linkedin-review.txt-561509f8.html" data-raw="instruction/20260113_linkedin-review.txt" class="viewer-link">./instruction/20260113_linkedin-review.txt</a></li>
</ul>
</div>
    </main>
  </div>
  <div id="viewer-overlay" class="viewer-overlay"></div>
  <aside id="viewer-panel" class="viewer-panel" aria-hidden="true">
    <div class="viewer-header">
      <div class="viewer-title" id="viewer-title">Source preview</div>
      <div class="viewer-actions">
        <a id="viewer-raw" href="#" target="_blank" rel="noopener">Open raw</a>
        <button class="viewer-close" id="viewer-close" aria-label="Close">x</button>
      </div>
    </div>
    <iframe id="viewer-frame" class="viewer-frame" title="Source preview"></iframe>
  </aside>
  <script>
    (function() {
      const panel = document.getElementById('viewer-panel');
      const overlay = document.getElementById('viewer-overlay');
      const frame = document.getElementById('viewer-frame');
      const rawLink = document.getElementById('viewer-raw');
      const title = document.getElementById('viewer-title');
      const closeBtn = document.getElementById('viewer-close');
      function closeViewer() {
        panel.classList.remove('open');
        overlay.classList.remove('open');
        panel.setAttribute('aria-hidden', 'true');
        frame.src = 'about:blank';
      }
      function openViewer(viewer, raw, label) {
        frame.src = viewer;
        rawLink.href = raw || viewer;
        title.textContent = label || 'Source preview';
        panel.classList.add('open');
        overlay.classList.add('open');
        panel.setAttribute('aria-hidden', 'false');
      }
      document.querySelectorAll('a').forEach((link) => {
        const href = link.getAttribute('href') || '';
        if (href.startsWith('http://') || href.startsWith('https://')) {
          link.setAttribute('target', '_blank');
          link.setAttribute('rel', 'noopener');
        }
        const viewer = link.getAttribute('data-viewer');
        if (viewer) {
          link.addEventListener('click', (event) => {
            if (event.metaKey || event.ctrlKey) { return; }
            event.preventDefault();
            openViewer(viewer, link.getAttribute('data-raw'), link.textContent.trim());
          });
        }
      });
      overlay.addEventListener('click', closeViewer);
      closeBtn.addEventListener('click', closeViewer);
      document.addEventListener('keydown', (event) => {
        if (event.key === 'Escape') { closeViewer(); }
      });
    })();
  </script>
</body>
</html>
