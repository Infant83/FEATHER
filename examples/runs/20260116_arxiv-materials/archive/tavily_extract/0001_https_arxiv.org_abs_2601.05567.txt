{
  "results": [
    {
      "url": "https://arxiv.org/abs/2601.05567",
      "title": "[2601.05567] WildSci: Advancing Scientific Reasoning from In-the-Wild Literature",
      "raw_content": "We gratefully acknowledge support from the Simons Foundation, [member institutions](https://info.arxiv.org/about/ourmembers.html), and all contributors. [Donate](https://info.arxiv.org/about/donate.html)\n\n> [cs](/list/cs/recent) > arXiv:2601.05567\n\n\n\n# Computer Science > Artificial Intelligence\n\n**arXiv:2601.05567** (cs)\n\n[Submitted on 9 Jan 2026]\n\n# Title:WildSci: Advancing Scientific Reasoning from In-the-Wild Literature\n\nAuthors:[Tengxiao Liu](https://arxiv.org/search/cs?searchtype=author&query=Liu,+T), [Deepak Nathani](https://arxiv.org/search/cs?searchtype=author&query=Nathani,+D), [Zekun Li](https://arxiv.org/search/cs?searchtype=author&query=Li,+Z), [Kevin Yang](https://arxiv.org/search/cs?searchtype=author&query=Yang,+K), [William Yang Wang](https://arxiv.org/search/cs?searchtype=author&query=Wang,+W+Y)\n\nView a PDF of the paper titled WildSci: Advancing Scientific Reasoning from In-the-Wild Literature, by Tengxiao Liu and 4 other authors\n\n[View PDF](/pdf/2601.05567) [HTML (experimental)](https://arxiv.org/html/2601.05567v1)\n> Abstract:Recent progress in large language model (LLM) reasoning has focused on domains like mathematics and coding, where abundant high-quality data and objective evaluation metrics are readily available. In contrast, progress in LLM reasoning models remains limited in scientific domains such as medicine and materials science due to limited dataset coverage and the inherent complexity of open-ended scientific questions. To address these challenges, we introduce WildSci, a new dataset of domain-specific science questions automatically synthesized from peer-reviewed literature, covering 9 scientific disciplines and 26 subdomains. By framing complex scientific reasoning tasks in a multiple-choice format, we enable scalable training with well-defined reward signals. We further apply reinforcement learning to finetune models on these data and analyze the resulting training dynamics, including domain-specific performance changes, response behaviors, and generalization trends. Experiments on a suite of scientific benchmarks demonstrate the effectiveness of our dataset and approach. We release WildSci to enable scalable and sustainable research in scientific reasoning, available at [this https URL](https://huggingface.co/datasets/JustinTX/WildSci).\n\n|  |  |\n| --- | --- |\n| Subjects: | Artificial Intelligence (cs.AI); Computation and Language (cs.CL) |\n| Cite as: | [arXiv:2601.05567](https://arxiv.org/abs/2601.05567) [cs.AI] |\n|  | (or  [arXiv:2601.05567v1](https://arxiv.org/abs/2601.05567v1) [cs.AI] for this version) |\n|  | <https://doi.org/10.48550/arXiv.2601.05567> arXiv-issued DOI via DataCite (pending registration) |\n\n## Submission history\n\nFrom: Tengxiao Liu [[view email](/show-email/28b72215/2601.05567)]   \n **[v1]** Fri, 9 Jan 2026 06:35:23 UTC (637 KB)\n\nFull-text links:\n\n## Access Paper:\n\nView a PDF of the paper titled WildSci: Advancing Scientific Reasoning from In-the-Wild Literature, by Tengxiao Liu and 4 other authors\n\n* [View PDF](/pdf/2601.05567)\n* [HTML (experimental)](https://arxiv.org/html/2601.05567v1)\n* [TeX Source](/src/2601.05567)\n\n[view license](http://arxiv.org/licenses/nonexclusive-distrib/1.0/ \"Rights to this article\")\n\nCurrent browse context:\n\ncs.AI\n\n[< prev](/prevnext?id=2601.05567&function=prev&context=cs.AI \"previous in cs.AI (accesskey p)\")    |    [next >](/prevnext?id=2601.05567&function=next&context=cs.AI \"next in cs.AI (accesskey n)\")\n\n[new](/list/cs.AI/new)  |  [recent](/list/cs.AI/recent)  | [2026-01](/list/cs.AI/2026-01)\n\nChange to browse by:\n\n[cs](/abs/2601.05567?context=cs)  \n [cs.CL](/abs/2601.05567?context=cs.CL)\n\n### References & Citations\n\n* [NASA ADS](https://ui.adsabs.harvard.edu/abs/arXiv:2601.05567)\n* [Google Scholar](https://scholar.google.com/scholar_lookup?arxiv_id=2601.05567)\n* [Semantic Scholar](https://api.semanticscholar.org/arXiv:2601.05567)\n\nexport BibTeX citation Loading...\n\n## BibTeX formatted citation\n\n×\n\nData provided by:\n\n### Bookmark\n\n# Bibliographic and Citation Tools\n\nBibliographic Explorer *([What is the Explorer?](https://info.arxiv.org/labs/showcase.html#arxiv-bibliographic-explorer))*\n\nConnected Papers *([What is Connected Papers?](https://www.connectedpapers.com/about))*\n\nLitmaps *([What is Litmaps?](https://www.litmaps.co/))*\n\nscite Smart Citations *([What are Smart Citations?](https://www.scite.ai/))*\n\n# Code, Data and Media Associated with this Article\n\nalphaXiv *([What is alphaXiv?](https://alphaxiv.org/))*\n\nCatalyzeX Code Finder for Papers *([What is CatalyzeX?](https://www.catalyzex.com))*\n\nDagsHub *([What is DagsHub?](https://dagshub.com/))*\n\nGotit.pub *([What is GotitPub?](http://gotit.pub/faq))*\n\nHugging Face *([What is Huggingface?](https://huggingface.co/huggingface))*\n\nPapers with Code *([What is Papers with Code?](https://paperswithcode.com/))*\n\nScienceCast *([What is ScienceCast?](https://sciencecast.org/welcome))*\n\n# Demos\n\nReplicate *([What is Replicate?](https://replicate.com/docs/arxiv/about))*\n\nHugging Face Spaces *([What is Spaces?](https://huggingface.co/docs/hub/spaces))*\n\nTXYZ.AI *([What is TXYZ.AI?](https://txyz.ai))*\n\n# Recommenders and Search Tools\n\nInfluence Flower *([What are Influence Flowers?](https://influencemap.cmlab.dev/))*\n\nCORE Recommender *([What is CORE?](https://core.ac.uk/services/recommender))*\n\n* Author\n* Venue\n* Institution\n* Topic\n\n# arXivLabs: experimental projects with community collaborators\n\narXivLabs is a framework that allows collaborators to develop and share new arXiv features directly on our website.\n\nBoth individuals and organizations that work with arXivLabs have embraced and accepted our values of openness, community, excellence, and user data privacy. arXiv is committed to these values and only works with partners that adhere to them.\n\nHave an idea for a project that will add value for arXiv's community? [**Learn more about arXivLabs**](https://info.arxiv.org/labs/index.html).\n\n[Which authors of this paper are endorsers?](/auth/show-endorsers/2601.05567) | [Disable MathJax](javascript:setMathjaxCookie()) ([What is MathJax?](https://info.arxiv.org/help/mathjax.html))",
      "images": []
    }
  ],
  "failed_results": [],
  "response_time": 0.01,
  "request_id": "a4cbd854-7b18-4611-be87-c8fa718356f5"
}