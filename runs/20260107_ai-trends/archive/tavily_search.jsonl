{"query": "AI trends 2025 (English)", "result": {"query": "AI trends 2025 (English)", "follow_up_questions": null, "answer": null, "images": [], "results": [{"url": "https://www.uptech.team/blog/ai-trends-2025", "title": "7 AI Trends for 2025 That Businesses Should Follow - Uptech Team", "content": "## Global Momentum, Local Challenges, and Other AI Future Trends\n\nPublic and government engagement with AI is getting bigger. According to Stanford’s 2025 AI Index Report, in countries like China (83%), Indonesia (80%), and Thailand (77%), most people already see AI products and services as more beneficial than harmful. While skepticism remains in places like the U.S. (39%) and Canada (40%), sentiment is changing: Optimism has grown significantly across Germany, France, Great Britain, and others since 2022.\n\nGovernments have their responses, too. In 2024, U.S. federal agencies introduced 59 AI-related regulations, more than double the number from the previous year. Globally, legislative mentions of AI rose 21.3% across 75 countries, alongside record levels of public investment: from Canada’s $2.4B AI strategy to Saudi Arabia’s $100B Project Transcendence. [...] ## AI Trend 6: AI Moves from Cloud to Device\n\nCloud has been the norm for years. It made high-performance AI accessible, but also introduced real trade-offs around latency, cost, and privacy. That’s why the shift toward on-device AI is one of the latest developments in AI and most meaningful hardware-driven trends in 2025.\n\nThis change is no longer theoretical. It’s happening.\n\nWith the launch of Snapdragon X Elite, Microsoft’s Copilot+ PC line, and Apple Intelligence, AI workloads are now running directly on laptops and mobile devices. These devices ship with integrated NPUs (Neural Processing Units) that can run language models with over 13 billion parameters and generate responses in real time, all without touching the cloud. [...] Read full bio\n\nArtificial intelligence has moved past the hype stage. Across industries, we’re seeing real adoption, measurable value, and rapid evolution. In 2025, AI trends will play an even bigger role as companies shift from testing ideas to scaling real solutions.\n\nAccording to McKinsey, more than 75% of organizations already use AI in at least one business function, and the use of generative AI is accelerating faster than any previous technology wave. From the latest AI advancements in automation to emerging agent-based systems, businesses are paying close attention to what’s new in AI and how to make it work in practice.\n\nI’m Oleh Komenchuk, an ML Department Lead at Uptech. Together with my team, I’ve outlined the top 7 AI trends for 2025 that we believe will shape the future of business and technology, and show where the real value lies.\n\nLet’s dive in.", "score": 0.89545894, "raw_content": null, "summary": "According to McKinsey, more than 75% of organizations already use AI in at least one business function, and the use of generative AI is accelerating faster than any previous technology wave. From the latest AI advancements in automation to emerging agent-based systems, businesses are paying close attention to what’s new in AI and how to make it work in practice."}, {"url": "https://aimagazine.com/articles/top-10-ai-predictions-for-2025", "title": "Top 10 AI Predictions for 2025 - AI Magazine", "content": "## 1. AI-augmented workspaces\n\nThe contemporary workplace is experiencing a profound transformation as AI becomes an integral collaborator rather than a mere technological tool. Companies are increasingly deploying AI systems that enhance human productivity, decision-making, and creative capabilities across multiple professional domains. These AI-augmented workspaces are not about replacement, but strategic amplification of human potential.\n\nLeading technology firms are pioneering approaches where AI acts as an intelligent assistant, handling repetitive administrative tasks and providing sophisticated analytical insights. Microsoft's GitHub Copilot, for instance, demonstrates how AI can generate code suggestions in real-time, reducing developer workload and accelerating software development cycles. Similarly, consultancy firms like Deloitte are implementing AI-driven research platforms that can synthesise complex information sets in minutes, enabling consultants to focus on high-value strategic interpretation. [...] ## 8. Responsible AI\n\nResponsible AI represents a critical evolution in technological development, focusing on creating artificial intelligence systems that prioritise ethical considerations and human-centric design. Microsoft's pioneering Responsible AI Standard establishes a comprehensive framework built on six fundamental principles: fairness, reliability, safety, privacy, security, inclusiveness, transparency, and accountability.\n\nThe implementation of responsible AI practices spans multiple industries, demonstrating tangible benefits in sectors ranging from healthcare to financial services. For instance, FICO's credit scoring system exemplifies responsible AI by regularly auditing its algorithms to eliminate potential biases, ensuring equitable assessment of creditworthiness. Similarly, IBM's watsonx Orchestrate platform revolutionises talent acquisition by promoting unbiased candidate selection through diverse candidate pools, highlighting how ethical AI can transform traditional processes. [...] Emerging trends in responsible AI, such as explainable AI (XAI) and dedicated ethics training programmes, are reshaping technological development. These innovations aim to enhance system transparency, build user trust, and ensure that AI technologies remain accountable. By embedding ethical considerations into AI governance, organisations can develop intelligent systems that not only drive efficiency but also respect fundamental human values and societal norms.\n\n## 7. Generative Video AI\n\nGenerative video AI represents a groundbreaking technological advancement in digital content creation, enabling sophisticated video generation through complex computational processes. The technology harnesses deep learning techniques and neural networks to transform textual prompts into coherent, visually compelling video sequences.", "score": 0.8865877, "raw_content": null, "summary": "Responsible AI Responsible AI represents a critical evolution in technological development, focusing on creating artificial intelligence systems that prioritise ethical considerations and human-centric design. [...] Emerging trends in responsible AI, such as explainable AI (XAI) and dedicated ethics training programmes, are reshaping technological development."}, {"url": "https://news.microsoft.com/source/features/ai/6-ai-trends-youll-see-more-of-in-2025/", "title": "6 AI trends you'll see more of in 2025 - Microsoft Source", "content": "And AI’s impact on science will continue to grow.\n\nOne of the most exciting things to watch in 2025 will be how AI’s use in scientific research fuels progress in addressing some of the world’s most pressing concerns, says Ashley Llorens, corporate vice president and managing director at Microsoft Research.\n\n“We’ll start to see these tools having a measurable impact on the throughput of the people and institutions who are working on these huge problems, such as designing sustainable materials and accelerating development of life-saving drugs,” Llorens says.\n\nIn 2025, one trend is certain: AI will continue to drive innovation and unlock new potential for people and organizations around the globe.\n\n_Illustrations by Michał Bednarski / Makeshift Studios. Story published on Dec 5, 2024._\n\n#### Tags:\n\n   AI\n   Technology\n   Work & Life\n\nWhat's new [...] Image 4\n\nAI models will become more capable and useful\n\nOver the past year, AI models became faster and more efficient. Today, large-scale “frontier models” can complete a broad range of tasks from writing to coding, and highly specialized models can be tailored for specific tasks or industries.\n\nIn 2025, models will do more — and do it even better.\n\nModels with advanced reasoning capabilities, like OpenAI o1, can already solve complex problems with logical steps that are similar to how humans think before responding to difficult questions. These capabilities will continue to be useful in fields like science, coding, math, law and medicine, allowing models to compare contracts, generate code and execute multistep workflows.\n\nThese advancements will be important in model innovation, but so will progress in data curation and post-training. For example, Microsoft’s family of small Phi models showed that curating high-quality data can improve model performance and reasoning. [...] This progress will be driven by advancements in AI’s ability to remember more and reason better, among other innovations. And Microsoft will remain grounded in its commitment to help people use and build AI that is safe and secure.\n\n“AI is already making the impossible feel possible, and over the past year we’ve seen significant numbers of people and organizations moving from AI experimentation to more meaningful adoption,” says Chris Young, executive vice president of business development, strategy and ventures at Microsoft. “This is the start of a full-scale transformation of how this technology will change every part of our lives.”\n\nIn the last year alone, generative AI usage jumped from 55% to 75% among business leaders and AI decisionmakers. New AI tools will bring even more potential.\n\nWant to know what’s ahead? Here are six AI trends to watch — and how Microsoft will innovate on each — in 2025.\n\nImage 4\n\nAI models will become more capable and useful", "score": 0.87981987, "raw_content": null, "summary": "One of the most exciting things to watch in 2025 will be how AI’s use in scientific research fuels progress in addressing some of the world’s most pressing concerns, says Ashley Llorens, corporate vice president and managing director at Microsoft Research. “AI is already making the impossible feel possible, and over the past year we’ve seen significant numbers of people and organizations moving fr"}, {"url": "https://www.mckinsey.com/capabilities/tech-and-ai/our-insights/the-top-trends-in-tech", "title": "McKinsey technology trends outlook 2025", "content": "This outlook highlights transformative trends that are driving innovation and addressing critical challenges across sectors. Artificial intelligence stands out not only as a powerful technology wave on its own but also as a foundational amplifier of the other trends. Its impact increasingly occurs via a combination with other trends, as AI both accelerates progress within individual domains and unlocks new possibilities at the intersections—accelerating the training of robots, advancing scientific discoveries in bioengineering, optimizing energy systems, and much more. The evolution of AI solutions in the marketplace increasingly combines aspects of trends we previously analyzed separately as applied AI and generative AI, so this year, they are examined together.\n\nEven as excitement about AI applications and their use cases builds, realizing AI’s full potential across sectors will require continued innovations to manage computing intensity, reduce deployment costs, and drive infrastructure investment. This will also demand thoughtful approaches to safety, governance, and workforce adaptation, creating a wide range of opportunities for industry leaders, policymakers, and entrepreneurs alike.\n\n. [...] In addition, we updated the selection and definition of trends from last year’s report to reflect the evolution of technology trends:\n\n   An overarching artificial intelligence category replaces these four trends: applied AI, generative AI, industrializing machine learning, and next-generation software development.\n   The agentic AI and application-specific semiconductors trends have been added since last year’s publication.\n   Two separate trends from last year, electrification and renewables and climate technologies beyond electrification, have been combined into a single trend: future of energy and sustainability technologies.\n\nThe data sources and keywords have been updated. For equity investment insights into the future of space technologies and quantum technologies, we built on research from McKinsey’s Aerospace & Defense Practice and the Quantum Technology Monitor.\n\nInsights gathered from McKinsey expert interviews were utilized to assign enterprise-wide adoption scores (on a 1–5 scale) for each trend, defined as follows:", "score": 0.8740022, "raw_content": null, "summary": "The evolution of AI solutions in the marketplace increasingly combines aspects of trends we previously analyzed separately as applied AI and generative AI, so this year, they are examined together. [...] In addition, we updated the selection and definition of trends from last year’s report to reflect the evolution of technology trends: An overarching artificial intelligence category replaces these"}, {"url": "https://blogs.cisco.com/partner/six-ai-predictions-for-2025-that-will-reshape-how-we-think-about-enterprise-technology", "title": "Six AI Predictions For 2025 That Will Reshape How We Think About ...", "content": "## 1. Right-sized AI for real-world impact\n\nIn 2025, organizations will fundamentally shift away from massive GPU clusters toward targeted, efficient AI solutions as the true costs of large language models become unsustainable. With training costs ranging from $4.6M to $12M per run and requiring thousands of high-end GPUs, companies will embrace smaller, specialized models that offer better control, compliance, and cost efficiency. This shift isn’t just about technology—it’s about aligning AI with business reality and regulatory frameworks. As organizations become increasingly dissatisfied with the accuracy and confidence levels of general-purpose models, they will turn to bespoke language models optimized for specific business outcomes. Success will be measured by how effectively these precision AI investments drive tangible business transformation, not by the size of the deployment or the scale of the model.\n\n## 2. Data security and observability become AI’s foundation. [...] ## 5. Partner ecosystems become AI’s force multiplier.\n\nThe complexity of AI operations and scarcity of talent will make partnerships the cornerstone of successful AI deployment in 2025. Even technology-rich enterprises will struggle to maintain dedicated AI expertise, driving a new era of strategic collaboration. Partner business models will evolve dramatically as traditional boundaries blur—MSPs will expand into development and integration, resellers will build managed service practices, and integrators will create their own IP. The most successful organizations will be those that embrace this fluidity, leveraging APIs and cloud-native architectures to deliver value through multiple channels. These fluid partnerships will pioneer scalable innovation models that rapidly adapt across markets, with success measured by their ability to orchestrate diverse capabilities into tangible business impact.\n\n## 6. We are entering an era of accelerated re-skilling. [...] The explosive growth of AI is creating unprecedented pressure on data center sustainability. For example, Elon Musk’s artificial intelligence company, xAI, will be the world’s largest supercomputer facility in Memphis, TN. With each ChatGPT query consuming nearly 10 times the electricity of a Google search, organizations are facing a critical inflection point. Goldman Sachs projects that data center power demand will surge 160% by 2030, while Morgan Stanley forecasts that data center emissions will reach 2.5 billion metric tons of CO2 equivalent in the same timeframe. This collision between AI’s energy appetite and sustainability imperatives will drive radical innovation in 2025. We’ll see cutting-edge technologies like direct-to-chip cooling and liquid immersion alongside innovative approaches like harnessing ocean currents and strategically placing data centers near renewable energy sources. The future won’t be about more data centers, but about fewer, more powerful facilities designed with sustainability at their core.", "score": 0.8737439, "raw_content": null, "summary": "Success will be measured by how effectively these precision AI investments drive tangible business transformation, not by the size of the deployment or the scale of the model. The complexity of AI operations and scarcity of talent will make partnerships the cornerstone of successful AI deployment in 2025."}], "response_time": 1.46, "request_id": "983a8ce9-23a0-4517-8ab8-18f2b4be1a86"}, "query_summary": "One of the most exciting things to watch in 2025 will be how AI’s use in scientific research fuels progress in addressing some of the world’s most pressing concerns, says Ashley Llorens, corporate vice president and managing director at Microsoft Research. “AI is already making the impossible feel possible, and over the past year we’ve seen significant numbers of people and organizations moving fr The evolution of AI solutions in the marketplace increasingly combines aspects of trends we previously analyzed separately as applied AI and generative AI, so this year, they are examined together. [", "lang_pref": "en", "preferred_results": [{"url": "https://www.uptech.team/blog/ai-trends-2025", "title": "7 AI Trends for 2025 That Businesses Should Follow - Uptech Team", "content": "## Global Momentum, Local Challenges, and Other AI Future Trends\n\nPublic and government engagement with AI is getting bigger. According to Stanford’s 2025 AI Index Report, in countries like China (83%), Indonesia (80%), and Thailand (77%), most people already see AI products and services as more beneficial than harmful. While skepticism remains in places like the U.S. (39%) and Canada (40%), sentiment is changing: Optimism has grown significantly across Germany, France, Great Britain, and others since 2022.\n\nGovernments have their responses, too. In 2024, U.S. federal agencies introduced 59 AI-related regulations, more than double the number from the previous year. Globally, legislative mentions of AI rose 21.3% across 75 countries, alongside record levels of public investment: from Canada’s $2.4B AI strategy to Saudi Arabia’s $100B Project Transcendence. [...] ## AI Trend 6: AI Moves from Cloud to Device\n\nCloud has been the norm for years. It made high-performance AI accessible, but also introduced real trade-offs around latency, cost, and privacy. That’s why the shift toward on-device AI is one of the latest developments in AI and most meaningful hardware-driven trends in 2025.\n\nThis change is no longer theoretical. It’s happening.\n\nWith the launch of Snapdragon X Elite, Microsoft’s Copilot+ PC line, and Apple Intelligence, AI workloads are now running directly on laptops and mobile devices. These devices ship with integrated NPUs (Neural Processing Units) that can run language models with over 13 billion parameters and generate responses in real time, all without touching the cloud. [...] Read full bio\n\nArtificial intelligence has moved past the hype stage. Across industries, we’re seeing real adoption, measurable value, and rapid evolution. In 2025, AI trends will play an even bigger role as companies shift from testing ideas to scaling real solutions.\n\nAccording to McKinsey, more than 75% of organizations already use AI in at least one business function, and the use of generative AI is accelerating faster than any previous technology wave. From the latest AI advancements in automation to emerging agent-based systems, businesses are paying close attention to what’s new in AI and how to make it work in practice.\n\nI’m Oleh Komenchuk, an ML Department Lead at Uptech. Together with my team, I’ve outlined the top 7 AI trends for 2025 that we believe will shape the future of business and technology, and show where the real value lies.\n\nLet’s dive in.", "score": 0.89545894, "raw_content": null, "summary": "According to McKinsey, more than 75% of organizations already use AI in at least one business function, and the use of generative AI is accelerating faster than any previous technology wave. From the latest AI advancements in automation to emerging agent-based systems, businesses are paying close attention to what’s new in AI and how to make it work in practice."}, {"url": "https://aimagazine.com/articles/top-10-ai-predictions-for-2025", "title": "Top 10 AI Predictions for 2025 - AI Magazine", "content": "## 1. AI-augmented workspaces\n\nThe contemporary workplace is experiencing a profound transformation as AI becomes an integral collaborator rather than a mere technological tool. Companies are increasingly deploying AI systems that enhance human productivity, decision-making, and creative capabilities across multiple professional domains. These AI-augmented workspaces are not about replacement, but strategic amplification of human potential.\n\nLeading technology firms are pioneering approaches where AI acts as an intelligent assistant, handling repetitive administrative tasks and providing sophisticated analytical insights. Microsoft's GitHub Copilot, for instance, demonstrates how AI can generate code suggestions in real-time, reducing developer workload and accelerating software development cycles. Similarly, consultancy firms like Deloitte are implementing AI-driven research platforms that can synthesise complex information sets in minutes, enabling consultants to focus on high-value strategic interpretation. [...] ## 8. Responsible AI\n\nResponsible AI represents a critical evolution in technological development, focusing on creating artificial intelligence systems that prioritise ethical considerations and human-centric design. Microsoft's pioneering Responsible AI Standard establishes a comprehensive framework built on six fundamental principles: fairness, reliability, safety, privacy, security, inclusiveness, transparency, and accountability.\n\nThe implementation of responsible AI practices spans multiple industries, demonstrating tangible benefits in sectors ranging from healthcare to financial services. For instance, FICO's credit scoring system exemplifies responsible AI by regularly auditing its algorithms to eliminate potential biases, ensuring equitable assessment of creditworthiness. Similarly, IBM's watsonx Orchestrate platform revolutionises talent acquisition by promoting unbiased candidate selection through diverse candidate pools, highlighting how ethical AI can transform traditional processes. [...] Emerging trends in responsible AI, such as explainable AI (XAI) and dedicated ethics training programmes, are reshaping technological development. These innovations aim to enhance system transparency, build user trust, and ensure that AI technologies remain accountable. By embedding ethical considerations into AI governance, organisations can develop intelligent systems that not only drive efficiency but also respect fundamental human values and societal norms.\n\n## 7. Generative Video AI\n\nGenerative video AI represents a groundbreaking technological advancement in digital content creation, enabling sophisticated video generation through complex computational processes. The technology harnesses deep learning techniques and neural networks to transform textual prompts into coherent, visually compelling video sequences.", "score": 0.8865877, "raw_content": null, "summary": "Responsible AI Responsible AI represents a critical evolution in technological development, focusing on creating artificial intelligence systems that prioritise ethical considerations and human-centric design. [...] Emerging trends in responsible AI, such as explainable AI (XAI) and dedicated ethics training programmes, are reshaping technological development."}, {"url": "https://news.microsoft.com/source/features/ai/6-ai-trends-youll-see-more-of-in-2025/", "title": "6 AI trends you'll see more of in 2025 - Microsoft Source", "content": "And AI’s impact on science will continue to grow.\n\nOne of the most exciting things to watch in 2025 will be how AI’s use in scientific research fuels progress in addressing some of the world’s most pressing concerns, says Ashley Llorens, corporate vice president and managing director at Microsoft Research.\n\n“We’ll start to see these tools having a measurable impact on the throughput of the people and institutions who are working on these huge problems, such as designing sustainable materials and accelerating development of life-saving drugs,” Llorens says.\n\nIn 2025, one trend is certain: AI will continue to drive innovation and unlock new potential for people and organizations around the globe.\n\n_Illustrations by Michał Bednarski / Makeshift Studios. Story published on Dec 5, 2024._\n\n#### Tags:\n\n   AI\n   Technology\n   Work & Life\n\nWhat's new [...] Image 4\n\nAI models will become more capable and useful\n\nOver the past year, AI models became faster and more efficient. Today, large-scale “frontier models” can complete a broad range of tasks from writing to coding, and highly specialized models can be tailored for specific tasks or industries.\n\nIn 2025, models will do more — and do it even better.\n\nModels with advanced reasoning capabilities, like OpenAI o1, can already solve complex problems with logical steps that are similar to how humans think before responding to difficult questions. These capabilities will continue to be useful in fields like science, coding, math, law and medicine, allowing models to compare contracts, generate code and execute multistep workflows.\n\nThese advancements will be important in model innovation, but so will progress in data curation and post-training. For example, Microsoft’s family of small Phi models showed that curating high-quality data can improve model performance and reasoning. [...] This progress will be driven by advancements in AI’s ability to remember more and reason better, among other innovations. And Microsoft will remain grounded in its commitment to help people use and build AI that is safe and secure.\n\n“AI is already making the impossible feel possible, and over the past year we’ve seen significant numbers of people and organizations moving from AI experimentation to more meaningful adoption,” says Chris Young, executive vice president of business development, strategy and ventures at Microsoft. “This is the start of a full-scale transformation of how this technology will change every part of our lives.”\n\nIn the last year alone, generative AI usage jumped from 55% to 75% among business leaders and AI decisionmakers. New AI tools will bring even more potential.\n\nWant to know what’s ahead? Here are six AI trends to watch — and how Microsoft will innovate on each — in 2025.\n\nImage 4\n\nAI models will become more capable and useful", "score": 0.87981987, "raw_content": null, "summary": "One of the most exciting things to watch in 2025 will be how AI’s use in scientific research fuels progress in addressing some of the world’s most pressing concerns, says Ashley Llorens, corporate vice president and managing director at Microsoft Research. “AI is already making the impossible feel possible, and over the past year we’ve seen significant numbers of people and organizations moving fr"}, {"url": "https://www.mckinsey.com/capabilities/tech-and-ai/our-insights/the-top-trends-in-tech", "title": "McKinsey technology trends outlook 2025", "content": "This outlook highlights transformative trends that are driving innovation and addressing critical challenges across sectors. Artificial intelligence stands out not only as a powerful technology wave on its own but also as a foundational amplifier of the other trends. Its impact increasingly occurs via a combination with other trends, as AI both accelerates progress within individual domains and unlocks new possibilities at the intersections—accelerating the training of robots, advancing scientific discoveries in bioengineering, optimizing energy systems, and much more. The evolution of AI solutions in the marketplace increasingly combines aspects of trends we previously analyzed separately as applied AI and generative AI, so this year, they are examined together.\n\nEven as excitement about AI applications and their use cases builds, realizing AI’s full potential across sectors will require continued innovations to manage computing intensity, reduce deployment costs, and drive infrastructure investment. This will also demand thoughtful approaches to safety, governance, and workforce adaptation, creating a wide range of opportunities for industry leaders, policymakers, and entrepreneurs alike.\n\n. [...] In addition, we updated the selection and definition of trends from last year’s report to reflect the evolution of technology trends:\n\n   An overarching artificial intelligence category replaces these four trends: applied AI, generative AI, industrializing machine learning, and next-generation software development.\n   The agentic AI and application-specific semiconductors trends have been added since last year’s publication.\n   Two separate trends from last year, electrification and renewables and climate technologies beyond electrification, have been combined into a single trend: future of energy and sustainability technologies.\n\nThe data sources and keywords have been updated. For equity investment insights into the future of space technologies and quantum technologies, we built on research from McKinsey’s Aerospace & Defense Practice and the Quantum Technology Monitor.\n\nInsights gathered from McKinsey expert interviews were utilized to assign enterprise-wide adoption scores (on a 1–5 scale) for each trend, defined as follows:", "score": 0.8740022, "raw_content": null, "summary": "The evolution of AI solutions in the marketplace increasingly combines aspects of trends we previously analyzed separately as applied AI and generative AI, so this year, they are examined together. [...] In addition, we updated the selection and definition of trends from last year’s report to reflect the evolution of technology trends: An overarching artificial intelligence category replaces these"}, {"url": "https://blogs.cisco.com/partner/six-ai-predictions-for-2025-that-will-reshape-how-we-think-about-enterprise-technology", "title": "Six AI Predictions For 2025 That Will Reshape How We Think About ...", "content": "## 1. Right-sized AI for real-world impact\n\nIn 2025, organizations will fundamentally shift away from massive GPU clusters toward targeted, efficient AI solutions as the true costs of large language models become unsustainable. With training costs ranging from $4.6M to $12M per run and requiring thousands of high-end GPUs, companies will embrace smaller, specialized models that offer better control, compliance, and cost efficiency. This shift isn’t just about technology—it’s about aligning AI with business reality and regulatory frameworks. As organizations become increasingly dissatisfied with the accuracy and confidence levels of general-purpose models, they will turn to bespoke language models optimized for specific business outcomes. Success will be measured by how effectively these precision AI investments drive tangible business transformation, not by the size of the deployment or the scale of the model.\n\n## 2. Data security and observability become AI’s foundation. [...] ## 5. Partner ecosystems become AI’s force multiplier.\n\nThe complexity of AI operations and scarcity of talent will make partnerships the cornerstone of successful AI deployment in 2025. Even technology-rich enterprises will struggle to maintain dedicated AI expertise, driving a new era of strategic collaboration. Partner business models will evolve dramatically as traditional boundaries blur—MSPs will expand into development and integration, resellers will build managed service practices, and integrators will create their own IP. The most successful organizations will be those that embrace this fluidity, leveraging APIs and cloud-native architectures to deliver value through multiple channels. These fluid partnerships will pioneer scalable innovation models that rapidly adapt across markets, with success measured by their ability to orchestrate diverse capabilities into tangible business impact.\n\n## 6. We are entering an era of accelerated re-skilling. [...] The explosive growth of AI is creating unprecedented pressure on data center sustainability. For example, Elon Musk’s artificial intelligence company, xAI, will be the world’s largest supercomputer facility in Memphis, TN. With each ChatGPT query consuming nearly 10 times the electricity of a Google search, organizations are facing a critical inflection point. Goldman Sachs projects that data center power demand will surge 160% by 2030, while Morgan Stanley forecasts that data center emissions will reach 2.5 billion metric tons of CO2 equivalent in the same timeframe. This collision between AI’s energy appetite and sustainability imperatives will drive radical innovation in 2025. We’ll see cutting-edge technologies like direct-to-chip cooling and liquid immersion alongside innovative approaches like harnessing ocean currents and strategically placing data centers near renewable energy sources. The future won’t be about more data centers, but about fewer, more powerful facilities designed with sustainability at their core.", "score": 0.8737439, "raw_content": null, "summary": "Success will be measured by how effectively these precision AI investments drive tangible business transformation, not by the size of the deployment or the scale of the model. The complexity of AI operations and scarcity of talent will make partnerships the cornerstone of successful AI deployment in 2025."}]}
{"query": "AI trends 2026 (English)", "result": {"query": "AI trends 2026 (English)", "follow_up_questions": null, "answer": null, "images": [], "results": [{"url": "https://www.library.hbs.edu/working-knowledge/ai-trends-for-2026-building-change-fitness-and-balancing-trade-offs", "title": "AI Trends for 2026: Building 'Change Fitness' and Balancing Trade ...", "content": "_Jacqueline Ng Lane is an assistant professor in the Technology and Operations Management Unit and a co-principal investigator of the Laboratory for Innovation Science at the Digital Data Design Institute at Harvard._\n\nN. Louis Shipley: Entrepreneurial competition in AI remains fierce\n\nAs we enter 2026, we are in the midst of a massive AI buildout. This creates enormous opportunities for entrepreneurs and investors.\n\nClearly, AI is transforming the economy. It’s easy and in fact natural to get caught up in the euphoria. For entrepreneurs, it is critical to ensure your AI startup solves a real problem by addressing verifiable customer pain. The barriers to developing new products have dropped considerably, and products can be developed at record speed.\n\n### Do your homework [...] Image 1: A close-up illustration of a robotic hand, palm facing up, reaching from the right side of the image, against a dark background filled with rows of small teal dots that look like digital data. A semi-transparent large orange circle hovers in the hand.\n\n1.   Harvard Business School\n2.   Working Knowledge\n3.   AI Trends for 2026: Building 'Change Fitness' and Balancing Trade-Offs\n\nMany business leaders have made strides in bringing artificial intelligence into their organizations. In 2026, many will seek to wring more value from the technology.\n\nWe asked Harvard Business School faculty what trends leaders might see in the coming year, especially as AI becomes omnipresent. Here’s what they said.\n\nTheir comments have been lightly edited for length and clarity.\n\nTsedal Neeley: Change fitness will become the AI differentiator [...] In 2026, executives should:\n\n   Organize AI around strategy. Sequence predictive AI first if your goal is sustaining innovation, as in aerospace or medical devices. Put generative AI first if R&D or emerging markets are your focus.\n\n   Prioritize cognitive engagement, not just efficiency. AI’s format shapes outcomes as much as its recommendations. Dynamic interfaces (such as chatbots) increase exploration but may reduce quality. Static interfaces (such as fixed explanatory content) improve outcomes but may narrow the solution.\n\n   Consider AI orchestration a portfolio decision. Just as financial portfolios balance risk and return, innovation portfolios balance mean and variance.\n\n   Shift to process design from process optimization. Most AI implementations aim to improve existing workflows. Using AI to fundamentally reorganize how decisions happen is the emerging frontier.", "score": 0.8991304, "raw_content": null, "summary": "_Jacqueline Ng Lane is an assistant professor in the Technology and Operations Management Unit and a co-principal investigator of the Laboratory for Innovation Science at the Digital Data Design Institute at Harvard._ N. Louis Shipley: Entrepreneurial competition in AI remains fierce As we enter 2026, we are in the midst of a massive AI buildout."}, {"url": "https://news.microsoft.com/source/features/ai/whats-next-in-ai-7-trends-to-watch-in-2026/", "title": "What's next in AI: 7 trends to watch in 2026 - Microsoft Source", "content": "As AI agents become digital colleagues and take on specific tasks at human direction, organizations are strengthening security to keep pace with new risks. The infrastructure powering these advances is also maturing, with smarter, more efficient systems.\n\nThese seven trends to watch in 2026 show what’s possible when people join forces with AI.\n\nImage 4\n\nAI will amplify what people can achieve together\n\nAparna Chennapragada, Microsoft’s chief product officer for AI experiences, sees 2026 as a new era for alliances between technology and people. If recent years were about AI answering questions and reasoning through problems, the next wave will be about true collaboration, Chennapragada says.\n\n“The future isn’t about replacing humans,” she says. “It’s about amplifying them.” [...] Cancel0 Cart 0 items in shopping cart\n\nImage 2Source\n\n   \n   \n   \n   \n   \n\nImage 3: Abstract geometric illustration with floating icons on a blue gradient background\n\nWhat’s next in AI:7 trends to watch in 2026\n\n by Susanna Ray \n\nAI is entering a new phase, one defined by real-world impact.\n\nAfter several years of experimentation, 2026 is shaping up to be the year AI evolves from instrument to partner, transforming how we work, create and solve problems. Across industries, AI is moving beyond answering questions to collaborating with people and amplifying their expertise.\n\nThis transformation is visible everywhere. In medicine, AI is helping close gaps in care. In software development, it’s learning not just code but the context behind it. In scientific research, it’s becoming a true lab assistant. In quantum computing, new hybrid approaches are heralding breakthroughs once thought impossible. [...] King points to achievements demonstrated in 2025 by Microsoft AI’s Diagnostic Orchestrator (MAI-DxO), which solved complex medical cases with 85.5% accuracy, far above the 20% average for experienced physicians. With Copilot and Bing already answering more than 50 million health questions daily, he sees advances in AI as a way to give people more influence and control over their own health and wellbeing.\n\nImage 7\n\nAI will become central to the research process\n\nAI is already speeding up breakthroughs in fields like climate modeling, molecular dynamics and materials design, says Peter Lee, president of Microsoft Research. But the next leap is coming. In 2026, AI won’t just summarize papers, answer questions and write reports — it will actively join the process of discovery in physics, chemistry and biology.\n\n“AI will generate hypotheses, use tools and apps that control scientific experiments, and collaborate with both human and AI research colleagues,” Lee says.", "score": 0.8978479, "raw_content": null, "summary": "“It’s about amplifying them.” [...] Cancel0 Cart 0 items in shopping cart Image 2Source Image 3: Abstract geometric illustration with floating icons on a blue gradient background What’s next in AI:7 trends to watch in 2026 by Susanna Ray AI is entering a new phase, one defined by real-world impact. Image 7 AI will become central to the research process AI is already speeding up breakthroughs in fi"}, {"url": "https://www.ibm.com/think/news/ai-tech-trends-predictions-2026", "title": "The trends that will shape AI and tech in 2026 | IBM", "content": "### AI agents will shift from personal assistants to AI‑orchestrated teams, as everyday users become the new agent builders|Kevin Chung, Chief Strategy Officer,Writer\n\n2026 will be defined by three trends that move AI beyond personal productivity, says Kevin Chung, Chief Strategy Officer at Writer, an enterprise AI platform for agentic work.\n\n“First, AI is shifting from individual usage to team and workflow orchestration,” Chung told _IBM Think_. That means coordinating entire workflows, connecting data across departments and moving projects from idea to completion.\n\nSecond, as reasoning capabilities improve, systems won’t just follow instructions: they’ll anticipate needs. “This evolution transforms AI from a passive assistant into an active collaborator capable of meaningful problem-solving and decision-making,” he said. [...] ### Multimodal AI will interpret the world like humans |Aaron Baughman, IBM Fellow and Master Inventor, IBM\n\nGenerative models need to be multisensory so they can interpret the world like humans and even detect signals we might miss, said Aaron Baughman, IBM Fellow and Master Inventor, in a recent episode of _Mixture of Experts_.\n\nBaughman has worked with multimodal AI in sports and leads some of IBM’s work with the US Open, ESPN Fantasy Football and the Masters, notably. For him, multimodal AI is a trend he expects to see more of in 2026. [...] New agentic capabilities will give way to new possibilities for businesses and individuals alike. “I really see the parallels of music production à la Rick Rubin style with AI creation,” IBM’s Distinguished Engineer Chris Hay told _IBM Think_. “I don’t limit it to coding. I think we [will] all become AI composers, whether you’re a marketer, programmer or PM.”\n\nMany believe efficiency will be the new frontier. “GPUs will remain king, but ASIC-based accelerators, chiplet designs, analog inference and even quantum-assisted optimizers will mature,” Kaoutar El Maghraoui, a Principal Research Scientist at IBM, said during this week’s _Mixture of Experts_. “Maybe a new class of chips for agentic workloads will emerge.”\n\nAfter much skepticism around AI’s ROI, AI capabilities will pave new ways to do business in the enterprise. And open-source reasoning models and agents will keep pushing boundaries to conquer enterprise AI.", "score": 0.8961153, "raw_content": null, "summary": "### AI agents will shift from personal assistants to AI‑orchestrated teams, as everyday users become the new agent builders|Kevin Chung, Chief Strategy Officer,Writer 2026 will be defined by three trends that move AI beyond personal productivity, says Kevin Chung, Chief Strategy Officer at Writer, an enterprise AI platform for agentic work. [...] ### Multimodal AI will interpret the world like hum"}, {"url": "https://www.forbes.com/sites/robtoews/2025/12/22/10-ai-predictions-for-2026/", "title": "10 AI Predictions For 2026 - Forbes", "content": "In 2026, this vibe shift will translate to noticeably less discourse about and interest in the concepts of AGI and superintelligence. It’s not that people will challenge or reject these concepts outright; they will just be less focused on them. AI leaders like Sam Altman, Dario Amodei, Sundar Pichai and Satya Nadella will spend less time talking about superintelligent AI and more time talking about enterprise AI adoption. Commentators and thought leaders will choose to opine on more proximate topics, from the geopolitics of AI to AI-driven job displacement. Go-to discussion topics at cocktail parties and around the watercooler will shift in a similar direction.\n\nDiscourse about AGI will not go away altogether in 2026 — Eliezer Yudkowsky is not going anywhere! — but it will become far less common. [...] On the non-invasive side, ultrasound-based techniques will emerge as the buzziest and most promising BCI approach. Startups like Nudge (which recently announced a $100 million Series A led by Thrive and Greenoaks) and Merge Labs (Sam Altman’s new BCI startup, into which OpenAI is reportedly investing hundreds of millions of dollars) will rank among 2026’s trendiest companies and will raise big new rounds. Other non-invasive approaches, including silent speech and EEG, will also enjoy plenty of momentum.\n\nOn the invasive side, Neuralink has long been the dominant player. The company is effectively synonymous with the entire field of BCI today. It has a world-class team and has played a central role for years in moving this field forward. Next year, however, as BCI enters the spotlight, Neuralink’s position as the category leader will become shakier.\n\nWhy is that? [...] AI is on the cusp of invading the physical world. It will soon be embedded in millions of robots, autonomous vehicles, smart glasses, smart necklaces, home appliances, drones, brain-computer interfaces and more. The ideal chip for a humanoid robot is very different from the ideal chip for a pair of smart glasses. Enormous performance, cost and efficiency gains could be unlocked across the economy if it were feasible to more precisely tailor chips to the use cases to which they are applied.\n\nThis will not happen overnight. Transitioning to a world of ubiquitous customized silicon will take many years. But 2026 will be the year that the power of this idea becomes evident and that companies begin planning in earnest for it.", "score": 0.8755427, "raw_content": null, "summary": "Startups like Nudge (which recently announced a $100 million Series A led by Thrive and Greenoaks) and Merge Labs (Sam Altman’s new BCI startup, into which OpenAI is reportedly investing hundreds of millions of dollars) will rank among 2026’s trendiest companies and will raise big new rounds. But 2026 will be the year that the power of this idea becomes evident and that companies begin planning in"}, {"url": "https://hai.stanford.edu/news/stanford-ai-experts-predict-what-will-happen-in-2026", "title": "Stanford AI Experts Predict What Will Happen in 2026", "content": "In 2026, arguments about AI’s economic impact will finally give way to careful measurement. We’ll see the emergence of high-frequency “AI economic dashboards” that track, at the task and occupation level, where AI is boosting productivity, displacing workers, or creating new roles. Using payroll, platform, and usage data, these tools will function like real-time national accounts. In our “Canaries in the Coal Mine” work with ADP, we already see early-career workers in AI-exposed occupations experiencing weaker employment and earnings outcomes; in 2026, similar indicators will be updated monthly, not years later. Executives will check AI exposure metrics daily alongside revenue dashboards, and policymakers will use them to target training, safety nets, and innovation policy. The debate will shift from whether AI matters to how quickly its effects are diffusing, who is being left behind, and which complementary investments best turn AI capability into broad-based prosperity.", "score": 0.8145405, "raw_content": null, "summary": "In our “Canaries in the Coal Mine” work with ADP, we already see early-career workers in AI-exposed occupations experiencing weaker employment and earnings outcomes; in 2026, similar indicators will be updated monthly, not years later. The debate will shift from whether AI matters to how quickly its effects are diffusing, who is being left behind, and which complementary investments best turn AI c"}], "response_time": 1.28, "request_id": "51f6548b-050c-48c3-87ca-58273c47ce2d"}, "query_summary": "Image 7 AI will become central to the research process AI is already speeding up breakthroughs in fi ### AI agents will shift from personal assistants to AI‑orchestrated teams, as everyday users become the new agent builders|Kevin Chung, Chief Strategy Officer,Writer 2026 will be defined by three trends that move AI beyond personal productivity, says Kevin Chung, Chief Strategy Officer at Writer, an enterprise AI platform for agentic work. [...] ### Multimodal AI will interpret the world like hum Startups like Nudge (which recently announced a $100 million Series A led by Thrive and Greenoaks)", "lang_pref": "en", "preferred_results": [{"url": "https://www.library.hbs.edu/working-knowledge/ai-trends-for-2026-building-change-fitness-and-balancing-trade-offs", "title": "AI Trends for 2026: Building 'Change Fitness' and Balancing Trade ...", "content": "_Jacqueline Ng Lane is an assistant professor in the Technology and Operations Management Unit and a co-principal investigator of the Laboratory for Innovation Science at the Digital Data Design Institute at Harvard._\n\nN. Louis Shipley: Entrepreneurial competition in AI remains fierce\n\nAs we enter 2026, we are in the midst of a massive AI buildout. This creates enormous opportunities for entrepreneurs and investors.\n\nClearly, AI is transforming the economy. It’s easy and in fact natural to get caught up in the euphoria. For entrepreneurs, it is critical to ensure your AI startup solves a real problem by addressing verifiable customer pain. The barriers to developing new products have dropped considerably, and products can be developed at record speed.\n\n### Do your homework [...] Image 1: A close-up illustration of a robotic hand, palm facing up, reaching from the right side of the image, against a dark background filled with rows of small teal dots that look like digital data. A semi-transparent large orange circle hovers in the hand.\n\n1.   Harvard Business School\n2.   Working Knowledge\n3.   AI Trends for 2026: Building 'Change Fitness' and Balancing Trade-Offs\n\nMany business leaders have made strides in bringing artificial intelligence into their organizations. In 2026, many will seek to wring more value from the technology.\n\nWe asked Harvard Business School faculty what trends leaders might see in the coming year, especially as AI becomes omnipresent. Here’s what they said.\n\nTheir comments have been lightly edited for length and clarity.\n\nTsedal Neeley: Change fitness will become the AI differentiator [...] In 2026, executives should:\n\n   Organize AI around strategy. Sequence predictive AI first if your goal is sustaining innovation, as in aerospace or medical devices. Put generative AI first if R&D or emerging markets are your focus.\n\n   Prioritize cognitive engagement, not just efficiency. AI’s format shapes outcomes as much as its recommendations. Dynamic interfaces (such as chatbots) increase exploration but may reduce quality. Static interfaces (such as fixed explanatory content) improve outcomes but may narrow the solution.\n\n   Consider AI orchestration a portfolio decision. Just as financial portfolios balance risk and return, innovation portfolios balance mean and variance.\n\n   Shift to process design from process optimization. Most AI implementations aim to improve existing workflows. Using AI to fundamentally reorganize how decisions happen is the emerging frontier.", "score": 0.8991304, "raw_content": null, "summary": "_Jacqueline Ng Lane is an assistant professor in the Technology and Operations Management Unit and a co-principal investigator of the Laboratory for Innovation Science at the Digital Data Design Institute at Harvard._ N. Louis Shipley: Entrepreneurial competition in AI remains fierce As we enter 2026, we are in the midst of a massive AI buildout."}, {"url": "https://news.microsoft.com/source/features/ai/whats-next-in-ai-7-trends-to-watch-in-2026/", "title": "What's next in AI: 7 trends to watch in 2026 - Microsoft Source", "content": "As AI agents become digital colleagues and take on specific tasks at human direction, organizations are strengthening security to keep pace with new risks. The infrastructure powering these advances is also maturing, with smarter, more efficient systems.\n\nThese seven trends to watch in 2026 show what’s possible when people join forces with AI.\n\nImage 4\n\nAI will amplify what people can achieve together\n\nAparna Chennapragada, Microsoft’s chief product officer for AI experiences, sees 2026 as a new era for alliances between technology and people. If recent years were about AI answering questions and reasoning through problems, the next wave will be about true collaboration, Chennapragada says.\n\n“The future isn’t about replacing humans,” she says. “It’s about amplifying them.” [...] Cancel0 Cart 0 items in shopping cart\n\nImage 2Source\n\n   \n   \n   \n   \n   \n\nImage 3: Abstract geometric illustration with floating icons on a blue gradient background\n\nWhat’s next in AI:7 trends to watch in 2026\n\n by Susanna Ray \n\nAI is entering a new phase, one defined by real-world impact.\n\nAfter several years of experimentation, 2026 is shaping up to be the year AI evolves from instrument to partner, transforming how we work, create and solve problems. Across industries, AI is moving beyond answering questions to collaborating with people and amplifying their expertise.\n\nThis transformation is visible everywhere. In medicine, AI is helping close gaps in care. In software development, it’s learning not just code but the context behind it. In scientific research, it’s becoming a true lab assistant. In quantum computing, new hybrid approaches are heralding breakthroughs once thought impossible. [...] King points to achievements demonstrated in 2025 by Microsoft AI’s Diagnostic Orchestrator (MAI-DxO), which solved complex medical cases with 85.5% accuracy, far above the 20% average for experienced physicians. With Copilot and Bing already answering more than 50 million health questions daily, he sees advances in AI as a way to give people more influence and control over their own health and wellbeing.\n\nImage 7\n\nAI will become central to the research process\n\nAI is already speeding up breakthroughs in fields like climate modeling, molecular dynamics and materials design, says Peter Lee, president of Microsoft Research. But the next leap is coming. In 2026, AI won’t just summarize papers, answer questions and write reports — it will actively join the process of discovery in physics, chemistry and biology.\n\n“AI will generate hypotheses, use tools and apps that control scientific experiments, and collaborate with both human and AI research colleagues,” Lee says.", "score": 0.8978479, "raw_content": null, "summary": "“It’s about amplifying them.” [...] Cancel0 Cart 0 items in shopping cart Image 2Source Image 3: Abstract geometric illustration with floating icons on a blue gradient background What’s next in AI:7 trends to watch in 2026 by Susanna Ray AI is entering a new phase, one defined by real-world impact. Image 7 AI will become central to the research process AI is already speeding up breakthroughs in fi"}, {"url": "https://www.ibm.com/think/news/ai-tech-trends-predictions-2026", "title": "The trends that will shape AI and tech in 2026 | IBM", "content": "### AI agents will shift from personal assistants to AI‑orchestrated teams, as everyday users become the new agent builders|Kevin Chung, Chief Strategy Officer,Writer\n\n2026 will be defined by three trends that move AI beyond personal productivity, says Kevin Chung, Chief Strategy Officer at Writer, an enterprise AI platform for agentic work.\n\n“First, AI is shifting from individual usage to team and workflow orchestration,” Chung told _IBM Think_. That means coordinating entire workflows, connecting data across departments and moving projects from idea to completion.\n\nSecond, as reasoning capabilities improve, systems won’t just follow instructions: they’ll anticipate needs. “This evolution transforms AI from a passive assistant into an active collaborator capable of meaningful problem-solving and decision-making,” he said. [...] ### Multimodal AI will interpret the world like humans |Aaron Baughman, IBM Fellow and Master Inventor, IBM\n\nGenerative models need to be multisensory so they can interpret the world like humans and even detect signals we might miss, said Aaron Baughman, IBM Fellow and Master Inventor, in a recent episode of _Mixture of Experts_.\n\nBaughman has worked with multimodal AI in sports and leads some of IBM’s work with the US Open, ESPN Fantasy Football and the Masters, notably. For him, multimodal AI is a trend he expects to see more of in 2026. [...] New agentic capabilities will give way to new possibilities for businesses and individuals alike. “I really see the parallels of music production à la Rick Rubin style with AI creation,” IBM’s Distinguished Engineer Chris Hay told _IBM Think_. “I don’t limit it to coding. I think we [will] all become AI composers, whether you’re a marketer, programmer or PM.”\n\nMany believe efficiency will be the new frontier. “GPUs will remain king, but ASIC-based accelerators, chiplet designs, analog inference and even quantum-assisted optimizers will mature,” Kaoutar El Maghraoui, a Principal Research Scientist at IBM, said during this week’s _Mixture of Experts_. “Maybe a new class of chips for agentic workloads will emerge.”\n\nAfter much skepticism around AI’s ROI, AI capabilities will pave new ways to do business in the enterprise. And open-source reasoning models and agents will keep pushing boundaries to conquer enterprise AI.", "score": 0.8961153, "raw_content": null, "summary": "### AI agents will shift from personal assistants to AI‑orchestrated teams, as everyday users become the new agent builders|Kevin Chung, Chief Strategy Officer,Writer 2026 will be defined by three trends that move AI beyond personal productivity, says Kevin Chung, Chief Strategy Officer at Writer, an enterprise AI platform for agentic work. [...] ### Multimodal AI will interpret the world like hum"}, {"url": "https://www.forbes.com/sites/robtoews/2025/12/22/10-ai-predictions-for-2026/", "title": "10 AI Predictions For 2026 - Forbes", "content": "In 2026, this vibe shift will translate to noticeably less discourse about and interest in the concepts of AGI and superintelligence. It’s not that people will challenge or reject these concepts outright; they will just be less focused on them. AI leaders like Sam Altman, Dario Amodei, Sundar Pichai and Satya Nadella will spend less time talking about superintelligent AI and more time talking about enterprise AI adoption. Commentators and thought leaders will choose to opine on more proximate topics, from the geopolitics of AI to AI-driven job displacement. Go-to discussion topics at cocktail parties and around the watercooler will shift in a similar direction.\n\nDiscourse about AGI will not go away altogether in 2026 — Eliezer Yudkowsky is not going anywhere! — but it will become far less common. [...] On the non-invasive side, ultrasound-based techniques will emerge as the buzziest and most promising BCI approach. Startups like Nudge (which recently announced a $100 million Series A led by Thrive and Greenoaks) and Merge Labs (Sam Altman’s new BCI startup, into which OpenAI is reportedly investing hundreds of millions of dollars) will rank among 2026’s trendiest companies and will raise big new rounds. Other non-invasive approaches, including silent speech and EEG, will also enjoy plenty of momentum.\n\nOn the invasive side, Neuralink has long been the dominant player. The company is effectively synonymous with the entire field of BCI today. It has a world-class team and has played a central role for years in moving this field forward. Next year, however, as BCI enters the spotlight, Neuralink’s position as the category leader will become shakier.\n\nWhy is that? [...] AI is on the cusp of invading the physical world. It will soon be embedded in millions of robots, autonomous vehicles, smart glasses, smart necklaces, home appliances, drones, brain-computer interfaces and more. The ideal chip for a humanoid robot is very different from the ideal chip for a pair of smart glasses. Enormous performance, cost and efficiency gains could be unlocked across the economy if it were feasible to more precisely tailor chips to the use cases to which they are applied.\n\nThis will not happen overnight. Transitioning to a world of ubiquitous customized silicon will take many years. But 2026 will be the year that the power of this idea becomes evident and that companies begin planning in earnest for it.", "score": 0.8755427, "raw_content": null, "summary": "Startups like Nudge (which recently announced a $100 million Series A led by Thrive and Greenoaks) and Merge Labs (Sam Altman’s new BCI startup, into which OpenAI is reportedly investing hundreds of millions of dollars) will rank among 2026’s trendiest companies and will raise big new rounds. But 2026 will be the year that the power of this idea becomes evident and that companies begin planning in"}, {"url": "https://hai.stanford.edu/news/stanford-ai-experts-predict-what-will-happen-in-2026", "title": "Stanford AI Experts Predict What Will Happen in 2026", "content": "In 2026, arguments about AI’s economic impact will finally give way to careful measurement. We’ll see the emergence of high-frequency “AI economic dashboards” that track, at the task and occupation level, where AI is boosting productivity, displacing workers, or creating new roles. Using payroll, platform, and usage data, these tools will function like real-time national accounts. In our “Canaries in the Coal Mine” work with ADP, we already see early-career workers in AI-exposed occupations experiencing weaker employment and earnings outcomes; in 2026, similar indicators will be updated monthly, not years later. Executives will check AI exposure metrics daily alongside revenue dashboards, and policymakers will use them to target training, safety nets, and innovation policy. The debate will shift from whether AI matters to how quickly its effects are diffusing, who is being left behind, and which complementary investments best turn AI capability into broad-based prosperity.", "score": 0.8145405, "raw_content": null, "summary": "In our “Canaries in the Coal Mine” work with ADP, we already see early-career workers in AI-exposed occupations experiencing weaker employment and earnings outcomes; in 2026, similar indicators will be updated monthly, not years later. The debate will shift from whether AI matters to how quickly its effects are diffusing, who is being left behind, and which complementary investments best turn AI c"}]}
{"query": "emerging AI technologies 2026 (English)", "result": {"query": "emerging AI technologies 2026 (English)", "follow_up_questions": null, "answer": null, "images": [], "results": [{"url": "https://geniusee.com/single-blog/ai-trends-in-2026", "title": "9 AI trends in 2026: Our top to watch", "content": "The clinical standard: There is no better place to start than in healthcare. 2026 will be the year AI goes beyond experimental trials and into standard clinical practice. We are witnessing the digitalization of old hardware, like AI-enhanced stethoscopes, which introduce diagnostic logic into routine patient care.\n Education: Adaptive platforms are no longer just quizzes, but real-time tutors that can adjust the curriculum to match a student’s level of frustration or interest, as gauged through interactional patterns.\n\n## №6: Edge AI expansion\n\nNot every task requires a vast, costly model like GPT-5. Edge AI and Small Language Models are the pragmatic trends in Edge AI for 2026.\n\nWhy smaller is better: Running data locally on a device (Edge) will achieve lower latency and increased privacy. [...] ### The era of defensive AI:\n\n Predictive defense: AI-generated algorithms analyze network traffic baselines to identify anomalous traffic patterns that a human analyst might miss.\n Automated response: Intelligent systems can now automatically isolate an infected device to prevent the spread of a breach.\n The problem: Security vs. privacy is always a thin line. To safeguard user data, organizations need to employ Privacy-Enhancing Technologies (PETs) and develop effective security models.\n\n## FAQs about AI trends in 2026\n\n### What will AI do to change software development in 2026?\n\nAI will automate coding, testing, and debugging, making the development process both faster and more reliable. The developers will pay more attention to architecture and problem-solving.\n\n### What is the difference between a Chatbot and an AI Agent? [...] Developing trust: Explainable AI (XAI) provides the rationale behind a decision, a requirement for loan approvals and medical diagnoses.\n Green computing (GreenOps): It is projected that 12% of US electricity will be used in data centers. Therefore, in 2026, this is a major priority. We will observe AI automating its infrastructure- keeping cooling loops in check and load balancing software, in addition to a strategic movement to new sources of power such as Small Modular Reactors.\n\n## №8: AI in scientific discovery\n\nAI is serving as an R&D multiplier. We are leaving the trial and error to simulation and prediction.\n\n### Collaborative intelligence", "score": 0.8440111, "raw_content": null, "summary": "Edge AI and Small Language Models are the pragmatic trends in Edge AI for 2026. We will observe AI automating its infrastructure- keeping cooling loops in check and load balancing software, in addition to a strategic movement to new sources of power such as Small Modular Reactors."}, {"url": "https://sloanreview.mit.edu/article/five-trends-in-ai-and-data-science-for-2026/", "title": "Five Trends in AI and Data Science for 2026", "content": "Read More +\n\nOrganizations tend to change much more slowly than AI technology does these days. This means that forecasting enterprise adoption of AI is a bit easier than predicting technology change in this, our third year of making AI predictions. Neither of us is a computer or cognitive scientist, so we generally stay away from prognostication about AI technology or the specific ways it will rot our brains (though we do expect that to be an ongoing phenomenon!).\n\nHowever, AI seems to have moved beyond being just a technology to becoming the primary force driving economic growth and the stock market. We’re also neither economists nor investment analysts, but that won’t stop us from making our first prediction.\n\nHere are the emerging 2026 AI trends that leaders should understand and be prepared to act on.\n\n### 1. The AI bubble will deflate, and the economy will suffer. [...] Image 8: MIT Sloan Management Review Logo\n\nAI in Action\nFive Trends in AI and Data Science for 2026\n\nFrom the AI bubble to GenAI’s rise as an organizational tool, these are the 2026 AI trends to watch. Explore new data and advice from AI experts.\n\nImage 10Image 12\n\nThomas H. Davenport and Randy BeanJanuary 06, 2026 Reading Time: 8 min\n\n#### Topics\n\n   Data, AI, & Machine Learning\n   Managing Technology\n   AI & Machine Learning\n   Data & Data Culture\n   IT Governance & Leadership\n   Technology Implementation\n\n#### AI in Action\n\n This column series looks at the biggest data and analytics challenges facing modern companies and dives deep into successful use cases that can help other organizations accelerate their AI progress. \n\nMore in this series\n\nSubscribeShare\n\nTwitterFacebookLinkedin\n\n#### What to Read Next [...] SubscribeShare\n\nTwitterFacebookLinkedin\n\n#### What to Read Next\n\n1.   Three Steps Toward Fairer Talent Management\n2.   Build Better Pay-for-Performance Compensation Plans\n3.   Calm: The Underrated Capability Every Leader Needs Now | Lynda Gratton\n4.   Stop Making Hollow Apologies at Work | Jim Detert\n\nImage 14\n\nCarolyn Geason-Beissel/MIT SMR | Getty Images\n\nSummary:\nMIT SMR columnists Thomas H. Davenport and Randy Bean see five AI trends to pay attention to in 2026: deflation of the AI ... bubble and subsequent hits to the economy; growth of the “factory” infrastructure for all-in AI adapters; greater focus on generative AI as an organizational resource rather than an individual one; continued progression toward value from agentic AI, despite the hype; and ongoing questions around who should manage data and AI.\n\nRead More +", "score": 0.8325776, "raw_content": null, "summary": "Davenport and Randy BeanJanuary 06, 2026 Reading Time: 8 min #### Topics Data, AI, & Machine Learning Managing Technology AI & Machine Learning Data & Data Culture IT Governance & Leadership Technology Implementation #### AI in Action This column series looks at the biggest data and analytics challenges facing modern companies and dives deep into successful use cases that can help other organizati"}, {"url": "https://www.forbes.com/sites/robtoews/2025/12/22/10-ai-predictions-for-2026/", "title": "10 AI Predictions For 2026 - Forbes", "content": "On the non-invasive side, ultrasound-based techniques will emerge as the buzziest and most promising BCI approach. Startups like Nudge (which recently announced a $100 million Series A led by Thrive and Greenoaks) and Merge Labs (Sam Altman’s new BCI startup, into which OpenAI is reportedly investing hundreds of millions of dollars) will rank among 2026’s trendiest companies and will raise big new rounds. Other non-invasive approaches, including silent speech and EEG, will also enjoy plenty of momentum.\n\nOn the invasive side, Neuralink has long been the dominant player. The company is effectively synonymous with the entire field of BCI today. It has a world-class team and has played a central role for years in moving this field forward. Next year, however, as BCI enters the spotlight, Neuralink’s position as the category leader will become shakier.\n\nWhy is that? [...] _Possible acquirers include: AbbVie, AstraZeneca, Bristol Myers Squibb, Johnson & Johnson, Merck, Novartis, Pfizer, Roche, Sanofi, Takeda._\n\n_Possible acquisition targets include: Chai Discovery, Cradle Bio, Latent Labs, Nabla Bio, Profluent Bio, Xaira Therapeutics._\n\n10. Brain-computer interfaces will transition from a fringe frontier field to a mainstream technology and startup category. Neuralink’s position as the clear category leader will become shakier.\n\nTo most people, brain-computer interfaces sound like science fiction. People may be loosely familiar with Elon Musk’s Neuralink, but most generally assume that the technology is many years or even decades away from the real world. [...] This secrecy cannot last forever. In 2026, details of SSI’s approach will finally leak to the public. It will be a novel and promising enough research agenda that it will prompt the big labs — including OpenAI, Anthropic and Google DeepMind — to recalibrate their own research roadmaps and to invest more heavily in this direction.\n\nWhat could Sutskever and SSI’s big idea possibly be?\n\nTwo obvious answers would be recursive self-improvement (AI systems that can build stronger AI systems, that can build stronger AI systems and so forth) or continual learning (AI systems that can learn on an ongoing basis as they interact with the world).\n\nBoth of these fields address fundamental shortcomings of today’s AI systems, and both have become buzzy frontier research areas in recent months.\n\nBut we speculate that it’s something less consensus and more “out there” than these. We can’t wait to find out.", "score": 0.82761955, "raw_content": null, "summary": "It will be a novel and promising enough research agenda that it will prompt the big labs — including OpenAI, Anthropic and Google DeepMind — to recalibrate their own research roadmaps and to invest more heavily in this direction. Two obvious answers would be recursive self-improvement (AI systems that can build stronger AI systems, that can build stronger AI systems and so forth) or continual lear"}, {"url": "https://www.gartner.com/en/articles/top-technology-trends-2026", "title": "Gartner Top 10 Strategic Technology Trends for 2026", "content": "1. AI-Native Development Platforms\n2. AI Supercomputing Platforms\n3. Confidential Computing\n4. Multiagent Systems\n5. Domain-Specific Language Models\n6. Physical AI\n7. Preemptive Cybersecurity\n8. Digital Provenance\n9. AI Security Platforms\n10. Geopatriation\n\nBegin Download\n\n## Why these technology trends matter now\n\nTechnology leaders face a pivotal year. These trends are not just technical shifts — they are strategic imperatives. CIOs who act now will be better positioned to:\n\n Align digital strategy with enterprise goals\n Scale AI securely and responsibly\n Navigate geopolitical and regulatory complexity\n Lead transformation with confidence\n\nThis year’s trends are tightly interwoven and reflect the realities of a world where no single capability is enough. Gartner organizes them into three themes that define how leading organizations will innovate, compete and protect value: The Architect, The Synthesist and The Vanguard.", "score": 0.80014634, "raw_content": null, "summary": "CIOs who act now will be better positioned to: Align digital strategy with enterprise goals Scale AI securely and responsibly Navigate geopolitical and regulatory complexity Lead transformation with confidence This year’s trends are tightly interwoven and reflect the realities of a world where no single capability is enough. Gartner organizes them into three themes that define how leading organiza"}, {"url": "https://news.microsoft.com/source/features/ai/whats-next-in-ai-7-trends-to-watch-in-2026/", "title": "What's next in AI: 7 trends to watch in 2026", "content": "Cancel0 Cart 0 items in shopping cart\n\nImage 2Source\n\n   \n   \n   \n   \n   \n\nImage 3: Abstract geometric illustration with floating icons on a blue gradient background\n\nWhat’s next in AI:7 trends to watch in 2026\n\n by Susanna Ray \n\nAI is entering a new phase, one defined by real-world impact.\n\nAfter several years of experimentation, 2026 is shaping up to be the year AI evolves from instrument to partner, transforming how we work, create and solve problems. Across industries, AI is moving beyond answering questions to collaborating with people and amplifying their expertise.\n\nThis transformation is visible everywhere. In medicine, AI is helping close gaps in care. In software development, it’s learning not just code but the context behind it. In scientific research, it’s becoming a true lab assistant. In quantum computing, new hybrid approaches are heralding breakthroughs once thought impossible. [...] As AI agents become digital colleagues and take on specific tasks at human direction, organizations are strengthening security to keep pace with new risks. The infrastructure powering these advances is also maturing, with smarter, more efficient systems.\n\nThese seven trends to watch in 2026 show what’s possible when people join forces with AI.\n\nImage 4\n\nAI will amplify what people can achieve together\n\nAparna Chennapragada, Microsoft’s chief product officer for AI experiences, sees 2026 as a new era for alliances between technology and people. If recent years were about AI answering questions and reasoning through problems, the next wave will be about true collaboration, Chennapragada says.\n\n“The future isn’t about replacing humans,” she says. “It’s about amplifying them.” [...] King points to achievements demonstrated in 2025 by Microsoft AI’s Diagnostic Orchestrator (MAI-DxO), which solved complex medical cases with 85.5% accuracy, far above the 20% average for experienced physicians. With Copilot and Bing already answering more than 50 million health questions daily, he sees advances in AI as a way to give people more influence and control over their own health and wellbeing.\n\nImage 7\n\nAI will become central to the research process\n\nAI is already speeding up breakthroughs in fields like climate modeling, molecular dynamics and materials design, says Peter Lee, president of Microsoft Research. But the next leap is coming. In 2026, AI won’t just summarize papers, answer questions and write reports — it will actively join the process of discovery in physics, chemistry and biology.\n\n“AI will generate hypotheses, use tools and apps that control scientific experiments, and collaborate with both human and AI research colleagues,” Lee says.", "score": 0.7978881, "raw_content": null, "summary": "Cancel0 Cart 0 items in shopping cart Image 2Source Image 3: Abstract geometric illustration with floating icons on a blue gradient background What’s next in AI:7 trends to watch in 2026 by Susanna Ray AI is entering a new phase, one defined by real-world impact. Image 7 AI will become central to the research process AI is already speeding up breakthroughs in fields like climate modeling, molecula"}], "response_time": 1.66, "request_id": "a0883345-93c2-42cb-ac68-9c4e0745725b"}, "query_summary": "Davenport and Randy BeanJanuary 06, 2026 Reading Time: 8 min #### Topics Data, AI, & Machine Learning Managing Technology AI & Machine Learning Data & Data Culture IT Governance & Leadership Technology Implementation #### AI in Action This column series looks at the biggest data and analytics challenges facing modern companies and dives deep into successful use cases that can help other organizati It will be a novel and promising enough research agenda that it will prompt the big labs — including OpenAI, Anthropic and Google DeepMind — to recalibrate their own research roadmaps and to invest m", "lang_pref": "en", "preferred_results": [{"url": "https://geniusee.com/single-blog/ai-trends-in-2026", "title": "9 AI trends in 2026: Our top to watch", "content": "The clinical standard: There is no better place to start than in healthcare. 2026 will be the year AI goes beyond experimental trials and into standard clinical practice. We are witnessing the digitalization of old hardware, like AI-enhanced stethoscopes, which introduce diagnostic logic into routine patient care.\n Education: Adaptive platforms are no longer just quizzes, but real-time tutors that can adjust the curriculum to match a student’s level of frustration or interest, as gauged through interactional patterns.\n\n## №6: Edge AI expansion\n\nNot every task requires a vast, costly model like GPT-5. Edge AI and Small Language Models are the pragmatic trends in Edge AI for 2026.\n\nWhy smaller is better: Running data locally on a device (Edge) will achieve lower latency and increased privacy. [...] ### The era of defensive AI:\n\n Predictive defense: AI-generated algorithms analyze network traffic baselines to identify anomalous traffic patterns that a human analyst might miss.\n Automated response: Intelligent systems can now automatically isolate an infected device to prevent the spread of a breach.\n The problem: Security vs. privacy is always a thin line. To safeguard user data, organizations need to employ Privacy-Enhancing Technologies (PETs) and develop effective security models.\n\n## FAQs about AI trends in 2026\n\n### What will AI do to change software development in 2026?\n\nAI will automate coding, testing, and debugging, making the development process both faster and more reliable. The developers will pay more attention to architecture and problem-solving.\n\n### What is the difference between a Chatbot and an AI Agent? [...] Developing trust: Explainable AI (XAI) provides the rationale behind a decision, a requirement for loan approvals and medical diagnoses.\n Green computing (GreenOps): It is projected that 12% of US electricity will be used in data centers. Therefore, in 2026, this is a major priority. We will observe AI automating its infrastructure- keeping cooling loops in check and load balancing software, in addition to a strategic movement to new sources of power such as Small Modular Reactors.\n\n## №8: AI in scientific discovery\n\nAI is serving as an R&D multiplier. We are leaving the trial and error to simulation and prediction.\n\n### Collaborative intelligence", "score": 0.8440111, "raw_content": null, "summary": "Edge AI and Small Language Models are the pragmatic trends in Edge AI for 2026. We will observe AI automating its infrastructure- keeping cooling loops in check and load balancing software, in addition to a strategic movement to new sources of power such as Small Modular Reactors."}, {"url": "https://sloanreview.mit.edu/article/five-trends-in-ai-and-data-science-for-2026/", "title": "Five Trends in AI and Data Science for 2026", "content": "Read More +\n\nOrganizations tend to change much more slowly than AI technology does these days. This means that forecasting enterprise adoption of AI is a bit easier than predicting technology change in this, our third year of making AI predictions. Neither of us is a computer or cognitive scientist, so we generally stay away from prognostication about AI technology or the specific ways it will rot our brains (though we do expect that to be an ongoing phenomenon!).\n\nHowever, AI seems to have moved beyond being just a technology to becoming the primary force driving economic growth and the stock market. We’re also neither economists nor investment analysts, but that won’t stop us from making our first prediction.\n\nHere are the emerging 2026 AI trends that leaders should understand and be prepared to act on.\n\n### 1. The AI bubble will deflate, and the economy will suffer. [...] Image 8: MIT Sloan Management Review Logo\n\nAI in Action\nFive Trends in AI and Data Science for 2026\n\nFrom the AI bubble to GenAI’s rise as an organizational tool, these are the 2026 AI trends to watch. Explore new data and advice from AI experts.\n\nImage 10Image 12\n\nThomas H. Davenport and Randy BeanJanuary 06, 2026 Reading Time: 8 min\n\n#### Topics\n\n   Data, AI, & Machine Learning\n   Managing Technology\n   AI & Machine Learning\n   Data & Data Culture\n   IT Governance & Leadership\n   Technology Implementation\n\n#### AI in Action\n\n This column series looks at the biggest data and analytics challenges facing modern companies and dives deep into successful use cases that can help other organizations accelerate their AI progress. \n\nMore in this series\n\nSubscribeShare\n\nTwitterFacebookLinkedin\n\n#### What to Read Next [...] SubscribeShare\n\nTwitterFacebookLinkedin\n\n#### What to Read Next\n\n1.   Three Steps Toward Fairer Talent Management\n2.   Build Better Pay-for-Performance Compensation Plans\n3.   Calm: The Underrated Capability Every Leader Needs Now | Lynda Gratton\n4.   Stop Making Hollow Apologies at Work | Jim Detert\n\nImage 14\n\nCarolyn Geason-Beissel/MIT SMR | Getty Images\n\nSummary:\nMIT SMR columnists Thomas H. Davenport and Randy Bean see five AI trends to pay attention to in 2026: deflation of the AI ... bubble and subsequent hits to the economy; growth of the “factory” infrastructure for all-in AI adapters; greater focus on generative AI as an organizational resource rather than an individual one; continued progression toward value from agentic AI, despite the hype; and ongoing questions around who should manage data and AI.\n\nRead More +", "score": 0.8325776, "raw_content": null, "summary": "Davenport and Randy BeanJanuary 06, 2026 Reading Time: 8 min #### Topics Data, AI, & Machine Learning Managing Technology AI & Machine Learning Data & Data Culture IT Governance & Leadership Technology Implementation #### AI in Action This column series looks at the biggest data and analytics challenges facing modern companies and dives deep into successful use cases that can help other organizati"}, {"url": "https://www.forbes.com/sites/robtoews/2025/12/22/10-ai-predictions-for-2026/", "title": "10 AI Predictions For 2026 - Forbes", "content": "On the non-invasive side, ultrasound-based techniques will emerge as the buzziest and most promising BCI approach. Startups like Nudge (which recently announced a $100 million Series A led by Thrive and Greenoaks) and Merge Labs (Sam Altman’s new BCI startup, into which OpenAI is reportedly investing hundreds of millions of dollars) will rank among 2026’s trendiest companies and will raise big new rounds. Other non-invasive approaches, including silent speech and EEG, will also enjoy plenty of momentum.\n\nOn the invasive side, Neuralink has long been the dominant player. The company is effectively synonymous with the entire field of BCI today. It has a world-class team and has played a central role for years in moving this field forward. Next year, however, as BCI enters the spotlight, Neuralink’s position as the category leader will become shakier.\n\nWhy is that? [...] _Possible acquirers include: AbbVie, AstraZeneca, Bristol Myers Squibb, Johnson & Johnson, Merck, Novartis, Pfizer, Roche, Sanofi, Takeda._\n\n_Possible acquisition targets include: Chai Discovery, Cradle Bio, Latent Labs, Nabla Bio, Profluent Bio, Xaira Therapeutics._\n\n10. Brain-computer interfaces will transition from a fringe frontier field to a mainstream technology and startup category. Neuralink’s position as the clear category leader will become shakier.\n\nTo most people, brain-computer interfaces sound like science fiction. People may be loosely familiar with Elon Musk’s Neuralink, but most generally assume that the technology is many years or even decades away from the real world. [...] This secrecy cannot last forever. In 2026, details of SSI’s approach will finally leak to the public. It will be a novel and promising enough research agenda that it will prompt the big labs — including OpenAI, Anthropic and Google DeepMind — to recalibrate their own research roadmaps and to invest more heavily in this direction.\n\nWhat could Sutskever and SSI’s big idea possibly be?\n\nTwo obvious answers would be recursive self-improvement (AI systems that can build stronger AI systems, that can build stronger AI systems and so forth) or continual learning (AI systems that can learn on an ongoing basis as they interact with the world).\n\nBoth of these fields address fundamental shortcomings of today’s AI systems, and both have become buzzy frontier research areas in recent months.\n\nBut we speculate that it’s something less consensus and more “out there” than these. We can’t wait to find out.", "score": 0.82761955, "raw_content": null, "summary": "It will be a novel and promising enough research agenda that it will prompt the big labs — including OpenAI, Anthropic and Google DeepMind — to recalibrate their own research roadmaps and to invest more heavily in this direction. Two obvious answers would be recursive self-improvement (AI systems that can build stronger AI systems, that can build stronger AI systems and so forth) or continual lear"}, {"url": "https://www.gartner.com/en/articles/top-technology-trends-2026", "title": "Gartner Top 10 Strategic Technology Trends for 2026", "content": "1. AI-Native Development Platforms\n2. AI Supercomputing Platforms\n3. Confidential Computing\n4. Multiagent Systems\n5. Domain-Specific Language Models\n6. Physical AI\n7. Preemptive Cybersecurity\n8. Digital Provenance\n9. AI Security Platforms\n10. Geopatriation\n\nBegin Download\n\n## Why these technology trends matter now\n\nTechnology leaders face a pivotal year. These trends are not just technical shifts — they are strategic imperatives. CIOs who act now will be better positioned to:\n\n Align digital strategy with enterprise goals\n Scale AI securely and responsibly\n Navigate geopolitical and regulatory complexity\n Lead transformation with confidence\n\nThis year’s trends are tightly interwoven and reflect the realities of a world where no single capability is enough. Gartner organizes them into three themes that define how leading organizations will innovate, compete and protect value: The Architect, The Synthesist and The Vanguard.", "score": 0.80014634, "raw_content": null, "summary": "CIOs who act now will be better positioned to: Align digital strategy with enterprise goals Scale AI securely and responsibly Navigate geopolitical and regulatory complexity Lead transformation with confidence This year’s trends are tightly interwoven and reflect the realities of a world where no single capability is enough. Gartner organizes them into three themes that define how leading organiza"}, {"url": "https://news.microsoft.com/source/features/ai/whats-next-in-ai-7-trends-to-watch-in-2026/", "title": "What's next in AI: 7 trends to watch in 2026", "content": "Cancel0 Cart 0 items in shopping cart\n\nImage 2Source\n\n   \n   \n   \n   \n   \n\nImage 3: Abstract geometric illustration with floating icons on a blue gradient background\n\nWhat’s next in AI:7 trends to watch in 2026\n\n by Susanna Ray \n\nAI is entering a new phase, one defined by real-world impact.\n\nAfter several years of experimentation, 2026 is shaping up to be the year AI evolves from instrument to partner, transforming how we work, create and solve problems. Across industries, AI is moving beyond answering questions to collaborating with people and amplifying their expertise.\n\nThis transformation is visible everywhere. In medicine, AI is helping close gaps in care. In software development, it’s learning not just code but the context behind it. In scientific research, it’s becoming a true lab assistant. In quantum computing, new hybrid approaches are heralding breakthroughs once thought impossible. [...] As AI agents become digital colleagues and take on specific tasks at human direction, organizations are strengthening security to keep pace with new risks. The infrastructure powering these advances is also maturing, with smarter, more efficient systems.\n\nThese seven trends to watch in 2026 show what’s possible when people join forces with AI.\n\nImage 4\n\nAI will amplify what people can achieve together\n\nAparna Chennapragada, Microsoft’s chief product officer for AI experiences, sees 2026 as a new era for alliances between technology and people. If recent years were about AI answering questions and reasoning through problems, the next wave will be about true collaboration, Chennapragada says.\n\n“The future isn’t about replacing humans,” she says. “It’s about amplifying them.” [...] King points to achievements demonstrated in 2025 by Microsoft AI’s Diagnostic Orchestrator (MAI-DxO), which solved complex medical cases with 85.5% accuracy, far above the 20% average for experienced physicians. With Copilot and Bing already answering more than 50 million health questions daily, he sees advances in AI as a way to give people more influence and control over their own health and wellbeing.\n\nImage 7\n\nAI will become central to the research process\n\nAI is already speeding up breakthroughs in fields like climate modeling, molecular dynamics and materials design, says Peter Lee, president of Microsoft Research. But the next leap is coming. In 2026, AI won’t just summarize papers, answer questions and write reports — it will actively join the process of discovery in physics, chemistry and biology.\n\n“AI will generate hypotheses, use tools and apps that control scientific experiments, and collaborate with both human and AI research colleagues,” Lee says.", "score": 0.7978881, "raw_content": null, "summary": "Cancel0 Cart 0 items in shopping cart Image 2Source Image 3: Abstract geometric illustration with floating icons on a blue gradient background What’s next in AI:7 trends to watch in 2026 by Susanna Ray AI is entering a new phase, one defined by real-world impact. Image 7 AI will become central to the research process AI is already speeding up breakthroughs in fields like climate modeling, molecula"}]}
{"query": "agentic AI (English)", "result": {"query": "agentic AI (English)", "follow_up_questions": null, "answer": null, "images": [], "results": [{"url": "https://www.ibm.com/think/topics/agentic-ai", "title": "What is Agentic AI? | IBM", "content": "# What is agentic AI?\n\n## What is agentic AI?\n\nAgentic AI is an artificial intelligence system that can accomplish a specific goal with limited supervision. It consists of AI agents—machine learning models that mimic human decision-making to solve problems in real time. In a multiagent system, each agent performs a specific subtask required to reach the goal and their efforts are coordinated through AI orchestration.\n\nUnlike traditional AI models, which operate within predefined constraints and require human intervention, agentic AI exhibits autonomy, goal-driven behavior and adaptability. The term “agentic” refers to these models’ agency, or, their capacity to act independently and purposefully. [...] ### Thank you! You are subscribed.\n\nYour subscription will be delivered in English. You will find an unsubscribe link in every newsletter. You can manage your subscriptions or unsubscribe here. Refer to our IBM Privacy Statement for more information.\n\n## What are the advantages of agentic AI?\n\nAgentic systems have many advantages over their generative predecessors, which are limited by the information contained in the datasets upon which models are trained.\n\n### Autonomous\n\nThe most important advancement of agentic systems is that they allow for autonomy to perform tasks without constant human oversight. Agentic systems can maintain long-term goals, manage multistep problem-solving tasks and track progress over time.\n\n### Proactive\n\nAgentic systems provide the flexibility of LLMs, which can generate responses or actions based on nuanced, context-dependent understanding, with the structured, deterministic and reliable features of traditional programming. This approach allows agents to “think” and “do” in a more human-like fashion. [...] Agentic AI builds on generative AI (gen AI) techniques by using large language models (LLMs) to function in dynamic environments. While generative models focus on creating content based on learned patterns, agentic AI extends this capability by applying generative outputs toward specific goals. A generative AI model like OpenAI’s ChatGPT might produce text, images or code, but an agentic AI system can use that generated content to complete complex tasks autonomously by calling external tools. Agents can, for example, not only tell you the best time to climb Mt. Everest given your work schedule, it can also book you a flight and a hotel.\n\nThink Newsletter\n\n### Join over 100,000 subscribers who read the latest news in tech\n\nStay up to date on the most important—and intriguing—industry trends on AI, automation, data and beyond with the Think newsletter. See the IBM Privacy Statement.\n\n### Thank you! You are subscribed.", "score": 0.8963332, "raw_content": null, "summary": "[...] Agentic AI builds on generative AI (gen AI) techniques by using large language models (LLMs) to function in dynamic environments. Think Newsletter ### Join over 100,000 subscribers who read the latest news in tech Stay up to date on the most important—and intriguing—industry trends on AI, automation, data and beyond with the Think newsletter."}, {"url": "https://en.wikipedia.org/wiki/AI_agent", "title": "AI agent - Wikipedia", "content": "In the context of generative artificial intelligence, AI agents (also referred to as compound AI systems or agentic AI) are a class of intelligent agents distinguished by their ability to operate autonomously in complex environments. Agentic AI tools prioritize decision-making over content creation and do not require human prompts or continuous oversight.\n\n## Overview\n\n[edit]\n\nAI agents possess several key attributes, including complex goal structures, natural language interfaces, the capacity to act independently of user supervision, and the integration of software tools or planning systems. Their control flow is frequently driven by large language models (LLMs). Agents also include memory systems for remembering previous user-agent interactions and orchestration software \"Orchestration (computing)\") for organizing agent components.\n\nResearchers and commentators have noted that AI agents do not have a standard definition. The concept of agentic AI has been compared to the fictional character J.A.R.V.I.S..", "score": 0.8773195, "raw_content": null, "summary": "In the context of generative artificial intelligence, AI agents (also referred to as compound AI systems or agentic AI) are a class of intelligent agents distinguished by their ability to operate autonomously in complex environments. ## Overview [edit] AI agents possess several key attributes, including complex goal structures, natural language interfaces, the capacity to act independently of user"}, {"url": "https://www.uipath.com/ai/agentic-ai", "title": "What is Agentic AI? | UiPath", "content": "## What is agentic AI?\n\nAgentic AI refers to artificial intelligence systems that don’t just react or follow preset rules—they act with autonomy, initiative, and adaptability to pursue goals. This form of AI is capable of independently making decisions and taking actions to fulfill objectives in dynamic environments.  Agentic AI is an AI system that combines multiple types of artificial intelligence that, together, make it capable of planning, acting, learning, and improving. Agentic AI systems can:\n\n Make decisions based on context and changing conditions\n Break down goals into sub-tasks and pursue them independently\n Collaborate with tools and other AI systems to get results\n Reflect and adapt over time to get better results [...] These new AI capabilities open up vast new applications for AI across every facet of enterprise operations, and have brought AI agents into being. Agentic AI is brainpower that allows AI agents to act independently within unstructured environments—enabling enterprises to expand automation beyond specific, defined tasks and tackle complex, end-to-end processes.\n\n## Agentic AI and agentic automation [...] ## Agentic AI and agentic automation\n\nAgentic AI is enabling significant new capabilities for automation that vastly expand automation’s impact and potential value for enterprises. Agentic automation can now optimize complex, unstructured processes that traditional rules-based automation can't address by itself. Agentic automation extend’s automation’s footprint far beyond the structured, rules-based, repetitive tasks and processes that robotic process automation (RPA) can address. Now with agentic automation, enterprises can automate the myriad of workflows that require a more dynamic, context-aware approach—enhancing an enterprise’s ability to automate and streamline a entirely new class of complex tasks and business processes: complex decision-making and activities that require high adaptability and real-time action and analysis.\n\nAgentic automation is delivered via an orchestrated, symbiotic combination of AI agents, robots, and people.", "score": 0.87706697, "raw_content": null, "summary": "Agentic AI systems can: Make decisions based on context and changing conditions Break down goals into sub-tasks and pursue them independently Collaborate with tools and other AI systems to get results Reflect and adapt over time to get better results [...] These new AI capabilities open up vast new applications for AI across every facet of enterprise operations, and have brought AI agents into bei"}, {"url": "https://cloud.google.com/discover/what-is-agentic-ai", "title": "What is agentic AI? Definition and differentiators | Google Cloud", "content": "# What is agentic AI?\n\nAgentic AI is an advanced form of artificial intelligence focused on autonomous decision-making and action. Unlike traditional AI, which primarily responds to commands or analyzes data, agentic AI can set goals, plan, and execute tasks with minimal human intervention. This emerging technology has the potential to revolutionize various industries by automating complex processes and optimizing workflows.\n\nGet started for free\n\nAgentic AI: Workflows versus agents\n\n## Key concepts of agentic AI\n\nAgentic AI systems are designed to operate with a higher degree of autonomy. It works by using AI agents, which are essentially autonomous entities designed to perform specific tasks. At its core, this technology is built on several key components: [...] Generative AI, as its name suggests, is focused on the creation of new content, such as text, images, code, or music, based on input prompts. The LLM is at the heart of generative AI, and the value is generated by what the model can do and simple extensions of the LLM's capabilities. For example, you can generate or edit content, and even perform simple function calling and chain together various options.\n\nAgentic AI is a subset of generative AI that is centered around the orchestration and execution of agents that use LLMs as a \"brain\" to perform actions through tools. Agentic AI goes beyond content creation and function calling by executing actions in underlying systems to achieve higher-level goals. [...] 1. Perception: Agentic AI starts by gathering information from its surroundings and different sources, such as sensors, databases, and user interfaces. This could involve analyzing text, images, or other forms of data to understand the situation.\n2. Reasoning: Using a large language model (LLM), agentic AI analyzes the gathered data to understand the context, identify relevant information, and formulate potential solutions. For example, if the goal is to schedule a meeting, the LLM can parse the text of emails to identify attendees, available times, and the meeting's purpose.\n3. Planning: The AI then uses the information it gathered to develop a plan. This involves setting goals, breaking them down into smaller steps, and figuring out the best way to achieve them.\n4. Action: Based on its plan, the AI takes action. This could involve performing tasks, making decisions, or interacting with other systems.", "score": 0.82425016, "raw_content": null, "summary": "The LLM is at the heart of generative AI, and the value is generated by what the model can do and simple extensions of the LLM's capabilities. For example, if the goal is to schedule a meeting, the LLM can parse the text of emails to identify attendees, available times, and the meeting's purpose."}, {"url": "https://www.ibm.com/think/topics/ai-agent-use-cases", "title": "AI Agent Use Cases - IBM", "content": "## How do AI agents work?\n\nAgentic AI is based primarily on large language models (LLMs). Where traditional LLMs produced outputs based solely on the data used to train them and possessed limited reasoning abilities, AI agents are empowered to call on additional tools and APIs to meet more difficult goals. Agentic AI can autonomously obtain current data, optimize workflows and create subtasks based on its objectives. With advancements in gen AI and conversational AI technology, some agents interact with their human counterparts in natural language. And unlike previous LLMs or chatbots, AI agents store memory from one interaction to the other, improving reasoning power and accuracy over time.\n\nGenerally, AI agents are most useful when developed as part of a network. There are five central types of AI agents with varying levels of complexity. They are:\n\n Simple reflex agents, which perform based on a single set of rules. They do not hold memory or query other agents if they’re missing information. [...] Unlike previous AI tools, which relied on direct and continuous human input, agentic AI allows creators to scale content output rapidly with minimal human oversight, maintaining quality and consistency throughout. For example, the Associated Press uses AI to generate basic news articles on data-driven topics like sports scores or financial reports, increasing the volume of content production and reducing human workloads.\n\n### Customer experience\n\nGiven sharply rising customer expectations, and high levels of burnout among customer service representatives, AI agents can be particularly useful applied to customer experience. With their ability to improve responses over time and recall relevant customer data in real-time, agents deliver deeply contextual and hyper-personalized experiences.", "score": 0.79845446, "raw_content": null, "summary": "Where traditional LLMs produced outputs based solely on the data used to train them and possessed limited reasoning abilities, AI agents are empowered to call on additional tools and APIs to meet more difficult goals. [...] Unlike previous AI tools, which relied on direct and continuous human input, agentic AI allows creators to scale content output rapidly with minimal human oversight, maintainin"}], "response_time": 1.54, "request_id": "ac6e0dfa-e5d2-4daf-bb09-40d6d25ef905"}, "query_summary": "Think Newsletter ### Join over 100,000 subscribers who read the latest news in tech Stay up to date on the most important—and intriguing—industry trends on AI, automation, data and beyond with the Think newsletter. In the context of generative artificial intelligence, AI agents (also referred to as compound AI systems or agentic AI) are a class of intelligent agents distinguished by their ability to operate autonomously in complex environments. ## Overview [edit] AI agents possess several key attributes, including complex goal structures, natural language interfaces, the capacity to act indepe", "lang_pref": "en", "preferred_results": [{"url": "https://www.ibm.com/think/topics/agentic-ai", "title": "What is Agentic AI? | IBM", "content": "# What is agentic AI?\n\n## What is agentic AI?\n\nAgentic AI is an artificial intelligence system that can accomplish a specific goal with limited supervision. It consists of AI agents—machine learning models that mimic human decision-making to solve problems in real time. In a multiagent system, each agent performs a specific subtask required to reach the goal and their efforts are coordinated through AI orchestration.\n\nUnlike traditional AI models, which operate within predefined constraints and require human intervention, agentic AI exhibits autonomy, goal-driven behavior and adaptability. The term “agentic” refers to these models’ agency, or, their capacity to act independently and purposefully. [...] ### Thank you! You are subscribed.\n\nYour subscription will be delivered in English. You will find an unsubscribe link in every newsletter. You can manage your subscriptions or unsubscribe here. Refer to our IBM Privacy Statement for more information.\n\n## What are the advantages of agentic AI?\n\nAgentic systems have many advantages over their generative predecessors, which are limited by the information contained in the datasets upon which models are trained.\n\n### Autonomous\n\nThe most important advancement of agentic systems is that they allow for autonomy to perform tasks without constant human oversight. Agentic systems can maintain long-term goals, manage multistep problem-solving tasks and track progress over time.\n\n### Proactive\n\nAgentic systems provide the flexibility of LLMs, which can generate responses or actions based on nuanced, context-dependent understanding, with the structured, deterministic and reliable features of traditional programming. This approach allows agents to “think” and “do” in a more human-like fashion. [...] Agentic AI builds on generative AI (gen AI) techniques by using large language models (LLMs) to function in dynamic environments. While generative models focus on creating content based on learned patterns, agentic AI extends this capability by applying generative outputs toward specific goals. A generative AI model like OpenAI’s ChatGPT might produce text, images or code, but an agentic AI system can use that generated content to complete complex tasks autonomously by calling external tools. Agents can, for example, not only tell you the best time to climb Mt. Everest given your work schedule, it can also book you a flight and a hotel.\n\nThink Newsletter\n\n### Join over 100,000 subscribers who read the latest news in tech\n\nStay up to date on the most important—and intriguing—industry trends on AI, automation, data and beyond with the Think newsletter. See the IBM Privacy Statement.\n\n### Thank you! You are subscribed.", "score": 0.8963332, "raw_content": null, "summary": "[...] Agentic AI builds on generative AI (gen AI) techniques by using large language models (LLMs) to function in dynamic environments. Think Newsletter ### Join over 100,000 subscribers who read the latest news in tech Stay up to date on the most important—and intriguing—industry trends on AI, automation, data and beyond with the Think newsletter."}, {"url": "https://en.wikipedia.org/wiki/AI_agent", "title": "AI agent - Wikipedia", "content": "In the context of generative artificial intelligence, AI agents (also referred to as compound AI systems or agentic AI) are a class of intelligent agents distinguished by their ability to operate autonomously in complex environments. Agentic AI tools prioritize decision-making over content creation and do not require human prompts or continuous oversight.\n\n## Overview\n\n[edit]\n\nAI agents possess several key attributes, including complex goal structures, natural language interfaces, the capacity to act independently of user supervision, and the integration of software tools or planning systems. Their control flow is frequently driven by large language models (LLMs). Agents also include memory systems for remembering previous user-agent interactions and orchestration software \"Orchestration (computing)\") for organizing agent components.\n\nResearchers and commentators have noted that AI agents do not have a standard definition. The concept of agentic AI has been compared to the fictional character J.A.R.V.I.S..", "score": 0.8773195, "raw_content": null, "summary": "In the context of generative artificial intelligence, AI agents (also referred to as compound AI systems or agentic AI) are a class of intelligent agents distinguished by their ability to operate autonomously in complex environments. ## Overview [edit] AI agents possess several key attributes, including complex goal structures, natural language interfaces, the capacity to act independently of user"}, {"url": "https://www.uipath.com/ai/agentic-ai", "title": "What is Agentic AI? | UiPath", "content": "## What is agentic AI?\n\nAgentic AI refers to artificial intelligence systems that don’t just react or follow preset rules—they act with autonomy, initiative, and adaptability to pursue goals. This form of AI is capable of independently making decisions and taking actions to fulfill objectives in dynamic environments.  Agentic AI is an AI system that combines multiple types of artificial intelligence that, together, make it capable of planning, acting, learning, and improving. Agentic AI systems can:\n\n Make decisions based on context and changing conditions\n Break down goals into sub-tasks and pursue them independently\n Collaborate with tools and other AI systems to get results\n Reflect and adapt over time to get better results [...] These new AI capabilities open up vast new applications for AI across every facet of enterprise operations, and have brought AI agents into being. Agentic AI is brainpower that allows AI agents to act independently within unstructured environments—enabling enterprises to expand automation beyond specific, defined tasks and tackle complex, end-to-end processes.\n\n## Agentic AI and agentic automation [...] ## Agentic AI and agentic automation\n\nAgentic AI is enabling significant new capabilities for automation that vastly expand automation’s impact and potential value for enterprises. Agentic automation can now optimize complex, unstructured processes that traditional rules-based automation can't address by itself. Agentic automation extend’s automation’s footprint far beyond the structured, rules-based, repetitive tasks and processes that robotic process automation (RPA) can address. Now with agentic automation, enterprises can automate the myriad of workflows that require a more dynamic, context-aware approach—enhancing an enterprise’s ability to automate and streamline a entirely new class of complex tasks and business processes: complex decision-making and activities that require high adaptability and real-time action and analysis.\n\nAgentic automation is delivered via an orchestrated, symbiotic combination of AI agents, robots, and people.", "score": 0.87706697, "raw_content": null, "summary": "Agentic AI systems can: Make decisions based on context and changing conditions Break down goals into sub-tasks and pursue them independently Collaborate with tools and other AI systems to get results Reflect and adapt over time to get better results [...] These new AI capabilities open up vast new applications for AI across every facet of enterprise operations, and have brought AI agents into bei"}, {"url": "https://cloud.google.com/discover/what-is-agentic-ai", "title": "What is agentic AI? Definition and differentiators | Google Cloud", "content": "# What is agentic AI?\n\nAgentic AI is an advanced form of artificial intelligence focused on autonomous decision-making and action. Unlike traditional AI, which primarily responds to commands or analyzes data, agentic AI can set goals, plan, and execute tasks with minimal human intervention. This emerging technology has the potential to revolutionize various industries by automating complex processes and optimizing workflows.\n\nGet started for free\n\nAgentic AI: Workflows versus agents\n\n## Key concepts of agentic AI\n\nAgentic AI systems are designed to operate with a higher degree of autonomy. It works by using AI agents, which are essentially autonomous entities designed to perform specific tasks. At its core, this technology is built on several key components: [...] Generative AI, as its name suggests, is focused on the creation of new content, such as text, images, code, or music, based on input prompts. The LLM is at the heart of generative AI, and the value is generated by what the model can do and simple extensions of the LLM's capabilities. For example, you can generate or edit content, and even perform simple function calling and chain together various options.\n\nAgentic AI is a subset of generative AI that is centered around the orchestration and execution of agents that use LLMs as a \"brain\" to perform actions through tools. Agentic AI goes beyond content creation and function calling by executing actions in underlying systems to achieve higher-level goals. [...] 1. Perception: Agentic AI starts by gathering information from its surroundings and different sources, such as sensors, databases, and user interfaces. This could involve analyzing text, images, or other forms of data to understand the situation.\n2. Reasoning: Using a large language model (LLM), agentic AI analyzes the gathered data to understand the context, identify relevant information, and formulate potential solutions. For example, if the goal is to schedule a meeting, the LLM can parse the text of emails to identify attendees, available times, and the meeting's purpose.\n3. Planning: The AI then uses the information it gathered to develop a plan. This involves setting goals, breaking them down into smaller steps, and figuring out the best way to achieve them.\n4. Action: Based on its plan, the AI takes action. This could involve performing tasks, making decisions, or interacting with other systems.", "score": 0.82425016, "raw_content": null, "summary": "The LLM is at the heart of generative AI, and the value is generated by what the model can do and simple extensions of the LLM's capabilities. For example, if the goal is to schedule a meeting, the LLM can parse the text of emails to identify attendees, available times, and the meeting's purpose."}, {"url": "https://www.ibm.com/think/topics/ai-agent-use-cases", "title": "AI Agent Use Cases - IBM", "content": "## How do AI agents work?\n\nAgentic AI is based primarily on large language models (LLMs). Where traditional LLMs produced outputs based solely on the data used to train them and possessed limited reasoning abilities, AI agents are empowered to call on additional tools and APIs to meet more difficult goals. Agentic AI can autonomously obtain current data, optimize workflows and create subtasks based on its objectives. With advancements in gen AI and conversational AI technology, some agents interact with their human counterparts in natural language. And unlike previous LLMs or chatbots, AI agents store memory from one interaction to the other, improving reasoning power and accuracy over time.\n\nGenerally, AI agents are most useful when developed as part of a network. There are five central types of AI agents with varying levels of complexity. They are:\n\n Simple reflex agents, which perform based on a single set of rules. They do not hold memory or query other agents if they’re missing information. [...] Unlike previous AI tools, which relied on direct and continuous human input, agentic AI allows creators to scale content output rapidly with minimal human oversight, maintaining quality and consistency throughout. For example, the Associated Press uses AI to generate basic news articles on data-driven topics like sports scores or financial reports, increasing the volume of content production and reducing human workloads.\n\n### Customer experience\n\nGiven sharply rising customer expectations, and high levels of burnout among customer service representatives, AI agents can be particularly useful applied to customer experience. With their ability to improve responses over time and recall relevant customer data in real-time, agents deliver deeply contextual and hyper-personalized experiences.", "score": 0.79845446, "raw_content": null, "summary": "Where traditional LLMs produced outputs based solely on the data used to train them and possessed limited reasoning abilities, AI agents are empowered to call on additional tools and APIs to meet more difficult goals. [...] Unlike previous AI tools, which relied on direct and continuous human input, agentic AI allows creators to scale content output rapidly with minimal human oversight, maintainin"}]}
{"query": "physical AI robotics (English)", "result": {"query": "physical AI robotics (English)", "follow_up_questions": null, "answer": null, "images": [], "results": [{"url": "https://www.nvidia.com/en-us/glossary/generative-physical-ai/", "title": "What is Physical AI? | NVIDIA Glossary", "content": "Robots: Physical AI elevates robots from rigid automation to true autonomy. Enabling them to sense, reason, and act in real time helps them perform with greater safety, precision, and adaptability in any environment.\n\n Autonomous Mobile Robots (AMRs) in warehouses can navigate complex environments and avoid obstacles, including humans, by using direct feedback from onboard sensors.\n Manipulators, or robot arms, can adjust their grasping strength and position based on the pose of objects on a conveyor belt, showcasing both fine and gross motor skills tailored to the object type.\n Surgical robots benefit from this technology by learning intricate tasks such as threading needles and performing stitches, highlighting the precision and adaptability of physical AI in training robots for specialized tasks.\n Humanoid robots—or general-purpose robots—need both gross and fine motor skills, as well as the ability to perceive, understand, reason, and interact with the physical world, no matter what the given task is. [...] 1. Physical AI\n\n# What is Physical AI?\n\nPhysical AI lets autonomous systems like cameras, robots, and self-driving cars perceive, understand, reason, and perform or orchestrate complex actions in the physical world.\n\n## Why Is Physical AI Important?\n\nPreviously, autonomous machines were unable to perceive and sense the world around them. But with physical AI, robots can be built and trained to seamlessly interact with and adapt to their surroundings in the real world.\n\nTo build physical AI, teams need powerful, physics-based simulations that provide a safe, controlled environment for training autonomous machines. This not only enhances the efficiency and accuracy of robots in performing complex tasks but also facilitates more natural interactions between humans and machines, improving accessibility and functionality in real-world applications.\n\nPhysical AI is unlocking new capabilities that will transform every industry. For example: [...] Autonomous Vehicles (AVs): Physical AI lets AVs process sensor data in real-time to perceive and understand their surroundings. Reasoning vision-language-action (VLA) models use this data to make informed decisions in various environments, from open freeways to urban cityscapes. Training AVs in scalable, physically accurate simulation environments helps them more accurately detect pedestrians, respond to traffic or weather conditions, and autonomously navigate lane changes, effectively adapting to a wide range of unexpected scenarios.\n\nSmart Spaces: Physical AI is enhancing the functionality and safety of large indoor and outdoor spaces like factories and warehouses, where daily activities involve steady traffic of people, vehicles, and robots. Using fixed cameras and advanced computer vision models, teams can enhance dynamic route planning and optimize operational efficiency by tracking multiple entities and activities within these spaces. Video analytics AI agents further improve safety and operational efficiency by automatically detecting anomalies and providing real-time alerts.\n\n## How Does Physical AI Work?", "score": 0.77548623, "raw_content": null, "summary": "Humanoid robots—or general-purpose robots—need both gross and fine motor skills, as well as the ability to perceive, understand, reason, and interact with the physical world, no matter what the given task is. Smart Spaces: Physical AI is enhancing the functionality and safety of large indoor and outdoor spaces like factories and warehouses, where daily activities involve steady traffic of people,"}, {"url": "https://www.automate.org/ai/industry-insights/physical-ai-in-robotics-teaching-robots-to-learn-and-adapt", "title": "Industry Insights: Physical AI in Robotics | Teaching Robots to Learn ...", "content": "For AI to function properly, it needs real-world information. Traditional AI relies on reactive, rule-based coding that stipulates the predetermined rules and expected response at each step of a task. Any deviation from the predetermined parameters requires human intervention to update or change the rules so the robot continues to function.\n\n## Physical AI in Action\n\nPhysical AI applications bring artificial intelligence out of the digital realm and into the physical world, where machines integrated with AI in the physical body can sense, move, and act in real and dynamic environments. These systems combine AI with robotics, sensors, and advanced motion control to perform tasks that once required human intervention. That’s because, in addition to being able to analyze data, physical AI can translate the intelligence gleaned from the data into physical action. [...] ## Traditional AI vs. Physical AI\n\nArtificial intelligence has been used for several years to analyze big datasets quickly. Its applications in theoretical research are leading to advances in technology, science, biomedical research and academic research that benefits from the rapid identification, cataloguing and analysis of reams of information to a more manageable subset. Theoretical applications in the digital world of AI, which is intended to provide clarity and answers about the universe, the world, or medical and scientific research are the best understood uses of AI for most people.\n\nRecently, there has been a surge in the use of AI for real-world applications, especially in the field of robotics. Whereas digital AI focuses on theoretical applications, physical AI employs machine learning and AI to “teach” a robot how to do tasks that were historically too complex for a machine to complete. Rather than relying on complex foundation models and coding, this AI application relies on machine learning and reinforcement learning to improve the robot’s ability to complete complex tasks. [...] In healthcare, robots like Moxi assist nurses by transporting supplies, while exoskeletons help patients regain mobility. In logistics and manufacturing, AI-driven robots streamline warehouse operations, handle packages, and work safely alongside people. Autonomous vehicles and drones extend physical AI into transportation and delivery, enabling efficient, contactless movement of goods and people.\n\nEven social and companion robots demonstrate physical AI by recognizing emotions, responding to speech, and interacting naturally with humans. Across industries, these applications highlight AI’s growing role not just in thinking, but in doing, bridging digital intelligence with real-world action.\n\n## Challenges with Integrating Physical AI\n\nBringing physical AI into the real world isn’t easy though. Companies face challenges with safety, reliability, cost, and making sure these intelligent machines can work smoothly alongside people and existing systems.", "score": 0.73981786, "raw_content": null, "summary": "## Physical AI in Action Physical AI applications bring artificial intelligence out of the digital realm and into the physical world, where machines integrated with AI in the physical body can sense, move, and act in real and dynamic environments. Theoretical applications in the digital world of AI, which is intended to provide clarity and answers about the universe, the world, or medical and scie"}, {"url": "https://www.bvp.com/atlas/intelligent-robotics-the-new-era-of-physical-ai", "title": "Intelligent robotics: The new era of physical AI", "content": "This presentation shares Bessemer’s internal exploration of emerging trends and tailwinds in robotics and physical AI, now made public to highlight why this area excites us and where we see compelling investment opportunities developing. Historically, investing in robotics has been challenging — the category has required significant capital, and commercialization and innovation cycles in deep tech are longer in comparison to SaaS markets. But rapid advances in edge computing, commoditized hardware, and powerful AI models are creating real disruptive possibilities and potentially rewriting the playbook for robotics investment.\n\nThe following slideshow walks through our findings, including the accelerating research pace, talent migration from leading AI labs into robotics startups, and breakthroughs in hardware and compute. All of these findings and more are contributing to what could be a turning point for physical AI. [...] Skip To Content \n\nJump around\n\nFull slide deck\n\n Key insights on intelligent robotics\n\nContributors\n\nAlexandra Sukin Talia Goldberg Bhavik Nagda\n\nShare\n\nSubscribe\n\n11.4.25\n\nAI & ML\n\n# Intelligent robotics: The new era of physical AI\n\n## How robotics, edge computing, and AI are transforming physical automation — and the investment opportunities we see ahead.\n\nPhysical AI is entering the innovation spotlight, moving AI beyond digital confines and into the real world of robotics and automation. Over the last year, top-level AI talent has significantly increased its focus toward “physical AI,” driving dramatic innovation in how machines interact with and shape our environment. [...] Global labor shortages and demographic trends across the US, Europe, Japan, and China are driving demand for robotics to augment and replace human labor.\n A “ChatGPT” moment for robotics is still a few years away, but pragmatic applications are generating meaningful returns now.\n Breakthroughs in “sim-to-real” transfer for locomotion tasks relied on reinforcement learning and simulation, but manipulation tasks face bigger challenges due to complex real-world dynamics.\n Scalability in robotics hinges on collecting diverse, real-world demonstration data — currently costly and limited, prompting industry efforts to sell or aggregate such data for broader use cases.\n High-value, end-to-end autonomy in constrained domains (like surgical robots and self-driving cars) demonstrates superior results compared to human operation in certain niches.\n The emerging robotics ecosystem comprises commoditized hardware, democratized AI capabilities through foundation models, and critical infrastructure layers such as logging, simulation, and visualization platforms to support development.", "score": 0.7216064, "raw_content": null, "summary": "This presentation shares Bessemer’s internal exploration of emerging trends and tailwinds in robotics and physical AI, now made public to highlight why this area excites us and where we see compelling investment opportunities developing. [...] Skip To Content Jump around Full slide deck Key insights on intelligent robotics Contributors Alexandra Sukin Talia Goldberg Bhavik Nagda Share Subscribe 11"}, {"url": "https://www.reuters.com/business/autos-transportation/arm-launches-physical-ai-division-expand-robotics-market-2026-01-07/", "title": "Arm launches 'Physical AI' unit, joining rush to robotics by tech and ...", "content": "Summary\n Companies\n\n Arm reorganizes into three main business lines, including Physical AI\n Physical AI unit to focus on robotics and automotive sectors\n Arm sees robotics as a significant growth opportunity, plans to expand staff\n\nJan 7 (Reuters) - Chip technology company Arm Holdings has reorganized the company to create a Physical AI unit to expand its presence in the robotics market, company executives told Reuters at CES, where robots are a theme of the year.\n\nThe decision to create a unit that specializes in robotics arrives amid a flurry of announcements and activity at CES around humanoid robots. At the sprawling Las Vegas trade show, large and small companies demonstrated robots that could help build cars, clean toilets and deal games of poker - at a glacial pace.\n\nSign uphere. [...] Sign uphere.\n\nReuters is reporting the creation of Arm's Physical AI unit and reorganization for the first time. Arm will now operate three main lines of business: its Cloud and AI, Edge - which includes its mobile devices and PC products - and Physical AI, which will house its automotive business.\n\nRobots and autos are the core of physical AI and share a wide range of existing sensor tech and other hardware. Automakers including Tesla (TSLA.O), opens new tab are creating robots to automate warehouse and factory tasks.\n\nUK-based Arm does not make chips itself but supplies the underlying technology that powers most of the world's smartphones and a growing number of other devices such as laptops and data center chips. The company makes money by charging licensing fees and collecting royalties when its designs are used. [...] The company's expanded focus on Physical AI is part of a larger effort to increase the business. Since CEO Rene Haas took over the company roughly four years ago, Arm has developed ways to hike prices for its latest technology and is considering its own full chip design.\n\nArm executives see robotics as a market with immense potential for growth in the long run. The head of the newly formed unit, Drew Henry, told Reuters that physical AI solutions could \"fundamentally enhance labor, free up extra time\" and may have a considerable impact on gross domestic product as a result. That division plans to add staff dedicated to robotics, Arm Chief Marketing Officer Ami Badani said.\n\nThe company combined automotive and robotics into a single unit because the customer requirements for things such as power constraints, safety and reliability are similar, Badani said. Several automakers are moving into humanoid robotics, as well.", "score": 0.7173491, "raw_content": null, "summary": "Summary Companies Arm reorganizes into three main business lines, including Physical AI Physical AI unit to focus on robotics and automotive sectors Arm sees robotics as a significant growth opportunity, plans to expand staff Jan 7 (Reuters) - Chip technology company Arm Holdings has reorganized the company to create a Physical AI unit to expand its presence in the robotics market, company executi"}, {"url": "https://www.deloitte.com/us/en/insights/topics/technology-management/tech-trends/2026/physical-ai-humanoid-robots.html", "title": "AI goes physical: Navigating the convergence of AI and robotics", "content": "During the next decade, the intersection of agentic AI systems with physical AI robotic systems will result in robots whose “brains” are agentic AIs. Robots of all form factors should increasingly be able to adapt to new environments, plan multistep tasks, recover from failure, and operate under uncertainty. The impact of this technology convergence will be particularly profound for humanoid robots.\n\nInstead of custom robotics for each domain, more general agentic modules may be reused across warehouses, homes, health care, agriculture, and other areas. Agentic humanoids could one day function as assistants, coworkers, or health care aides with more intuitive interaction, reasoning, and negotiation capabilities. [...] Human acceptance.While most workers are generally comfortable with predictable, rule-based robots, physical AI systems that learn and adapt introduce new uncertainties, especially worries about job displacement. However, experts predict that most roles will evolve toward collaboration rather than replacement.17 The goal is to create environments where robots handle repetitive or dangerous tasks while humans focus on creative problem-solving and complex decision-making.\n\nCybersecurity vulnerabilities. As discussed in “The AI dilemma,” physical AI systems create new attack surfaces that bridge digital and physical domains. Connected fleets increase cyber risks, with vulnerabilities potentially leading to unauthorized access, data breaches, or even malicious robot control. The stakes are even higher when security breaches can affect physical safety and operational continuity. [...] Image 19\n\nAyanna Howard is the dean of the College of Engineering at The Ohio State University and a prominent roboticist and advocate for AI safety and alignment. Previously, she was a senior robotics researcher at NASA’s Jet Propulsion Laboratory and later chaired Georgia Tech’s School of Interactive Computing and founded the Human-Automation Systems Lab. Watch the interview.\n\nQ: What technology challenges are holding back progress in physical AI and robotics?\n\nA: One of the fundamental challenges is that the physical world is inherently dynamic. I can walk into my office every day, but there’s always some difference—maybe someone vacuumed, moved things around, or my computer doesn’t boot up. The question is, how do you simulate all these variations so robots can learn to adapt, walk, lift, and interact with uncertainty the way humans do? You can’t just practice endlessly in the real world because you’ll break things.", "score": 0.67527276, "raw_content": null, "summary": "During the next decade, the intersection of agentic AI systems with physical AI robotic systems will result in robots whose “brains” are agentic AIs. [...] Image 19 Ayanna Howard is the dean of the College of Engineering at The Ohio State University and a prominent roboticist and advocate for AI safety and alignment."}], "response_time": 1.8, "request_id": "46342ef2-851d-4e89-8b88-bb72c7c97906"}, "query_summary": "Smart Spaces: Physical AI is enhancing the functionality and safety of large indoor and outdoor spaces like factories and warehouses, where daily activities involve steady traffic of people, ## Physical AI in Action Physical AI applications bring artificial intelligence out of the digital realm and into the physical world, where machines integrated with AI in the physical body can sense, move, and act in real and dynamic environments. Theoretical applications in the digital world of AI, which is intended to provide clarity and answers about the universe, the world, or medical and scie This pre", "lang_pref": "en", "preferred_results": [{"url": "https://www.nvidia.com/en-us/glossary/generative-physical-ai/", "title": "What is Physical AI? | NVIDIA Glossary", "content": "Robots: Physical AI elevates robots from rigid automation to true autonomy. Enabling them to sense, reason, and act in real time helps them perform with greater safety, precision, and adaptability in any environment.\n\n Autonomous Mobile Robots (AMRs) in warehouses can navigate complex environments and avoid obstacles, including humans, by using direct feedback from onboard sensors.\n Manipulators, or robot arms, can adjust their grasping strength and position based on the pose of objects on a conveyor belt, showcasing both fine and gross motor skills tailored to the object type.\n Surgical robots benefit from this technology by learning intricate tasks such as threading needles and performing stitches, highlighting the precision and adaptability of physical AI in training robots for specialized tasks.\n Humanoid robots—or general-purpose robots—need both gross and fine motor skills, as well as the ability to perceive, understand, reason, and interact with the physical world, no matter what the given task is. [...] 1. Physical AI\n\n# What is Physical AI?\n\nPhysical AI lets autonomous systems like cameras, robots, and self-driving cars perceive, understand, reason, and perform or orchestrate complex actions in the physical world.\n\n## Why Is Physical AI Important?\n\nPreviously, autonomous machines were unable to perceive and sense the world around them. But with physical AI, robots can be built and trained to seamlessly interact with and adapt to their surroundings in the real world.\n\nTo build physical AI, teams need powerful, physics-based simulations that provide a safe, controlled environment for training autonomous machines. This not only enhances the efficiency and accuracy of robots in performing complex tasks but also facilitates more natural interactions between humans and machines, improving accessibility and functionality in real-world applications.\n\nPhysical AI is unlocking new capabilities that will transform every industry. For example: [...] Autonomous Vehicles (AVs): Physical AI lets AVs process sensor data in real-time to perceive and understand their surroundings. Reasoning vision-language-action (VLA) models use this data to make informed decisions in various environments, from open freeways to urban cityscapes. Training AVs in scalable, physically accurate simulation environments helps them more accurately detect pedestrians, respond to traffic or weather conditions, and autonomously navigate lane changes, effectively adapting to a wide range of unexpected scenarios.\n\nSmart Spaces: Physical AI is enhancing the functionality and safety of large indoor and outdoor spaces like factories and warehouses, where daily activities involve steady traffic of people, vehicles, and robots. Using fixed cameras and advanced computer vision models, teams can enhance dynamic route planning and optimize operational efficiency by tracking multiple entities and activities within these spaces. Video analytics AI agents further improve safety and operational efficiency by automatically detecting anomalies and providing real-time alerts.\n\n## How Does Physical AI Work?", "score": 0.77548623, "raw_content": null, "summary": "Humanoid robots—or general-purpose robots—need both gross and fine motor skills, as well as the ability to perceive, understand, reason, and interact with the physical world, no matter what the given task is. Smart Spaces: Physical AI is enhancing the functionality and safety of large indoor and outdoor spaces like factories and warehouses, where daily activities involve steady traffic of people,"}, {"url": "https://www.automate.org/ai/industry-insights/physical-ai-in-robotics-teaching-robots-to-learn-and-adapt", "title": "Industry Insights: Physical AI in Robotics | Teaching Robots to Learn ...", "content": "For AI to function properly, it needs real-world information. Traditional AI relies on reactive, rule-based coding that stipulates the predetermined rules and expected response at each step of a task. Any deviation from the predetermined parameters requires human intervention to update or change the rules so the robot continues to function.\n\n## Physical AI in Action\n\nPhysical AI applications bring artificial intelligence out of the digital realm and into the physical world, where machines integrated with AI in the physical body can sense, move, and act in real and dynamic environments. These systems combine AI with robotics, sensors, and advanced motion control to perform tasks that once required human intervention. That’s because, in addition to being able to analyze data, physical AI can translate the intelligence gleaned from the data into physical action. [...] ## Traditional AI vs. Physical AI\n\nArtificial intelligence has been used for several years to analyze big datasets quickly. Its applications in theoretical research are leading to advances in technology, science, biomedical research and academic research that benefits from the rapid identification, cataloguing and analysis of reams of information to a more manageable subset. Theoretical applications in the digital world of AI, which is intended to provide clarity and answers about the universe, the world, or medical and scientific research are the best understood uses of AI for most people.\n\nRecently, there has been a surge in the use of AI for real-world applications, especially in the field of robotics. Whereas digital AI focuses on theoretical applications, physical AI employs machine learning and AI to “teach” a robot how to do tasks that were historically too complex for a machine to complete. Rather than relying on complex foundation models and coding, this AI application relies on machine learning and reinforcement learning to improve the robot’s ability to complete complex tasks. [...] In healthcare, robots like Moxi assist nurses by transporting supplies, while exoskeletons help patients regain mobility. In logistics and manufacturing, AI-driven robots streamline warehouse operations, handle packages, and work safely alongside people. Autonomous vehicles and drones extend physical AI into transportation and delivery, enabling efficient, contactless movement of goods and people.\n\nEven social and companion robots demonstrate physical AI by recognizing emotions, responding to speech, and interacting naturally with humans. Across industries, these applications highlight AI’s growing role not just in thinking, but in doing, bridging digital intelligence with real-world action.\n\n## Challenges with Integrating Physical AI\n\nBringing physical AI into the real world isn’t easy though. Companies face challenges with safety, reliability, cost, and making sure these intelligent machines can work smoothly alongside people and existing systems.", "score": 0.73981786, "raw_content": null, "summary": "## Physical AI in Action Physical AI applications bring artificial intelligence out of the digital realm and into the physical world, where machines integrated with AI in the physical body can sense, move, and act in real and dynamic environments. Theoretical applications in the digital world of AI, which is intended to provide clarity and answers about the universe, the world, or medical and scie"}, {"url": "https://www.bvp.com/atlas/intelligent-robotics-the-new-era-of-physical-ai", "title": "Intelligent robotics: The new era of physical AI", "content": "This presentation shares Bessemer’s internal exploration of emerging trends and tailwinds in robotics and physical AI, now made public to highlight why this area excites us and where we see compelling investment opportunities developing. Historically, investing in robotics has been challenging — the category has required significant capital, and commercialization and innovation cycles in deep tech are longer in comparison to SaaS markets. But rapid advances in edge computing, commoditized hardware, and powerful AI models are creating real disruptive possibilities and potentially rewriting the playbook for robotics investment.\n\nThe following slideshow walks through our findings, including the accelerating research pace, talent migration from leading AI labs into robotics startups, and breakthroughs in hardware and compute. All of these findings and more are contributing to what could be a turning point for physical AI. [...] Skip To Content \n\nJump around\n\nFull slide deck\n\n Key insights on intelligent robotics\n\nContributors\n\nAlexandra Sukin Talia Goldberg Bhavik Nagda\n\nShare\n\nSubscribe\n\n11.4.25\n\nAI & ML\n\n# Intelligent robotics: The new era of physical AI\n\n## How robotics, edge computing, and AI are transforming physical automation — and the investment opportunities we see ahead.\n\nPhysical AI is entering the innovation spotlight, moving AI beyond digital confines and into the real world of robotics and automation. Over the last year, top-level AI talent has significantly increased its focus toward “physical AI,” driving dramatic innovation in how machines interact with and shape our environment. [...] Global labor shortages and demographic trends across the US, Europe, Japan, and China are driving demand for robotics to augment and replace human labor.\n A “ChatGPT” moment for robotics is still a few years away, but pragmatic applications are generating meaningful returns now.\n Breakthroughs in “sim-to-real” transfer for locomotion tasks relied on reinforcement learning and simulation, but manipulation tasks face bigger challenges due to complex real-world dynamics.\n Scalability in robotics hinges on collecting diverse, real-world demonstration data — currently costly and limited, prompting industry efforts to sell or aggregate such data for broader use cases.\n High-value, end-to-end autonomy in constrained domains (like surgical robots and self-driving cars) demonstrates superior results compared to human operation in certain niches.\n The emerging robotics ecosystem comprises commoditized hardware, democratized AI capabilities through foundation models, and critical infrastructure layers such as logging, simulation, and visualization platforms to support development.", "score": 0.7216064, "raw_content": null, "summary": "This presentation shares Bessemer’s internal exploration of emerging trends and tailwinds in robotics and physical AI, now made public to highlight why this area excites us and where we see compelling investment opportunities developing. [...] Skip To Content Jump around Full slide deck Key insights on intelligent robotics Contributors Alexandra Sukin Talia Goldberg Bhavik Nagda Share Subscribe 11"}, {"url": "https://www.reuters.com/business/autos-transportation/arm-launches-physical-ai-division-expand-robotics-market-2026-01-07/", "title": "Arm launches 'Physical AI' unit, joining rush to robotics by tech and ...", "content": "Summary\n Companies\n\n Arm reorganizes into three main business lines, including Physical AI\n Physical AI unit to focus on robotics and automotive sectors\n Arm sees robotics as a significant growth opportunity, plans to expand staff\n\nJan 7 (Reuters) - Chip technology company Arm Holdings has reorganized the company to create a Physical AI unit to expand its presence in the robotics market, company executives told Reuters at CES, where robots are a theme of the year.\n\nThe decision to create a unit that specializes in robotics arrives amid a flurry of announcements and activity at CES around humanoid robots. At the sprawling Las Vegas trade show, large and small companies demonstrated robots that could help build cars, clean toilets and deal games of poker - at a glacial pace.\n\nSign uphere. [...] Sign uphere.\n\nReuters is reporting the creation of Arm's Physical AI unit and reorganization for the first time. Arm will now operate three main lines of business: its Cloud and AI, Edge - which includes its mobile devices and PC products - and Physical AI, which will house its automotive business.\n\nRobots and autos are the core of physical AI and share a wide range of existing sensor tech and other hardware. Automakers including Tesla (TSLA.O), opens new tab are creating robots to automate warehouse and factory tasks.\n\nUK-based Arm does not make chips itself but supplies the underlying technology that powers most of the world's smartphones and a growing number of other devices such as laptops and data center chips. The company makes money by charging licensing fees and collecting royalties when its designs are used. [...] The company's expanded focus on Physical AI is part of a larger effort to increase the business. Since CEO Rene Haas took over the company roughly four years ago, Arm has developed ways to hike prices for its latest technology and is considering its own full chip design.\n\nArm executives see robotics as a market with immense potential for growth in the long run. The head of the newly formed unit, Drew Henry, told Reuters that physical AI solutions could \"fundamentally enhance labor, free up extra time\" and may have a considerable impact on gross domestic product as a result. That division plans to add staff dedicated to robotics, Arm Chief Marketing Officer Ami Badani said.\n\nThe company combined automotive and robotics into a single unit because the customer requirements for things such as power constraints, safety and reliability are similar, Badani said. Several automakers are moving into humanoid robotics, as well.", "score": 0.7173491, "raw_content": null, "summary": "Summary Companies Arm reorganizes into three main business lines, including Physical AI Physical AI unit to focus on robotics and automotive sectors Arm sees robotics as a significant growth opportunity, plans to expand staff Jan 7 (Reuters) - Chip technology company Arm Holdings has reorganized the company to create a Physical AI unit to expand its presence in the robotics market, company executi"}, {"url": "https://www.deloitte.com/us/en/insights/topics/technology-management/tech-trends/2026/physical-ai-humanoid-robots.html", "title": "AI goes physical: Navigating the convergence of AI and robotics", "content": "During the next decade, the intersection of agentic AI systems with physical AI robotic systems will result in robots whose “brains” are agentic AIs. Robots of all form factors should increasingly be able to adapt to new environments, plan multistep tasks, recover from failure, and operate under uncertainty. The impact of this technology convergence will be particularly profound for humanoid robots.\n\nInstead of custom robotics for each domain, more general agentic modules may be reused across warehouses, homes, health care, agriculture, and other areas. Agentic humanoids could one day function as assistants, coworkers, or health care aides with more intuitive interaction, reasoning, and negotiation capabilities. [...] Human acceptance.While most workers are generally comfortable with predictable, rule-based robots, physical AI systems that learn and adapt introduce new uncertainties, especially worries about job displacement. However, experts predict that most roles will evolve toward collaboration rather than replacement.17 The goal is to create environments where robots handle repetitive or dangerous tasks while humans focus on creative problem-solving and complex decision-making.\n\nCybersecurity vulnerabilities. As discussed in “The AI dilemma,” physical AI systems create new attack surfaces that bridge digital and physical domains. Connected fleets increase cyber risks, with vulnerabilities potentially leading to unauthorized access, data breaches, or even malicious robot control. The stakes are even higher when security breaches can affect physical safety and operational continuity. [...] Image 19\n\nAyanna Howard is the dean of the College of Engineering at The Ohio State University and a prominent roboticist and advocate for AI safety and alignment. Previously, she was a senior robotics researcher at NASA’s Jet Propulsion Laboratory and later chaired Georgia Tech’s School of Interactive Computing and founded the Human-Automation Systems Lab. Watch the interview.\n\nQ: What technology challenges are holding back progress in physical AI and robotics?\n\nA: One of the fundamental challenges is that the physical world is inherently dynamic. I can walk into my office every day, but there’s always some difference—maybe someone vacuumed, moved things around, or my computer doesn’t boot up. The question is, how do you simulate all these variations so robots can learn to adapt, walk, lift, and interact with uncertainty the way humans do? You can’t just practice endlessly in the real world because you’ll break things.", "score": 0.67527276, "raw_content": null, "summary": "During the next decade, the intersection of agentic AI systems with physical AI robotic systems will result in robots whose “brains” are agentic AIs. [...] Image 19 Ayanna Howard is the dean of the College of Engineering at The Ohio State University and a prominent roboticist and advocate for AI safety and alignment."}]}
{"query": "recent 30 days AI industry trends (English)", "result": {"query": "recent 30 days AI industry trends (English)", "follow_up_questions": null, "answer": null, "images": [], "results": [{"url": "https://www.bondcap.com/report/pdf/Trends_Artificial_Intelligence.pdf", "title": "[PDF] Trends – Artificial Intelligence (AI) - Bondcap", "content": "- ElevenLabs Press Release, 1/25 AI Development Trending = Unprecedented ElevenLabs Monthly Global Site Visits (MM), per Similarweb – 1/23-4/25 47 …AI Performance = Evolving to Mainstream Realistic Audio Translation / Generation Note: Revenue annualized using Q1:25 results. Source: Spotify, ‘The New York Post,’ ‘Inside Spotify: CEO Daniel Ek on AI, Free Speech & the Future of Music’ (5/2/25); Spotify earnings releases; eMarketer, ‘Spotify dominates Apple and Amazon in digital audio’ (4/25) AI-Powered Audio Translation – 5/25, per Spotify Imagine if you’re a creator and you’re the world expert at something…but you happen to be Indonesian.\nToday, there’s a language barrier and it will be very hard if you don’t know English to be able to get to a world stage. [...] images 3/23: Google releases Bard, its ChatGPT competitor 11/23: 28 countries, including USA, EU members & China, sign Bletchley Declaration on AI Safety 4/24: Meta Platforms releases its open-source Llama 3 model with 70B parameters 5/24: Google introduces AI overviews to augment its search functions 9/24: Alibaba releases 100 open-source Qwen 2.5 models, with performance in line with Western competitors 1/25: DeepSeek releases its R1 & R1-Zero open-source reasoning models 2/25: OpenAI releases GPT-4.5, Anthropic releases Claude 3.7 Sonnet, & xAI releases Grok 3 4/25: ChatGPT reaches 800MM weekly users1 AI = Many Years Before Lift-Off 30 AI = Circa Q2:25 31 Top Ten Things AI Can Do Today, [...] 91 Source: Salesforce (10/24), Salesforce Ben, Anthropic (10/24), OpenAI (1/25), Amazon (3/25) AI Agent Deployments = AI Incumbent Product Launches Accelerating OpenAI Operator (1/25 = Research Preview Release) Salesforce Agentforce (10/24 = General Release) Anthropic Claude 3.5 Computer Use (10/24 = Research Preview Release) Amazon Nova Act (3/25 = Research Preview Release) Agent Released Select Capabilities • Automated customer support • Case resolution • Lead qualification • Order tracking • Control computer screen directly to perform tasks like pulling data from websites, making online purchases, etc.", "score": 0.7161595, "raw_content": null, "summary": "Source: Spotify, ‘The New York Post,’ ‘Inside Spotify: CEO Daniel Ek on AI, Free Speech & the Future of Music’ (5/2/25); Spotify earnings releases; eMarketer, ‘Spotify dominates Apple and Amazon in digital audio’ (4/25) AI-Powered Audio Translation – 5/25, per Spotify Imagine if you’re a creator and you’re the world expert at something…but you happen to be Indonesian. [...] images 3/23: Google rel"}, {"url": "https://www.artificialintelligence-news.com/", "title": "AI News | Latest News | Insights Powering AI-Driven Business Growth", "content": "Artificial Intelligence\n\nApril 2, 2025\n\n#### Enterprise\n\n### L’Oréal brings AI into everyday digital advertising production\n\nAI in Action\n\nJanuary 5, 2026\n\n### Disney is embedding generative AI into its operating model\n\nEntertainment & Media\n\nDecember 24, 2025\n\n### Zara’s use of AI shows how retail workflows are quietly changing\n\nDeep Dives\n\nDecember 19, 2025\n\n#### Industries\n\n### Grab brings robotics in-house to manage delivery costs\n\nAI Mergers & Acquisitions\n\nJanuary 7, 2026\n\n### The Law Society: Current laws are fit for the AI era\n\nLegal Industry AI\n\nJanuary 6, 2026\n\n### L’Oréal brings AI into everyday digital advertising production\n\nAI in Action\n\nJanuary 5, 2026\n\n#### Deep Learning\n\n### IBM Research unveils breakthrough analog AI chip for efficient deep learning\n\nAI Market Trends [...] # Grab brings robotics in-house to manage delivery costs\n\nLady Justice atop the Old Bailey in London as, while ministers push to loosen rules to speed up AI adoption, The Law Society argues that lawyers just need to know how current laws apply.\n\nLegal Industry AI\n\nJanuary 6, 2026\n\n# The Law Society: Current laws are fit for the AI era\n\nMarketing AI\n\nJanuary 6, 2026\n\n# What PubMatic’s AgenticOS signals for enterprise marketing\n\nArtificial Intelligence\n\nJanuary 6, 2026\n\n# 2025’s AI chip wars: What enterprise leaders learned about supply chain reality\n\nL’Oréal brings AI into everyday digital advertising production\n\nAI in Action\n\nJanuary 5, 2026\n\n# L’Oréal brings AI into everyday digital advertising production\n\nArtificial Intelligence\n\nJanuary 4, 2026\n\n# 3 best secure container images for modern applications\n\nGovernment & Public Sector AI [...] AI News is part of the TechForge Publications series\n\nTechForge\n\n## Featured\n\nHealthcare & Wellness AI\n\n# “Dr AI, am I healthy?” 59% of Brits rely on AI for self-diagnosis\n\nJanuary 8, 2026\n\nAI Market Trends\n\nJanuary 8, 2026\n\n# 2026 to be the year of the agentic AI intern\n\nBosch’s €2.9 billion AI investment and shifting manufacturing priorities\n\nManufacturing & Engineering AI\n\nJanuary 8, 2026\n\n# Bosch’s €2.9 billion AI investment and shifting manufacturing priorities\n\n## Popular\n\nArtificial Intelligence, How It Works, Inside AI, Utilities\n\n### The role of machine learning in enhancing cloud-native container security\n\nAI in Action, AI Market Trends, Artificial Intelligence\n\n### Google’s Veo 3 AI video creation tools are now widely available\n\nDeep Dives, Features, How It Works", "score": 0.7031221, "raw_content": null, "summary": "Artificial Intelligence April 2, 2025 #### Enterprise ### L’Oréal brings AI into everyday digital advertising production AI in Action January 5, 2026 ### Disney is embedding generative AI into its operating model Entertainment & Media December 24, 2025 ### Zara’s use of AI shows how retail workflows are quietly changing Deep Dives December 19, 2025 #### Industries ### Grab brings robotics in-house"}, {"url": "https://www.crescendo.ai/news/latest-ai-news-and-updates", "title": "Latest AI News and AI Breakthroughs that Matter Most: 2026 & 2025", "content": "Date: September 2, 2025  \nSummary: IBM is piloting AI-driven tennis commentary powered by computer vision and speech models that adjust tone, volume, and enthusiasm to match on-court excitement. Developed in partnership with IBM's MIT-IBM Watson AI Lab, the system enhances fan experience by treating AI as an augmentation tool, not a replacement. It's already being tested in tournament settings to supplement live coverage.  \nSource: IBM Think\n\n### Alibaba Shares Surge 19% on AI-Driven Cloud Growth\n\nDate: September 1, 2025  \nSummary: Alibaba's stock soared approximately 19% in Hong Kong amid investor enthusiasm tied to strong growth in its AI-powered cloud business. Quarterly earnings revealed substantial year-over-year gains in AI-related revenue, signaling a sustained competitive edge. Analysts also noted expectations around a new AI chip development. The rally reflects rising confidence in Alibaba’s tech-led strategic execution.  \nSource: Reuters [...] Date: October 12, 2025 Summary: Meta has poached Andrew Tulloch, co‑founder of the startup Thinking Machines Lab, with a compensation package rumored to reach $1.5 billion over six years. The move underscores Meta’s aggressive strategy to close the AI gap with OpenAI, Google, and Anthropic by acquiring top talent rather than just technology. Tulloch’s transition comes after Meta unsuccessfully attempted to acquire his company outright, following similar offers to other engineers. Industry analysts see this as part of an escalating “arms race” over elite AI researchers, whose skills are increasingly viewed as more critical than compute power or datasets. Source: Calcalistech\n\n### Gap Partners With Google Cloud to Advance AI Strategy [...] ### Israel’s AI Sector Struggles Amid Economic and Political Shifts\n\nDate: December 18, 2025 Summary: Despite its reputation as a global tech hub, Israel’s AI startup ecosystem is facing significant headwinds due to a combination of geopolitical instability and shifting investment trends. Recent data shows a slowdown in seed-stage funding for new AI ventures as investors become more risk-averse. Industry leaders are calling for increased government support and clearer regulatory frameworks to ensure that the country remains competitive in the global race for AI dominance, warning that a \"brain drain\" of talent to the U.S. remains a serious threat.\n\nSource: Calcalistech ↗\n\n### Tech Stocks Tumble Amid Growing AI Skepticism", "score": 0.7016523, "raw_content": null, "summary": "Source: Calcalistech ### Gap Partners With Google Cloud to Advance AI Strategy [...] ### Israel’s AI Sector Struggles Amid Economic and Political Shifts Date: December 18, 2025 Summary: Despite its reputation as a global tech hub, Israel’s AI startup ecosystem is facing significant headwinds due to a combination of geopolitical instability and shifting investment trends. Industry leaders are calli"}, {"url": "https://aiweekly.co/", "title": "AI Weekly — AI News & Leading Newsletter on Artificial Intelligence ...", "content": "3. Adobe Beats Estimates as AI Hits 33% of Sales\nAdobe posted Q4 earnings of $5.50 per share on Dec 11, revealing that \"AI-influenced\" revenue now accounts for over one-third of its total recurring revenue, though the stock dipped slightly on high expectations.\n\n4. Microsoft Commits $23B to Global AI Infra\nMicrosoft announced back-to-back mega-investments this week, committing $17.5 billion to India and $5.4 billion to Canada to build the data center capacity required for its next generation of agentic AI models.\n\n5. EU Launches Antitrust Probe into Google\nThe European Commission opened a formal investigation on Dec 9 into Google's use of publisher and YouTube content for AI training, threatening fines of up to 10% of global turnover if the company is found to be abusing its dominance. [...] 6. TSMC November Sales Confirm Sustained Demand\nTSMC reported that November revenue rose 24.5% year-over-year, dispelling rumors of a chip slowdown and confirming that demand for high-performance AI accelerators remains at peak levels.\n\n7. Disney Partners with OpenAI for Video\nDisney shares reacted to a historic licensing deal on Dec 11 that allows OpenAI's Sora to train on and generate content using iconic IP, signaling the first major public media conglomerate to fully embrace generative video.\n\n8. CoreWeave \"Bubble\" Sentiment Hits Markets\nBroader AI sentiment took a hit this week as reports on CoreWeave's valuation struggles despite a $2.25B raise reignited \"AI bubble\" fears, causing volatility in major chip and infrastructure stocks like Nvidia and Dell.\n\n## Ethics [...] 4. fal Secures $140M for Media Speed\nGenerative media infrastructure startup fal raised $140 million in Series D funding on Dec 9, led by Sequoia, to accelerate the inference speeds of image and video generation models for developers.\n\n5. Mistral Launches Devstral 2\nFrench lab Mistral released \"Devstral 2\" on Dec 9, a specialized open-weight coding model designed to offer developers a more efficient, privacy-focused alternative to GitHub Copilot.\n\n6. Runware Raises $50M for Edge AI\nOn Dec 11, Runware announced a $50 million Series A led by Dawn Capital to scale its ultra-low-latency API, which enables complex AI models to run on edge devices and mobile hardware.", "score": 0.6599319, "raw_content": null, "summary": "Microsoft Commits $23B to Global AI Infra Microsoft announced back-to-back mega-investments this week, committing $17.5 billion to India and $5.4 billion to Canada to build the data center capacity required for its next generation of agentic AI models. EU Launches Antitrust Probe into Google The European Commission opened a formal investigation on Dec 9 into Google's use of publisher and YouTube c"}, {"url": "https://www.omnius.so/blog/ai-search-industry-report", "title": "AI Search Industry Report 2025: Key Trends & Market Insights", "content": "Legacy search engines are being challenged, not just by each other, but by AI-native platforms that answer questions directly, personalize results, and pull data straight from the web and internal systems.\n\nThis report explores the core trends driving this shift: from chat-based search to retrieval-augmented generation (RAG), and from enterprise knowledge tools to on-device assistants.\n\nIt also examines the emerging business models, regulatory pressures, and the growing role of AI in both consumer and enterprise search.\n\n## AI Search Industry Report: Key Trends and Innovations\n\n### 1. Generative AI in Search\n\nSearch is just getting smarter. Microsoft’s Copilot Search (Apr 2025) combines web results with AI-generated summaries and source citations. Marketers are increasingly using ChatGPT SEO prompts to test content visibility and understand how their brand appears in AI-generated responses.\n\nGoogle’s SGE, built on Gemini and tested in Search Labs, does the same. [...] Via Malte Landwehr, CTR is reduced by 37-40% when AI Overviews are present (showed by multiple studies from different SEO tools from January 2024 - May 2025)\n\nHowever, AI Overviews are expanding rapidly, triggered for 6.49% of queries in January 2025, climbing to 7.64% by February (an 18% monthly increase).\n\nThe percentage continued to grow, hitting 13.14% by March (72% growth from the previous month).\n\nHere, you can see the AI Overview growth separated by industry (May 2024-May 2025):\n\nThis shift creates both challenges and opportunities: content creators face reduced traffic, but those who adapt their strategies to appear in AI citations can capture new visibility channels.\n\n### 2. AI Chatbots as Search Tools [...] | Platform | Estimated Daily Queries | 2025 Market Share | Models Used |\n ---  --- |\n| ChatGPT | ~1 billion/day | 60.6% | GPT-4o, GPT-4, GPT-3.5, GPT-4.5 |\n| Claude | N/A (likely tens of millions) | 3.2% | Claude 4 (Opus, Sonnet), Claude 3.7 Sonnet |\n| Bing | ~900 million/day | 14.3% | GPT-4 via Microsoft Prometheus |\n| Perplexity | ~30 million/day | 6.2% | GPT-4.1, Claude 4.0 Sonnet, Mistral, Custom LLMs |\n\n‍\n\nNiche players are gaining traction too: Phind focuses on code, Andi delivers simple answers, and embedding‑search startups are emerging.", "score": 0.63723457, "raw_content": null, "summary": "[...] Via Malte Landwehr, CTR is reduced by 37-40% when AI Overviews are present (showed by multiple studies from different SEO tools from January 2024 - May 2025) However, AI Overviews are expanding rapidly, triggered for 6.49% of queries in January 2025, climbing to 7.64% by February (an 18% monthly increase). AI Chatbots as Search Tools [...] | Platform | Estimated Daily Queries | 2025 Market S"}], "response_time": 3.98, "request_id": "541e2705-16e6-4578-90ae-69047275e87c"}, "query_summary": "Source: Spotify, ‘The New York Post,’ ‘Inside Spotify: CEO Daniel Ek on AI, Free Speech & the Future of Music’ (5/2/25); Spotify earnings releases; eMarketer, ‘Spotify dominates Apple and Amazon in digital audio’ (4/25) AI-Powered Audio Translation – 5/25, per Spotify Imagine if you’re a creator and you’re the world expert at something…but you happen to be Indonesian. [...] images 3/23: Google rel Artificial Intelligence April 2, 2025 #### Enterprise ### L’Oréal brings AI into everyday digital advertising production AI in Action January 5, 2026 ### Disney is embedding generative AI into its op", "lang_pref": "en", "preferred_results": [{"url": "https://www.bondcap.com/report/pdf/Trends_Artificial_Intelligence.pdf", "title": "[PDF] Trends – Artificial Intelligence (AI) - Bondcap", "content": "- ElevenLabs Press Release, 1/25 AI Development Trending = Unprecedented ElevenLabs Monthly Global Site Visits (MM), per Similarweb – 1/23-4/25 47 …AI Performance = Evolving to Mainstream Realistic Audio Translation / Generation Note: Revenue annualized using Q1:25 results. Source: Spotify, ‘The New York Post,’ ‘Inside Spotify: CEO Daniel Ek on AI, Free Speech & the Future of Music’ (5/2/25); Spotify earnings releases; eMarketer, ‘Spotify dominates Apple and Amazon in digital audio’ (4/25) AI-Powered Audio Translation – 5/25, per Spotify Imagine if you’re a creator and you’re the world expert at something…but you happen to be Indonesian.\nToday, there’s a language barrier and it will be very hard if you don’t know English to be able to get to a world stage. [...] images 3/23: Google releases Bard, its ChatGPT competitor 11/23: 28 countries, including USA, EU members & China, sign Bletchley Declaration on AI Safety 4/24: Meta Platforms releases its open-source Llama 3 model with 70B parameters 5/24: Google introduces AI overviews to augment its search functions 9/24: Alibaba releases 100 open-source Qwen 2.5 models, with performance in line with Western competitors 1/25: DeepSeek releases its R1 & R1-Zero open-source reasoning models 2/25: OpenAI releases GPT-4.5, Anthropic releases Claude 3.7 Sonnet, & xAI releases Grok 3 4/25: ChatGPT reaches 800MM weekly users1 AI = Many Years Before Lift-Off 30 AI = Circa Q2:25 31 Top Ten Things AI Can Do Today, [...] 91 Source: Salesforce (10/24), Salesforce Ben, Anthropic (10/24), OpenAI (1/25), Amazon (3/25) AI Agent Deployments = AI Incumbent Product Launches Accelerating OpenAI Operator (1/25 = Research Preview Release) Salesforce Agentforce (10/24 = General Release) Anthropic Claude 3.5 Computer Use (10/24 = Research Preview Release) Amazon Nova Act (3/25 = Research Preview Release) Agent Released Select Capabilities • Automated customer support • Case resolution • Lead qualification • Order tracking • Control computer screen directly to perform tasks like pulling data from websites, making online purchases, etc.", "score": 0.7161595, "raw_content": null, "summary": "Source: Spotify, ‘The New York Post,’ ‘Inside Spotify: CEO Daniel Ek on AI, Free Speech & the Future of Music’ (5/2/25); Spotify earnings releases; eMarketer, ‘Spotify dominates Apple and Amazon in digital audio’ (4/25) AI-Powered Audio Translation – 5/25, per Spotify Imagine if you’re a creator and you’re the world expert at something…but you happen to be Indonesian. [...] images 3/23: Google rel"}, {"url": "https://www.artificialintelligence-news.com/", "title": "AI News | Latest News | Insights Powering AI-Driven Business Growth", "content": "Artificial Intelligence\n\nApril 2, 2025\n\n#### Enterprise\n\n### L’Oréal brings AI into everyday digital advertising production\n\nAI in Action\n\nJanuary 5, 2026\n\n### Disney is embedding generative AI into its operating model\n\nEntertainment & Media\n\nDecember 24, 2025\n\n### Zara’s use of AI shows how retail workflows are quietly changing\n\nDeep Dives\n\nDecember 19, 2025\n\n#### Industries\n\n### Grab brings robotics in-house to manage delivery costs\n\nAI Mergers & Acquisitions\n\nJanuary 7, 2026\n\n### The Law Society: Current laws are fit for the AI era\n\nLegal Industry AI\n\nJanuary 6, 2026\n\n### L’Oréal brings AI into everyday digital advertising production\n\nAI in Action\n\nJanuary 5, 2026\n\n#### Deep Learning\n\n### IBM Research unveils breakthrough analog AI chip for efficient deep learning\n\nAI Market Trends [...] # Grab brings robotics in-house to manage delivery costs\n\nLady Justice atop the Old Bailey in London as, while ministers push to loosen rules to speed up AI adoption, The Law Society argues that lawyers just need to know how current laws apply.\n\nLegal Industry AI\n\nJanuary 6, 2026\n\n# The Law Society: Current laws are fit for the AI era\n\nMarketing AI\n\nJanuary 6, 2026\n\n# What PubMatic’s AgenticOS signals for enterprise marketing\n\nArtificial Intelligence\n\nJanuary 6, 2026\n\n# 2025’s AI chip wars: What enterprise leaders learned about supply chain reality\n\nL’Oréal brings AI into everyday digital advertising production\n\nAI in Action\n\nJanuary 5, 2026\n\n# L’Oréal brings AI into everyday digital advertising production\n\nArtificial Intelligence\n\nJanuary 4, 2026\n\n# 3 best secure container images for modern applications\n\nGovernment & Public Sector AI [...] AI News is part of the TechForge Publications series\n\nTechForge\n\n## Featured\n\nHealthcare & Wellness AI\n\n# “Dr AI, am I healthy?” 59% of Brits rely on AI for self-diagnosis\n\nJanuary 8, 2026\n\nAI Market Trends\n\nJanuary 8, 2026\n\n# 2026 to be the year of the agentic AI intern\n\nBosch’s €2.9 billion AI investment and shifting manufacturing priorities\n\nManufacturing & Engineering AI\n\nJanuary 8, 2026\n\n# Bosch’s €2.9 billion AI investment and shifting manufacturing priorities\n\n## Popular\n\nArtificial Intelligence, How It Works, Inside AI, Utilities\n\n### The role of machine learning in enhancing cloud-native container security\n\nAI in Action, AI Market Trends, Artificial Intelligence\n\n### Google’s Veo 3 AI video creation tools are now widely available\n\nDeep Dives, Features, How It Works", "score": 0.7031221, "raw_content": null, "summary": "Artificial Intelligence April 2, 2025 #### Enterprise ### L’Oréal brings AI into everyday digital advertising production AI in Action January 5, 2026 ### Disney is embedding generative AI into its operating model Entertainment & Media December 24, 2025 ### Zara’s use of AI shows how retail workflows are quietly changing Deep Dives December 19, 2025 #### Industries ### Grab brings robotics in-house"}, {"url": "https://www.crescendo.ai/news/latest-ai-news-and-updates", "title": "Latest AI News and AI Breakthroughs that Matter Most: 2026 & 2025", "content": "Date: September 2, 2025  \nSummary: IBM is piloting AI-driven tennis commentary powered by computer vision and speech models that adjust tone, volume, and enthusiasm to match on-court excitement. Developed in partnership with IBM's MIT-IBM Watson AI Lab, the system enhances fan experience by treating AI as an augmentation tool, not a replacement. It's already being tested in tournament settings to supplement live coverage.  \nSource: IBM Think\n\n### Alibaba Shares Surge 19% on AI-Driven Cloud Growth\n\nDate: September 1, 2025  \nSummary: Alibaba's stock soared approximately 19% in Hong Kong amid investor enthusiasm tied to strong growth in its AI-powered cloud business. Quarterly earnings revealed substantial year-over-year gains in AI-related revenue, signaling a sustained competitive edge. Analysts also noted expectations around a new AI chip development. The rally reflects rising confidence in Alibaba’s tech-led strategic execution.  \nSource: Reuters [...] Date: October 12, 2025 Summary: Meta has poached Andrew Tulloch, co‑founder of the startup Thinking Machines Lab, with a compensation package rumored to reach $1.5 billion over six years. The move underscores Meta’s aggressive strategy to close the AI gap with OpenAI, Google, and Anthropic by acquiring top talent rather than just technology. Tulloch’s transition comes after Meta unsuccessfully attempted to acquire his company outright, following similar offers to other engineers. Industry analysts see this as part of an escalating “arms race” over elite AI researchers, whose skills are increasingly viewed as more critical than compute power or datasets. Source: Calcalistech\n\n### Gap Partners With Google Cloud to Advance AI Strategy [...] ### Israel’s AI Sector Struggles Amid Economic and Political Shifts\n\nDate: December 18, 2025 Summary: Despite its reputation as a global tech hub, Israel’s AI startup ecosystem is facing significant headwinds due to a combination of geopolitical instability and shifting investment trends. Recent data shows a slowdown in seed-stage funding for new AI ventures as investors become more risk-averse. Industry leaders are calling for increased government support and clearer regulatory frameworks to ensure that the country remains competitive in the global race for AI dominance, warning that a \"brain drain\" of talent to the U.S. remains a serious threat.\n\nSource: Calcalistech ↗\n\n### Tech Stocks Tumble Amid Growing AI Skepticism", "score": 0.7016523, "raw_content": null, "summary": "Source: Calcalistech ### Gap Partners With Google Cloud to Advance AI Strategy [...] ### Israel’s AI Sector Struggles Amid Economic and Political Shifts Date: December 18, 2025 Summary: Despite its reputation as a global tech hub, Israel’s AI startup ecosystem is facing significant headwinds due to a combination of geopolitical instability and shifting investment trends. Industry leaders are calli"}, {"url": "https://aiweekly.co/", "title": "AI Weekly — AI News & Leading Newsletter on Artificial Intelligence ...", "content": "3. Adobe Beats Estimates as AI Hits 33% of Sales\nAdobe posted Q4 earnings of $5.50 per share on Dec 11, revealing that \"AI-influenced\" revenue now accounts for over one-third of its total recurring revenue, though the stock dipped slightly on high expectations.\n\n4. Microsoft Commits $23B to Global AI Infra\nMicrosoft announced back-to-back mega-investments this week, committing $17.5 billion to India and $5.4 billion to Canada to build the data center capacity required for its next generation of agentic AI models.\n\n5. EU Launches Antitrust Probe into Google\nThe European Commission opened a formal investigation on Dec 9 into Google's use of publisher and YouTube content for AI training, threatening fines of up to 10% of global turnover if the company is found to be abusing its dominance. [...] 6. TSMC November Sales Confirm Sustained Demand\nTSMC reported that November revenue rose 24.5% year-over-year, dispelling rumors of a chip slowdown and confirming that demand for high-performance AI accelerators remains at peak levels.\n\n7. Disney Partners with OpenAI for Video\nDisney shares reacted to a historic licensing deal on Dec 11 that allows OpenAI's Sora to train on and generate content using iconic IP, signaling the first major public media conglomerate to fully embrace generative video.\n\n8. CoreWeave \"Bubble\" Sentiment Hits Markets\nBroader AI sentiment took a hit this week as reports on CoreWeave's valuation struggles despite a $2.25B raise reignited \"AI bubble\" fears, causing volatility in major chip and infrastructure stocks like Nvidia and Dell.\n\n## Ethics [...] 4. fal Secures $140M for Media Speed\nGenerative media infrastructure startup fal raised $140 million in Series D funding on Dec 9, led by Sequoia, to accelerate the inference speeds of image and video generation models for developers.\n\n5. Mistral Launches Devstral 2\nFrench lab Mistral released \"Devstral 2\" on Dec 9, a specialized open-weight coding model designed to offer developers a more efficient, privacy-focused alternative to GitHub Copilot.\n\n6. Runware Raises $50M for Edge AI\nOn Dec 11, Runware announced a $50 million Series A led by Dawn Capital to scale its ultra-low-latency API, which enables complex AI models to run on edge devices and mobile hardware.", "score": 0.6599319, "raw_content": null, "summary": "Microsoft Commits $23B to Global AI Infra Microsoft announced back-to-back mega-investments this week, committing $17.5 billion to India and $5.4 billion to Canada to build the data center capacity required for its next generation of agentic AI models. EU Launches Antitrust Probe into Google The European Commission opened a formal investigation on Dec 9 into Google's use of publisher and YouTube c"}, {"url": "https://www.omnius.so/blog/ai-search-industry-report", "title": "AI Search Industry Report 2025: Key Trends & Market Insights", "content": "Legacy search engines are being challenged, not just by each other, but by AI-native platforms that answer questions directly, personalize results, and pull data straight from the web and internal systems.\n\nThis report explores the core trends driving this shift: from chat-based search to retrieval-augmented generation (RAG), and from enterprise knowledge tools to on-device assistants.\n\nIt also examines the emerging business models, regulatory pressures, and the growing role of AI in both consumer and enterprise search.\n\n## AI Search Industry Report: Key Trends and Innovations\n\n### 1. Generative AI in Search\n\nSearch is just getting smarter. Microsoft’s Copilot Search (Apr 2025) combines web results with AI-generated summaries and source citations. Marketers are increasingly using ChatGPT SEO prompts to test content visibility and understand how their brand appears in AI-generated responses.\n\nGoogle’s SGE, built on Gemini and tested in Search Labs, does the same. [...] Via Malte Landwehr, CTR is reduced by 37-40% when AI Overviews are present (showed by multiple studies from different SEO tools from January 2024 - May 2025)\n\nHowever, AI Overviews are expanding rapidly, triggered for 6.49% of queries in January 2025, climbing to 7.64% by February (an 18% monthly increase).\n\nThe percentage continued to grow, hitting 13.14% by March (72% growth from the previous month).\n\nHere, you can see the AI Overview growth separated by industry (May 2024-May 2025):\n\nThis shift creates both challenges and opportunities: content creators face reduced traffic, but those who adapt their strategies to appear in AI citations can capture new visibility channels.\n\n### 2. AI Chatbots as Search Tools [...] | Platform | Estimated Daily Queries | 2025 Market Share | Models Used |\n ---  --- |\n| ChatGPT | ~1 billion/day | 60.6% | GPT-4o, GPT-4, GPT-3.5, GPT-4.5 |\n| Claude | N/A (likely tens of millions) | 3.2% | Claude 4 (Opus, Sonnet), Claude 3.7 Sonnet |\n| Bing | ~900 million/day | 14.3% | GPT-4 via Microsoft Prometheus |\n| Perplexity | ~30 million/day | 6.2% | GPT-4.1, Claude 4.0 Sonnet, Mistral, Custom LLMs |\n\n‍\n\nNiche players are gaining traction too: Phind focuses on code, Andi delivers simple answers, and embedding‑search startups are emerging.", "score": 0.63723457, "raw_content": null, "summary": "[...] Via Malte Landwehr, CTR is reduced by 37-40% when AI Overviews are present (showed by multiple studies from different SEO tools from January 2024 - May 2025) However, AI Overviews are expanding rapidly, triggered for 6.49% of queries in January 2025, climbing to 7.64% by February (an 18% monthly increase). AI Chatbots as Search Tools [...] | Platform | Estimated Daily Queries | 2025 Market S"}]}
{"query": "CES 2026 AI industrial automation (English)", "result": {"query": "CES 2026 AI industrial automation (English)", "follow_up_questions": null, "answer": null, "images": [], "results": [{"url": "https://press.siemens.com/global/en/event/siemens-ces-2026-industrial-ai-takes-center-stage", "title": "Siemens at CES 2026: Industrial AI takes center stage | Press", "content": "Save the date2026-01-06 00:002026-01-09 00:00Europe/Parisuse-titleSiemens at CES 2026: Industrial AI takes center stageThis year, Siemens is showing how Industrial AI is moving from vision to reality and how it is transforming manufacturing, infrastructure, mobility, and energy through digital twins, AI-powered software, and automation. One of the highlights at CES: the Siemens opening keynote. On Tuesday, January 6, 2026, 8:30 a.m. PST, Roland Busch, President and CEO will take the CES stage together with global industry leaders from NVIDIA, Microsoft, PepsiCo, and Commonwealth Fusion Systems. In the opening keynote, they will spotlight how Siemens, together with customers and partners, is accelerating the industrial AI revolution, from design and engineering to operations and real-world impact. At the center: how to scale intelligence responsibly and reliably in the physical world and turn AI into tangible value for [...] Save the date2026-01-06 00:002026-01-09 00:00Europe/Parisuse-titleSiemens at CES 2026: Industrial AI takes center stageThis year, Siemens is showing how Industrial AI is moving from vision to reality and how it is transforming manufacturing, infrastructure, mobility, and energy through digital twins, AI-powered software, and automation. One of the highlights at CES: the Siemens opening keynote. On Tuesday, January 6, 2026, 8:30 a.m. PST, Roland Busch, President and CEO will take the CES stage together with global industry leaders from NVIDIA, Microsoft, PepsiCo, and Commonwealth Fusion Systems. In the opening keynote, they will spotlight how Siemens, together with customers and partners, is accelerating the industrial AI revolution, from design and engineering to operations and real-world impact. At the center: how to scale intelligence responsibly and reliably in the physical world and turn AI into tangible value for [...] This year, Siemens is showing how Industrial AI is moving from vision to reality and how it is transforming manufacturing, infrastructure, mobility, and energy through digital twins, AI-powered software, and automation.   \n   \nOne of the highlights at CES: the Siemens opening keynote. On Tuesday, January 6, 2026, 8:30 a.m. PST, Roland Busch, President and CEO will take the CES stage together with global industry leaders from NVIDIA, Microsoft, PepsiCo, and Commonwealth Fusion Systems. In the opening keynote, they will spotlight how Siemens, together with customers and partners, is accelerating the industrial AI revolution, from design and engineering to operations and real-world impact. At the center: how to scale intelligence responsibly and reliably in the physical world and turn AI into tangible value for industry, infrastructure, transportation, and energy.   \n   \nWatch the Livestream Keynote.", "score": 0.9108078, "raw_content": null, "summary": "At the center: how to scale intelligence responsibly and reliably in the physical world and turn AI into tangible value for [...] Save the date2026-01-06 00:002026-01-09 00:00Europe/Parisuse-titleSiemens at CES 2026: Industrial AI takes center stageThis year, Siemens is showing how Industrial AI is moving from vision to reality and how it is transforming manufacturing, infrastructure, mobility, an"}, {"url": "https://press.siemens.com/global/en/pressrelease/siemens-unveils-technologies-accelerate-industrial-ai-revolution-ces-2026", "title": "Siemens unveils technologies to accelerate the industrial AI ...", "content": "Siemens highlighted its long-standing partnership with NVIDIA at CES 2026: The companies are expanding their partnership to build the Industrial AI Operating System – helping customers revolutionize how they design, engineer, and operate physical systems. Siemens and NVIDIA will work together to build AI-accelerated industrial solutions across the full lifecycle of products and production, enabling faster innovation, continuous optimization, and more resilient, sustainable manufacturing. The companies also aim to build the world’s first fully AI-driven, adaptive manufacturing sites globally, starting in 2026 with the Siemens Electronics Factory in Erlangen, Germany, as the first blueprint.\n\nTo support development, NVIDIA will provide AI infrastructure, simulation libraries, models, frameworks and blueprints, while Siemens will commit hundreds of industrial AI experts and leading hardware and software. The companies have identified impact areas to make this vision a reality: AI-native EDA, AI-native Simulation, AI-driven adaptive manufacturing and supply chain, and AI-factories. [...] At CES 2026, Siemens’ keynote marked a new era of technology for industry and infrastructure, showcasing how customers and partners are harnessing artificial intelligence to transform their businesses. With AI-enabled technologies, deep domain expertise, and trusted partnerships, Siemens is converting this technological leap into measurable benefits for customers, partners, and society. [...] New Technology Connects Digital Twin with Real-Time, Real-World Data\n\nSiemens’ primary product launch at CES 2026 is the Digital Twin Composer, available on the Siemens Xcelerator Marketplace mid-2026. This new technology brings together Siemens’ comprehensive digital twin, simulations built using NVIDIA Omniverse libraries, and real-time, real-world engineering data.", "score": 0.8536326, "raw_content": null, "summary": "Siemens and NVIDIA will work together to build AI-accelerated industrial solutions across the full lifecycle of products and production, enabling faster innovation, continuous optimization, and more resilient, sustainable manufacturing. The companies have identified impact areas to make this vision a reality: AI-native EDA, AI-native Simulation, AI-driven adaptive manufacturing and supply chain, a"}, {"url": "https://www.youtube.com/watch?v=5eMSMiL7F2o", "title": "Hyundai and Boston Dynamics Reveal Their Humanoid ... - YouTube", "content": "### Description\n731 views\nPosted: 5 Jan 2026\nThe era of industrial AI Robotics is officially here. At CES 2026 in Las Vegas, Boston Dynamics and Hyundai Motor Group made history by unveiling the product version of the new Atlas® robot. No longer just a research prototype, this fully electric humanoid is now a production-ready machine designed to revolutionize the way industry works.\nWhat makes the new Atlas a game-changer?\n• Superhuman Agility: Atlas features 56 degrees of freedom with fully rotational joints and a reach of 2.3 meters (7.5 ft).\n• Industrial Strength: It is engineered to perform exhausting manual labor, capable of lifting up to 50 kg (110 lbs).\n• Advanced AI: A strategic partnership with Google DeepMind integrates cutting-edge foundation models into Atlas, giving it the cognitive capabilities to learn new tasks in under a day.", "score": 0.852752, "raw_content": null, "summary": "At CES 2026 in Las Vegas, Boston Dynamics and Hyundai Motor Group made history by unveiling the product version of the new Atlas® robot. • Advanced AI: A strategic partnership with Google DeepMind integrates cutting-edge foundation models into Atlas, giving it the cognitive capabilities to learn new tasks in under a day."}, {"url": "https://newsroom.arm.com/blog/top-trends-for-ces-2026", "title": "Top 5 trends you can expect from CES 2026 in Las Vegas", "content": "Tesla’s next-generation AI5 chip, built on the Arm compute platform, is delivering up to 40x faster AI performance than the prior generation, underlining how efficiency and scalability are becoming central requirements as physical AI expands beyond traditional driver-assistance. Elsewhere, the Arm-based NVIDIA DRIVE Thor platform is powering the Lenovo  HPC 3.0 system behind WeRide’s Level 4 Robotaxi GXR, while autonomy companies such as Nuro, Wayve, and Zoox continue to refine their services within defined operating zones. [...] For instance, look out for DEEP Robotics’ LYNX M20 Pro, a quadruped designed for industrial inspection and emergency operations. It can traverse rugged terrain that would challenge conventional wheeled robots. Service robots are becoming a familiar sight as well, with companies like Roborock and PUDU Robotics demonstrating cleaning, delivery and hospitality robots capable of navigating busy, unpredictable indoor spaces.\n\nHumanoids are also moving beyond the conceptual stage. Several companies, including Agility Robotics, AGIBOT and Galbot, have made tangible progress in locomotion, balance and manipulation, with thousands of units already produced and deployed in commercial environments. Their presence at CES 2026 will help clarify how these use cases are beginning to take shape, particularly across manufacturing, retail, and warehouse operations.\n\nPlatforms such as NVIDIA’s Jetson Thor, running on Arm-based compute, show how simulation is evolving into deployment-ready systems.\n\n## On-device AI becomes standard on PCs, laptops, and tablets [...] And, make sure to stop by the NVIDIA DRIVE AGX Thor Developer Kit  showcase, where you’ll see how Arm-based platforms enable a seamless path from early development to scalable, production-ready automotive systems. Meanwhile, digital twins demos and virtual platforms, including Siemens’ new PAVE360™ Automotive technology which is used by multiple companies you will find at CES 2026, are speeding the path to integration. That broader push is reflected in Arm’s work with Amazon Web Services (AWS), and Google Cloud.\n\nAdditionally, HERE Technologies will highlight how Arm-based AWS Graviton infrastructure is helping to move work from the cloud toward production more efficiently.\n\n## Robotics embodies a new phase of physical AI\n\nCES 2026 is where you’ll see robots move beyond the lab, driven by advancements in AI models, sensing, actuation, low-power compute and energy-efficient system integration that make autonomous deployment more practical at scale.", "score": 0.7890553, "raw_content": null, "summary": "Tesla’s next-generation AI5 chip, built on the Arm compute platform, is delivering up to 40x faster AI performance than the prior generation, underlining how efficiency and scalability are becoming central requirements as physical AI expands beyond traditional driver-assistance. ## On-device AI becomes standard on PCs, laptops, and tablets [...] And, make sure to stop by the NVIDIA DRIVE AGX Thor"}, {"url": "https://www.ces.tech/articles/ai-enthusiasts-at-ces-2026-a-sample-itinerary/", "title": "AI Enthusiasts at CES 2026: A Sample Itinerary", "content": "Next, catch a session or two at LVCC:\n\n11 AM–12 PM Transforming Industries with Physical AI, presented by McKinsey (LVCC Level 2)\n2–2:40 PM Blueprint of Innovation: The Tech Shaping Tomorrow, presented by Invesco QQQ and Nasdaq (LVCC Level 2)\n4–4:40 PM Building the Enterprise AI Blueprint: From Startup Speed to Scale, presented by Cox Automotive (LVCC Level 2)\n\nGo further and add these tracks or the deluxe conference pass to your registration for ultimate access: [...] 11–11:40 AM The Edge Awakens: Why Agentic AI Will Reshape Everything (LVCC Level 2)\n1–1:40 PM Intelligence Through Motion: AI Takes Physical Form (LVCC Level 2)\n2–3 PM Keynote: All-In Interview at CES Featuring McKinsey and General Catalyst, (Venetian Level 5, Palazzo Ballroom)\n3–3:30 PM AI at Work: Turning Hype into Hard ROI (ARIA Level 1) [...] 9–9:40 AM AI-Powered Wearables (Venetian Level 4)\n11:30–12 PM Future of Leadership in the AI Era (Fontainebleau Level 4)\n12:30–1 PM Robots Among Us: Welcome to the Age of Humanoids, presented by Agility Robots (Fontainebleau Level 4)\n3–3:30 PM Mapping What’s Possible With AI, presented by TomTom (Fontainebleau Level 4)\n4–4:40 PMMasterclass: AI Prompt Engineering with Black Girl Ventures (Venetian Expo Level 1)\n\n### Want more?\n\n Be sure to add the deluxe conference pass to your registration for access to every AI session. \n\nExplore the full schedule\n\n#### Evening Celebration", "score": 0.75831425, "raw_content": null, "summary": "Next, catch a session or two at LVCC: 11 AM–12 PM Transforming Industries with Physical AI, presented by McKinsey (LVCC Level 2) 2–2:40 PM Blueprint of Innovation: The Tech Shaping Tomorrow, presented by Invesco QQQ and Nasdaq (LVCC Level 2) 4–4:40 PM Building the Enterprise AI Blueprint: From Startup Speed to Scale, presented by Cox Automotive (LVCC Level 2) Go further and add these tracks or the"}], "response_time": 1.59, "request_id": "bd430809-a7ee-41c4-ab7a-777255b0cbb1"}, "query_summary": "At the center: how to scale intelligence responsibly and reliably in the physical world and turn AI into tangible value for [...] Save the date2026-01-06 00:002026-01-09 00:00Europe/Parisuse-titleSiemens at CES 2026: Industrial AI takes center stageThis year, Siemens is showing how Industrial AI is moving from vision to reality and how it is transforming manufacturing, infrastructure, mobility, an Siemens and NVIDIA will work together to build AI-accelerated industrial solutions across the full lifecycle of products and production, enabling faster innovation, continuous optimization, and more", "lang_pref": "en", "preferred_results": [{"url": "https://press.siemens.com/global/en/event/siemens-ces-2026-industrial-ai-takes-center-stage", "title": "Siemens at CES 2026: Industrial AI takes center stage | Press", "content": "Save the date2026-01-06 00:002026-01-09 00:00Europe/Parisuse-titleSiemens at CES 2026: Industrial AI takes center stageThis year, Siemens is showing how Industrial AI is moving from vision to reality and how it is transforming manufacturing, infrastructure, mobility, and energy through digital twins, AI-powered software, and automation. One of the highlights at CES: the Siemens opening keynote. On Tuesday, January 6, 2026, 8:30 a.m. PST, Roland Busch, President and CEO will take the CES stage together with global industry leaders from NVIDIA, Microsoft, PepsiCo, and Commonwealth Fusion Systems. In the opening keynote, they will spotlight how Siemens, together with customers and partners, is accelerating the industrial AI revolution, from design and engineering to operations and real-world impact. At the center: how to scale intelligence responsibly and reliably in the physical world and turn AI into tangible value for [...] Save the date2026-01-06 00:002026-01-09 00:00Europe/Parisuse-titleSiemens at CES 2026: Industrial AI takes center stageThis year, Siemens is showing how Industrial AI is moving from vision to reality and how it is transforming manufacturing, infrastructure, mobility, and energy through digital twins, AI-powered software, and automation. One of the highlights at CES: the Siemens opening keynote. On Tuesday, January 6, 2026, 8:30 a.m. PST, Roland Busch, President and CEO will take the CES stage together with global industry leaders from NVIDIA, Microsoft, PepsiCo, and Commonwealth Fusion Systems. In the opening keynote, they will spotlight how Siemens, together with customers and partners, is accelerating the industrial AI revolution, from design and engineering to operations and real-world impact. At the center: how to scale intelligence responsibly and reliably in the physical world and turn AI into tangible value for [...] This year, Siemens is showing how Industrial AI is moving from vision to reality and how it is transforming manufacturing, infrastructure, mobility, and energy through digital twins, AI-powered software, and automation.   \n   \nOne of the highlights at CES: the Siemens opening keynote. On Tuesday, January 6, 2026, 8:30 a.m. PST, Roland Busch, President and CEO will take the CES stage together with global industry leaders from NVIDIA, Microsoft, PepsiCo, and Commonwealth Fusion Systems. In the opening keynote, they will spotlight how Siemens, together with customers and partners, is accelerating the industrial AI revolution, from design and engineering to operations and real-world impact. At the center: how to scale intelligence responsibly and reliably in the physical world and turn AI into tangible value for industry, infrastructure, transportation, and energy.   \n   \nWatch the Livestream Keynote.", "score": 0.9108078, "raw_content": null, "summary": "At the center: how to scale intelligence responsibly and reliably in the physical world and turn AI into tangible value for [...] Save the date2026-01-06 00:002026-01-09 00:00Europe/Parisuse-titleSiemens at CES 2026: Industrial AI takes center stageThis year, Siemens is showing how Industrial AI is moving from vision to reality and how it is transforming manufacturing, infrastructure, mobility, an"}, {"url": "https://press.siemens.com/global/en/pressrelease/siemens-unveils-technologies-accelerate-industrial-ai-revolution-ces-2026", "title": "Siemens unveils technologies to accelerate the industrial AI ...", "content": "Siemens highlighted its long-standing partnership with NVIDIA at CES 2026: The companies are expanding their partnership to build the Industrial AI Operating System – helping customers revolutionize how they design, engineer, and operate physical systems. Siemens and NVIDIA will work together to build AI-accelerated industrial solutions across the full lifecycle of products and production, enabling faster innovation, continuous optimization, and more resilient, sustainable manufacturing. The companies also aim to build the world’s first fully AI-driven, adaptive manufacturing sites globally, starting in 2026 with the Siemens Electronics Factory in Erlangen, Germany, as the first blueprint.\n\nTo support development, NVIDIA will provide AI infrastructure, simulation libraries, models, frameworks and blueprints, while Siemens will commit hundreds of industrial AI experts and leading hardware and software. The companies have identified impact areas to make this vision a reality: AI-native EDA, AI-native Simulation, AI-driven adaptive manufacturing and supply chain, and AI-factories. [...] At CES 2026, Siemens’ keynote marked a new era of technology for industry and infrastructure, showcasing how customers and partners are harnessing artificial intelligence to transform their businesses. With AI-enabled technologies, deep domain expertise, and trusted partnerships, Siemens is converting this technological leap into measurable benefits for customers, partners, and society. [...] New Technology Connects Digital Twin with Real-Time, Real-World Data\n\nSiemens’ primary product launch at CES 2026 is the Digital Twin Composer, available on the Siemens Xcelerator Marketplace mid-2026. This new technology brings together Siemens’ comprehensive digital twin, simulations built using NVIDIA Omniverse libraries, and real-time, real-world engineering data.", "score": 0.8536326, "raw_content": null, "summary": "Siemens and NVIDIA will work together to build AI-accelerated industrial solutions across the full lifecycle of products and production, enabling faster innovation, continuous optimization, and more resilient, sustainable manufacturing. The companies have identified impact areas to make this vision a reality: AI-native EDA, AI-native Simulation, AI-driven adaptive manufacturing and supply chain, a"}, {"url": "https://www.youtube.com/watch?v=5eMSMiL7F2o", "title": "Hyundai and Boston Dynamics Reveal Their Humanoid ... - YouTube", "content": "### Description\n731 views\nPosted: 5 Jan 2026\nThe era of industrial AI Robotics is officially here. At CES 2026 in Las Vegas, Boston Dynamics and Hyundai Motor Group made history by unveiling the product version of the new Atlas® robot. No longer just a research prototype, this fully electric humanoid is now a production-ready machine designed to revolutionize the way industry works.\nWhat makes the new Atlas a game-changer?\n• Superhuman Agility: Atlas features 56 degrees of freedom with fully rotational joints and a reach of 2.3 meters (7.5 ft).\n• Industrial Strength: It is engineered to perform exhausting manual labor, capable of lifting up to 50 kg (110 lbs).\n• Advanced AI: A strategic partnership with Google DeepMind integrates cutting-edge foundation models into Atlas, giving it the cognitive capabilities to learn new tasks in under a day.", "score": 0.852752, "raw_content": null, "summary": "At CES 2026 in Las Vegas, Boston Dynamics and Hyundai Motor Group made history by unveiling the product version of the new Atlas® robot. • Advanced AI: A strategic partnership with Google DeepMind integrates cutting-edge foundation models into Atlas, giving it the cognitive capabilities to learn new tasks in under a day."}, {"url": "https://newsroom.arm.com/blog/top-trends-for-ces-2026", "title": "Top 5 trends you can expect from CES 2026 in Las Vegas", "content": "Tesla’s next-generation AI5 chip, built on the Arm compute platform, is delivering up to 40x faster AI performance than the prior generation, underlining how efficiency and scalability are becoming central requirements as physical AI expands beyond traditional driver-assistance. Elsewhere, the Arm-based NVIDIA DRIVE Thor platform is powering the Lenovo  HPC 3.0 system behind WeRide’s Level 4 Robotaxi GXR, while autonomy companies such as Nuro, Wayve, and Zoox continue to refine their services within defined operating zones. [...] For instance, look out for DEEP Robotics’ LYNX M20 Pro, a quadruped designed for industrial inspection and emergency operations. It can traverse rugged terrain that would challenge conventional wheeled robots. Service robots are becoming a familiar sight as well, with companies like Roborock and PUDU Robotics demonstrating cleaning, delivery and hospitality robots capable of navigating busy, unpredictable indoor spaces.\n\nHumanoids are also moving beyond the conceptual stage. Several companies, including Agility Robotics, AGIBOT and Galbot, have made tangible progress in locomotion, balance and manipulation, with thousands of units already produced and deployed in commercial environments. Their presence at CES 2026 will help clarify how these use cases are beginning to take shape, particularly across manufacturing, retail, and warehouse operations.\n\nPlatforms such as NVIDIA’s Jetson Thor, running on Arm-based compute, show how simulation is evolving into deployment-ready systems.\n\n## On-device AI becomes standard on PCs, laptops, and tablets [...] And, make sure to stop by the NVIDIA DRIVE AGX Thor Developer Kit  showcase, where you’ll see how Arm-based platforms enable a seamless path from early development to scalable, production-ready automotive systems. Meanwhile, digital twins demos and virtual platforms, including Siemens’ new PAVE360™ Automotive technology which is used by multiple companies you will find at CES 2026, are speeding the path to integration. That broader push is reflected in Arm’s work with Amazon Web Services (AWS), and Google Cloud.\n\nAdditionally, HERE Technologies will highlight how Arm-based AWS Graviton infrastructure is helping to move work from the cloud toward production more efficiently.\n\n## Robotics embodies a new phase of physical AI\n\nCES 2026 is where you’ll see robots move beyond the lab, driven by advancements in AI models, sensing, actuation, low-power compute and energy-efficient system integration that make autonomous deployment more practical at scale.", "score": 0.7890553, "raw_content": null, "summary": "Tesla’s next-generation AI5 chip, built on the Arm compute platform, is delivering up to 40x faster AI performance than the prior generation, underlining how efficiency and scalability are becoming central requirements as physical AI expands beyond traditional driver-assistance. ## On-device AI becomes standard on PCs, laptops, and tablets [...] And, make sure to stop by the NVIDIA DRIVE AGX Thor"}, {"url": "https://www.ces.tech/articles/ai-enthusiasts-at-ces-2026-a-sample-itinerary/", "title": "AI Enthusiasts at CES 2026: A Sample Itinerary", "content": "Next, catch a session or two at LVCC:\n\n11 AM–12 PM Transforming Industries with Physical AI, presented by McKinsey (LVCC Level 2)\n2–2:40 PM Blueprint of Innovation: The Tech Shaping Tomorrow, presented by Invesco QQQ and Nasdaq (LVCC Level 2)\n4–4:40 PM Building the Enterprise AI Blueprint: From Startup Speed to Scale, presented by Cox Automotive (LVCC Level 2)\n\nGo further and add these tracks or the deluxe conference pass to your registration for ultimate access: [...] 11–11:40 AM The Edge Awakens: Why Agentic AI Will Reshape Everything (LVCC Level 2)\n1–1:40 PM Intelligence Through Motion: AI Takes Physical Form (LVCC Level 2)\n2–3 PM Keynote: All-In Interview at CES Featuring McKinsey and General Catalyst, (Venetian Level 5, Palazzo Ballroom)\n3–3:30 PM AI at Work: Turning Hype into Hard ROI (ARIA Level 1) [...] 9–9:40 AM AI-Powered Wearables (Venetian Level 4)\n11:30–12 PM Future of Leadership in the AI Era (Fontainebleau Level 4)\n12:30–1 PM Robots Among Us: Welcome to the Age of Humanoids, presented by Agility Robots (Fontainebleau Level 4)\n3–3:30 PM Mapping What’s Possible With AI, presented by TomTom (Fontainebleau Level 4)\n4–4:40 PMMasterclass: AI Prompt Engineering with Black Girl Ventures (Venetian Expo Level 1)\n\n### Want more?\n\n Be sure to add the deluxe conference pass to your registration for access to every AI session. \n\nExplore the full schedule\n\n#### Evening Celebration", "score": 0.75831425, "raw_content": null, "summary": "Next, catch a session or two at LVCC: 11 AM–12 PM Transforming Industries with Physical AI, presented by McKinsey (LVCC Level 2) 2–2:40 PM Blueprint of Innovation: The Tech Shaping Tomorrow, presented by Invesco QQQ and Nasdaq (LVCC Level 2) 4–4:40 PM Building the Enterprise AI Blueprint: From Startup Speed to Scale, presented by Cox Automotive (LVCC Level 2) Go further and add these tracks or the"}]}
{"query": "CES 2026 industrial robotics AI (English)", "result": {"query": "CES 2026 industrial robotics AI (English)", "follow_up_questions": null, "answer": null, "images": [], "results": [{"url": "https://www.ces.tech/articles/roboticists-at-ces-2026-a-sample-itinerary/", "title": "Roboticists at CES 2026: A Sample Itinerary", "content": "|  |  |\n --- |\n| 9–9:30 AM | Unlocking AI Transformation: From Devices to Culture, presented by Microsoft (Fontainebleau Level 4) |\n| 11–11:30 AM | Pioneering Industrial AI Technologies, presented by Hitachi (Fontainebleau Level 4) |\n| 12:30–1 PM | Robots Among Us: Welcome to the Age of Humanoids, presented by Agility Robots (Fontainebleau Level 4) |\n| 2–2:30 PM | Uplifting Robots for Independent Living (Venetian Expo Level 2) |\n\n### Evening Celebration\n\nDon’t miss the CES Foundry Celebration Event, presented by IBM, JobsOhio and Vector, from 4:30–6 PM in the Azure Ballroom at Fontainebleau. It’s open to all CES badge holders and promises strategic introductions and high-value exchanges.\n\n Learn More\n\n#### Evening Celebration [...] |  |  |\n --- |\n| 10:30 AM–11 AM | Physical AI and the Big Bang of General Robotics, presented by NVIDIA |\n| 1 PM–1:30 PM | Inside the AI-Native Enterprise, presented by Monks |\n| 3–3:30 PM | AI-Powered Workflows: Transforming Frontline Operations for the Future, presented by Zebra |\n| 4–4:30 PM | Promoting Promise, Preventing Peril: Harnessing AI’s Capabilities for Good |\n\n### Evening Fun\n\nFirst time at CES? Don’t miss the First-Timer Meetup (4:30–6 PM, The Garden at LVCC Central Plaza).\n\n Learn More\n\n## Thursday: Explore, Learn, Connect, Celebrate\n\nVisit top exhibitors like NVIDIA, Intel, Qualcomm, ARM and Mediatrak. Then catch these standout sessions: [...] Get the ultimate CES experience with a show floor tour, Robots Rising: How Machines, AI, and Infrastructure Are Rebuilding the World. This tour explores how robotics, AI and connected infrastructure are reshaping industries and public spaces. Highlighting real-world applications — from autonomous mobility and smart logistics to energy systems and urban tech — it showcases solutions making environments more efficient, responsive and resilient. Attendees will also see how these technologies work with people, keeping human insight at the core of intelligent systems. This tour is designed for professionals eager to see how physical AI is shaping the built world — today and tomorrow.", "score": 0.8724455, "raw_content": null, "summary": "| | | --- | | 9–9:30 AM | Unlocking AI Transformation: From Devices to Culture, presented by Microsoft (Fontainebleau Level 4) | | 11–11:30 AM | Pioneering Industrial AI Technologies, presented by Hitachi (Fontainebleau Level 4) | | 12:30–1 PM | Robots Among Us: Welcome to the Age of Humanoids, presented by Agility Robots (Fontainebleau Level 4) | | 2–2:30 PM | Uplifting Robots for Independent Liv"}, {"url": "https://emag.directindustry.com/2026/01/06/ces-2026-ai-robotics-low-carbon-remediation-industrial-innovation/", "title": "CES 2026: Four Industrial Innovations to Watch", "content": "This year’s key trends include:\n\n   Artificial intelligence embedded at the edge\n   Robotics and automation for real-world operations\n   Software-defined vehicles and smart mobility\n   Sustainable, low-carbon industrial technologies\n\nAmong the many announcements, four innovations stood out for their immediate relevance to industrial stakeholders.\n\n1/ Qualcomm: Powering Physical AI from Industrial AMRs to Full-Size Humanoids\n\n### The innovation\n\nQualcomm is unveiling a next-generation, full-stack robotics architecture designed to move Physical AI out of labs and into real-world industrial environments. Built on safety-grade, high-performance SoC platforms, this comprehensive approach combines hardware, software and compound AI to power general-purpose robots, from industrial AMRs to full-size humanoids capable of reasoning, adapting and making decisions.\n\nAt the core of this announcement is the launch of the Qualcomm Dragonwing™ IQ10 Series, the company’s latest premium-tier robotics processor, purpose-built for advanced autonomous mobile robots and humanoid platforms. [...] January 6, 2026 11 mins\n\nAt CES 2026, innovation is moving decisively from concept to deployment. Robotics, AI-driven mobility, advanced sensing and environmental engineering solutions demonstrated how digital technologies are now reshaping industrial operations, infrastructure and sustainability strategies. From robotics platforms to AI-driven mobility software and low-carbon soil remediation, CES 2026 once again proves that industrial innovation is accelerating well beyond consumer electronics.\n\nCES Las Vegas, a Global Innovation Hub\n\nHeld every January in Las Vegas, CES (Consumer Electronics Show) is one of the world’s largest and most influential technology events.\n\nThe 2026 edition, which officially starts today January 6th until January 9th, is bringing togetherover 130,000 visitors, nearly 4,000 exhibitors, and thousands of startups from more than 150 countries.\n\nThis year’s key trends include: [...] Industrial Innovation, Ready for Deployment\n\nCES 2026 confirms a clear evolution: industrial technologies are no longer experimental. From AI-powered robotics and software-defined mobility to advanced sensing and low-carbon remediation, these innovations are designed for real-world constraints, regulations and operational efficiency.\n\nFor industrial players, CES is no longer about spotting distant trends—it’s about identifying deployable technologies that will define competitiveness in the years ahead.\n\nAI AgentsCarbon-FreeNew ProductOEMSensorsTrade Shows\n\nAdvertisement\n\nImage 11: pub\n\nAdvertisement\n\nImage 12: pub\n\nAdvertisement\n\nImage 13: pub\n\nAdvertisement\n\nImage 14: pub\n\nAdvertisement\n\nRelated articles\n\nSee all news\n\n   Image 15: Image Why Wave Springs Are Essential for Bearing Preload Applications (by Smalley)\")Sponsored Content\n### Why Wave Springs Are Essential for Bearing Preload Applications (by Smalley)\")", "score": 0.86713725, "raw_content": null, "summary": "This year’s key trends include: Artificial intelligence embedded at the edge Robotics and automation for real-world operations Software-defined vehicles and smart mobility Sustainable, low-carbon industrial technologies Among the many announcements, four innovations stood out for their immediate relevance to industrial stakeholders. AI AgentsCarbon-FreeNew ProductOEMSensorsTrade Shows Advertisemen"}, {"url": "https://www.prnewswire.com/news-releases/hitachi-ignites-ces-2026-unveiling-key-collaborations-with-nvidia-google-cloud-and-nozomi-networks--bringing-the-power-of-ai-to-social-infrastructure-302656000.html", "title": "Hitachi ignites CES 2026 unveiling key collaborations with NVIDIA ...", "content": "LAS VEGAS, Jan. 8, 2026 /PRNewswire/ -- Hitachi, Ltd. (TSE: 6501; \"Hitachi\"), today completed a pivotal week at CES 2026, detailing its strategy and solutions that bring the transformative power of AI to social infrastructure. Highlighted by collaborations with NVIDIA and Google Cloud, Hitachi's initiative is aimed at applying advanced AI across the world's critical energy, mobility and industrial infrastructure to address pressing societal challenges. Central to this strategy is HMAX by Hitachi, a suite of next-generation solutions that brings the power of AI to social infrastructure and serves as Hitachi's flagship AI solutions portfolio. HMAX will take center stage during the CES Foundry session, \"Pioneering AI Technologies for the Physical World\".\n\nContinue Reading [...] Foundry Session: Pioneering AI Technologies for the Physical World: Arya Barirani, CMO of Hitachi America Ltd., and Deepu Talla, VP and GM of Robotics and Edge AI at NVIDIA, will present \"Pioneering AI Technologies for the Physical World.\" The session explores how the two companies' collaboration will accelerate real-world applications and safely harness the power of physical AI to enable a more efficient and autonomous future. [...] \"Our presence at CES 2026 is the culmination of our vision for a Harmonized Society, where technology serves a greater purpose,\" said Arya Barirani, CMO of Hitachi America Ltd. \"Hitachi is in a unique position to apply the power of AI to systems and infrastructure that directly impact society. By integrating AI into energy grids, rail systems and industrial applications and more, we are addressing complex challenges with novel solutions and demonstrating what's next for a sustainable, interconnected world.\"\n\nKey Hitachi Announcements and Highlights at CES 2026:", "score": 0.852752, "raw_content": null, "summary": "Central to this strategy is HMAX by Hitachi, a suite of next-generation solutions that brings the power of AI to social infrastructure and serves as Hitachi's flagship AI solutions portfolio. Continue Reading [...] Foundry Session: Pioneering AI Technologies for the Physical World: Arya Barirani, CMO of Hitachi America Ltd., and Deepu Talla, VP and GM of Robotics and Edge AI at NVIDIA, will presen"}, {"url": "https://www.caterpillar.com/en/news/corporate-press-releases/h/cat-ces-2026.html", "title": "Caterpillar to Showcase Next Era in Industrial AI and Autonomy at ...", "content": "FOR IMMEDIATE RELEASE\n\nIRVING, Texas, Jan. 5, 2026 – Caterpillar Inc. (NYSE: CAT) will take the keynote stage and show floor at CES® 2026, the world’s most powerful tech event, to highlight how Industrial AI and autonomy are unlocking innovation and transforming worksites around the world.\n\n“Caterpillar’s legacy of innovation is rooted in solving our customers’ toughest challenges, and that mission continues to guide our future,” said Caterpillar CEO Joe Creed. “Technology is accelerating and expanding our ability to meet customer needs by seamlessly connecting deep digital insights with our machine expertise to deliver solutions for their most critical tasks.”\n\nCaterpillar CES 2026 Keynote AddressAnnounced as a keynote speaker by the Consumer Technology Association last fall, Creed will lead a conversation on the company’s legacy of innovation, and how the team is transforming the customer experience with advanced technology. [...] English\n       English\n       Deutsch\n       Español\n       Français\n       Italiano\n       Magyar\n       Nederlands\n       Polski\n       Português\n       Русский\n       中文\n       日本語\n\n_close_\n\nOK\n\n   News\n   Corporate Press Releases\n   Corporate Press Release Archive\n   Caterpillar to Showcase Next Era at CES 2026\n\nImage 3: Cat workers on site\n\nCaterpillar to Showcase Next Era in Industrial AI and Autonomy at CES 2026\n\n_Company leaders to highlight how advanced technology is changing the industrial landscape during keynote and live demonstrations_\n\nFOR IMMEDIATE RELEASE", "score": 0.83678174, "raw_content": null, "summary": "“Technology is accelerating and expanding our ability to meet customer needs by seamlessly connecting deep digital insights with our machine expertise to deliver solutions for their most critical tasks.” Caterpillar CES 2026 Keynote AddressAnnounced as a keynote speaker by the Consumer Technology Association last fall, Creed will lead a conversation on the company’s legacy of innovation, and how t"}, {"url": "https://www.linkedin.com/news/story/ces-2026-kicks-off-with-chatgpt-moment-for-physical-ai-7363081/", "title": "CES 2026 kicks off with 'ChatGPT moment for physical AI' | LinkedIn", "content": "Partnering Human Progress: Our Vision for Human-Centered AI Robotics This week at CES, our parent Hyundai Motor Group unveiled our AI Robotics Strategy under the theme \"Partnering Human Progress.\" For Hyundai Motor Company and the automotive business, our robotics strategy helps us build better vehicles for our customers while creating safer, more rewarding work for our team members. The Boston Dynamics humanoid robot we unveiled represents a breakthrough in industrial robotics. With 56 degrees of freedom, human-scale hands with tactile sensing, and the ability to lift 110 pounds, Atlas will help us deliver beautifully designed vehicles with exceptional quality and industry-leading safety that customers value Our robots don't compete with humans. They compete FOR humans. We call this \"human-centered automation.\" It means deploying robots to handle the tasks that are repetitive, physically demanding, or potentially dangerous, so our team members can focus on higher-value work that requires human judgment, creativity, and oversight. Lifting heavy components, working in extreme temperatures, and performing the [...] Today marks a milestone for the global robotics ecosystem. At NVIDIA, we believe the path to general-purpose robotics shouldn't be a solo climb—it requires a shared foundation of models, data, and simulation. With our latest releases at #CES2026, we are providing the building blocks that allow every startup, researcher, and industrial partner to leapfrog years of R&D. What this means for our ecosystem: • From \"Seeing\" to \"Reasoning\": With GR00T N1.6 and NVIDIA Cosmos, we’re providing the community with World Models that understand the laws of physics, not just pixels. • Democratizing Development: Our partnership with Hugging Face brings these models directly into the LeRobot library, making Physical AI accessible to 13M+ developers. • Solving the \"Eval Bottleneck\": Tools like Isaac Lab-Arena allow you to benchmark policies across hundreds of scenarios simultaneously, moving us past slow, manual testing. • Blackwell at the Edge: The new [...] is expected to create 25,000 jobs and generate more than 100,000 direct and indirect employment opportunities. The future of manufacturing isn't humans versus robots. It's humans AND robots, working side by side, each doing what they do best. As we shared at CES: \"Boston Dynamics makes robots move. Hyundai Motor Group makes them ready for work.\" Together with our partners at Boston Dynamics, Google DeepMind, and NVIDIA, we are building the future of mobility, one where technology serves humanity, not the other way around. It's a great time to be with Hyundai. #CES2026 #Robotics #AI #Hyundai #BostonDynamics #Manufacturing #FutureOfWork #Innovation #CES #automation #futuremobility", "score": 0.82048416, "raw_content": null, "summary": "Partnering Human Progress: Our Vision for Human-Centered AI Robotics This week at CES, our parent Hyundai Motor Group unveiled our AI Robotics Strategy under the theme \"Partnering Human Progress.\" For Hyundai Motor Company and the automotive business, our robotics strategy helps us build better vehicles for our customers while creating safer, more rewarding work for our team members. With 56 degre"}], "response_time": 1.79, "request_id": "315d0a54-93c0-456b-89e7-d05a35d87c69"}, "query_summary": "| | | --- | | 9–9:30 AM | Unlocking AI Transformation: From Devices to Culture, presented by Microsoft (Fontainebleau Level 4) | | 11–11:30 AM | Pioneering Industrial AI Technologies, presented by Hitachi (Fontainebleau Level 4) | | 12:30–1 PM | Robots Among Us: Welcome to the Age of Humanoids, presented by Agility Robots (Fontainebleau Level 4) | | 2–2:30 PM | Uplifting Robots for Independent Liv This year’s key trends include: Artificial intelligence embedded at the edge Robotics and automation for real-world operations Software-defined vehicles and smart mobility Sustainable, low-carbon ind", "lang_pref": "en", "preferred_results": [{"url": "https://www.ces.tech/articles/roboticists-at-ces-2026-a-sample-itinerary/", "title": "Roboticists at CES 2026: A Sample Itinerary", "content": "|  |  |\n --- |\n| 9–9:30 AM | Unlocking AI Transformation: From Devices to Culture, presented by Microsoft (Fontainebleau Level 4) |\n| 11–11:30 AM | Pioneering Industrial AI Technologies, presented by Hitachi (Fontainebleau Level 4) |\n| 12:30–1 PM | Robots Among Us: Welcome to the Age of Humanoids, presented by Agility Robots (Fontainebleau Level 4) |\n| 2–2:30 PM | Uplifting Robots for Independent Living (Venetian Expo Level 2) |\n\n### Evening Celebration\n\nDon’t miss the CES Foundry Celebration Event, presented by IBM, JobsOhio and Vector, from 4:30–6 PM in the Azure Ballroom at Fontainebleau. It’s open to all CES badge holders and promises strategic introductions and high-value exchanges.\n\n Learn More\n\n#### Evening Celebration [...] |  |  |\n --- |\n| 10:30 AM–11 AM | Physical AI and the Big Bang of General Robotics, presented by NVIDIA |\n| 1 PM–1:30 PM | Inside the AI-Native Enterprise, presented by Monks |\n| 3–3:30 PM | AI-Powered Workflows: Transforming Frontline Operations for the Future, presented by Zebra |\n| 4–4:30 PM | Promoting Promise, Preventing Peril: Harnessing AI’s Capabilities for Good |\n\n### Evening Fun\n\nFirst time at CES? Don’t miss the First-Timer Meetup (4:30–6 PM, The Garden at LVCC Central Plaza).\n\n Learn More\n\n## Thursday: Explore, Learn, Connect, Celebrate\n\nVisit top exhibitors like NVIDIA, Intel, Qualcomm, ARM and Mediatrak. Then catch these standout sessions: [...] Get the ultimate CES experience with a show floor tour, Robots Rising: How Machines, AI, and Infrastructure Are Rebuilding the World. This tour explores how robotics, AI and connected infrastructure are reshaping industries and public spaces. Highlighting real-world applications — from autonomous mobility and smart logistics to energy systems and urban tech — it showcases solutions making environments more efficient, responsive and resilient. Attendees will also see how these technologies work with people, keeping human insight at the core of intelligent systems. This tour is designed for professionals eager to see how physical AI is shaping the built world — today and tomorrow.", "score": 0.8724455, "raw_content": null, "summary": "| | | --- | | 9–9:30 AM | Unlocking AI Transformation: From Devices to Culture, presented by Microsoft (Fontainebleau Level 4) | | 11–11:30 AM | Pioneering Industrial AI Technologies, presented by Hitachi (Fontainebleau Level 4) | | 12:30–1 PM | Robots Among Us: Welcome to the Age of Humanoids, presented by Agility Robots (Fontainebleau Level 4) | | 2–2:30 PM | Uplifting Robots for Independent Liv"}, {"url": "https://emag.directindustry.com/2026/01/06/ces-2026-ai-robotics-low-carbon-remediation-industrial-innovation/", "title": "CES 2026: Four Industrial Innovations to Watch", "content": "This year’s key trends include:\n\n   Artificial intelligence embedded at the edge\n   Robotics and automation for real-world operations\n   Software-defined vehicles and smart mobility\n   Sustainable, low-carbon industrial technologies\n\nAmong the many announcements, four innovations stood out for their immediate relevance to industrial stakeholders.\n\n1/ Qualcomm: Powering Physical AI from Industrial AMRs to Full-Size Humanoids\n\n### The innovation\n\nQualcomm is unveiling a next-generation, full-stack robotics architecture designed to move Physical AI out of labs and into real-world industrial environments. Built on safety-grade, high-performance SoC platforms, this comprehensive approach combines hardware, software and compound AI to power general-purpose robots, from industrial AMRs to full-size humanoids capable of reasoning, adapting and making decisions.\n\nAt the core of this announcement is the launch of the Qualcomm Dragonwing™ IQ10 Series, the company’s latest premium-tier robotics processor, purpose-built for advanced autonomous mobile robots and humanoid platforms. [...] January 6, 2026 11 mins\n\nAt CES 2026, innovation is moving decisively from concept to deployment. Robotics, AI-driven mobility, advanced sensing and environmental engineering solutions demonstrated how digital technologies are now reshaping industrial operations, infrastructure and sustainability strategies. From robotics platforms to AI-driven mobility software and low-carbon soil remediation, CES 2026 once again proves that industrial innovation is accelerating well beyond consumer electronics.\n\nCES Las Vegas, a Global Innovation Hub\n\nHeld every January in Las Vegas, CES (Consumer Electronics Show) is one of the world’s largest and most influential technology events.\n\nThe 2026 edition, which officially starts today January 6th until January 9th, is bringing togetherover 130,000 visitors, nearly 4,000 exhibitors, and thousands of startups from more than 150 countries.\n\nThis year’s key trends include: [...] Industrial Innovation, Ready for Deployment\n\nCES 2026 confirms a clear evolution: industrial technologies are no longer experimental. From AI-powered robotics and software-defined mobility to advanced sensing and low-carbon remediation, these innovations are designed for real-world constraints, regulations and operational efficiency.\n\nFor industrial players, CES is no longer about spotting distant trends—it’s about identifying deployable technologies that will define competitiveness in the years ahead.\n\nAI AgentsCarbon-FreeNew ProductOEMSensorsTrade Shows\n\nAdvertisement\n\nImage 11: pub\n\nAdvertisement\n\nImage 12: pub\n\nAdvertisement\n\nImage 13: pub\n\nAdvertisement\n\nImage 14: pub\n\nAdvertisement\n\nRelated articles\n\nSee all news\n\n   Image 15: Image Why Wave Springs Are Essential for Bearing Preload Applications (by Smalley)\")Sponsored Content\n### Why Wave Springs Are Essential for Bearing Preload Applications (by Smalley)\")", "score": 0.86713725, "raw_content": null, "summary": "This year’s key trends include: Artificial intelligence embedded at the edge Robotics and automation for real-world operations Software-defined vehicles and smart mobility Sustainable, low-carbon industrial technologies Among the many announcements, four innovations stood out for their immediate relevance to industrial stakeholders. AI AgentsCarbon-FreeNew ProductOEMSensorsTrade Shows Advertisemen"}, {"url": "https://www.prnewswire.com/news-releases/hitachi-ignites-ces-2026-unveiling-key-collaborations-with-nvidia-google-cloud-and-nozomi-networks--bringing-the-power-of-ai-to-social-infrastructure-302656000.html", "title": "Hitachi ignites CES 2026 unveiling key collaborations with NVIDIA ...", "content": "LAS VEGAS, Jan. 8, 2026 /PRNewswire/ -- Hitachi, Ltd. (TSE: 6501; \"Hitachi\"), today completed a pivotal week at CES 2026, detailing its strategy and solutions that bring the transformative power of AI to social infrastructure. Highlighted by collaborations with NVIDIA and Google Cloud, Hitachi's initiative is aimed at applying advanced AI across the world's critical energy, mobility and industrial infrastructure to address pressing societal challenges. Central to this strategy is HMAX by Hitachi, a suite of next-generation solutions that brings the power of AI to social infrastructure and serves as Hitachi's flagship AI solutions portfolio. HMAX will take center stage during the CES Foundry session, \"Pioneering AI Technologies for the Physical World\".\n\nContinue Reading [...] Foundry Session: Pioneering AI Technologies for the Physical World: Arya Barirani, CMO of Hitachi America Ltd., and Deepu Talla, VP and GM of Robotics and Edge AI at NVIDIA, will present \"Pioneering AI Technologies for the Physical World.\" The session explores how the two companies' collaboration will accelerate real-world applications and safely harness the power of physical AI to enable a more efficient and autonomous future. [...] \"Our presence at CES 2026 is the culmination of our vision for a Harmonized Society, where technology serves a greater purpose,\" said Arya Barirani, CMO of Hitachi America Ltd. \"Hitachi is in a unique position to apply the power of AI to systems and infrastructure that directly impact society. By integrating AI into energy grids, rail systems and industrial applications and more, we are addressing complex challenges with novel solutions and demonstrating what's next for a sustainable, interconnected world.\"\n\nKey Hitachi Announcements and Highlights at CES 2026:", "score": 0.852752, "raw_content": null, "summary": "Central to this strategy is HMAX by Hitachi, a suite of next-generation solutions that brings the power of AI to social infrastructure and serves as Hitachi's flagship AI solutions portfolio. Continue Reading [...] Foundry Session: Pioneering AI Technologies for the Physical World: Arya Barirani, CMO of Hitachi America Ltd., and Deepu Talla, VP and GM of Robotics and Edge AI at NVIDIA, will presen"}, {"url": "https://www.caterpillar.com/en/news/corporate-press-releases/h/cat-ces-2026.html", "title": "Caterpillar to Showcase Next Era in Industrial AI and Autonomy at ...", "content": "FOR IMMEDIATE RELEASE\n\nIRVING, Texas, Jan. 5, 2026 – Caterpillar Inc. (NYSE: CAT) will take the keynote stage and show floor at CES® 2026, the world’s most powerful tech event, to highlight how Industrial AI and autonomy are unlocking innovation and transforming worksites around the world.\n\n“Caterpillar’s legacy of innovation is rooted in solving our customers’ toughest challenges, and that mission continues to guide our future,” said Caterpillar CEO Joe Creed. “Technology is accelerating and expanding our ability to meet customer needs by seamlessly connecting deep digital insights with our machine expertise to deliver solutions for their most critical tasks.”\n\nCaterpillar CES 2026 Keynote AddressAnnounced as a keynote speaker by the Consumer Technology Association last fall, Creed will lead a conversation on the company’s legacy of innovation, and how the team is transforming the customer experience with advanced technology. [...] English\n       English\n       Deutsch\n       Español\n       Français\n       Italiano\n       Magyar\n       Nederlands\n       Polski\n       Português\n       Русский\n       中文\n       日本語\n\n_close_\n\nOK\n\n   News\n   Corporate Press Releases\n   Corporate Press Release Archive\n   Caterpillar to Showcase Next Era at CES 2026\n\nImage 3: Cat workers on site\n\nCaterpillar to Showcase Next Era in Industrial AI and Autonomy at CES 2026\n\n_Company leaders to highlight how advanced technology is changing the industrial landscape during keynote and live demonstrations_\n\nFOR IMMEDIATE RELEASE", "score": 0.83678174, "raw_content": null, "summary": "“Technology is accelerating and expanding our ability to meet customer needs by seamlessly connecting deep digital insights with our machine expertise to deliver solutions for their most critical tasks.” Caterpillar CES 2026 Keynote AddressAnnounced as a keynote speaker by the Consumer Technology Association last fall, Creed will lead a conversation on the company’s legacy of innovation, and how t"}, {"url": "https://www.linkedin.com/news/story/ces-2026-kicks-off-with-chatgpt-moment-for-physical-ai-7363081/", "title": "CES 2026 kicks off with 'ChatGPT moment for physical AI' | LinkedIn", "content": "Partnering Human Progress: Our Vision for Human-Centered AI Robotics This week at CES, our parent Hyundai Motor Group unveiled our AI Robotics Strategy under the theme \"Partnering Human Progress.\" For Hyundai Motor Company and the automotive business, our robotics strategy helps us build better vehicles for our customers while creating safer, more rewarding work for our team members. The Boston Dynamics humanoid robot we unveiled represents a breakthrough in industrial robotics. With 56 degrees of freedom, human-scale hands with tactile sensing, and the ability to lift 110 pounds, Atlas will help us deliver beautifully designed vehicles with exceptional quality and industry-leading safety that customers value Our robots don't compete with humans. They compete FOR humans. We call this \"human-centered automation.\" It means deploying robots to handle the tasks that are repetitive, physically demanding, or potentially dangerous, so our team members can focus on higher-value work that requires human judgment, creativity, and oversight. Lifting heavy components, working in extreme temperatures, and performing the [...] Today marks a milestone for the global robotics ecosystem. At NVIDIA, we believe the path to general-purpose robotics shouldn't be a solo climb—it requires a shared foundation of models, data, and simulation. With our latest releases at #CES2026, we are providing the building blocks that allow every startup, researcher, and industrial partner to leapfrog years of R&D. What this means for our ecosystem: • From \"Seeing\" to \"Reasoning\": With GR00T N1.6 and NVIDIA Cosmos, we’re providing the community with World Models that understand the laws of physics, not just pixels. • Democratizing Development: Our partnership with Hugging Face brings these models directly into the LeRobot library, making Physical AI accessible to 13M+ developers. • Solving the \"Eval Bottleneck\": Tools like Isaac Lab-Arena allow you to benchmark policies across hundreds of scenarios simultaneously, moving us past slow, manual testing. • Blackwell at the Edge: The new [...] is expected to create 25,000 jobs and generate more than 100,000 direct and indirect employment opportunities. The future of manufacturing isn't humans versus robots. It's humans AND robots, working side by side, each doing what they do best. As we shared at CES: \"Boston Dynamics makes robots move. Hyundai Motor Group makes them ready for work.\" Together with our partners at Boston Dynamics, Google DeepMind, and NVIDIA, we are building the future of mobility, one where technology serves humanity, not the other way around. It's a great time to be with Hyundai. #CES2026 #Robotics #AI #Hyundai #BostonDynamics #Manufacturing #FutureOfWork #Innovation #CES #automation #futuremobility", "score": 0.82048416, "raw_content": null, "summary": "Partnering Human Progress: Our Vision for Human-Centered AI Robotics This week at CES, our parent Hyundai Motor Group unveiled our AI Robotics Strategy under the theme \"Partnering Human Progress.\" For Hyundai Motor Company and the automotive business, our robotics strategy helps us build better vehicles for our customers while creating safer, more rewarding work for our team members. With 56 degre"}]}
{"query": "site:technologyreview.com AI trends 2025 (English)", "result": {"query": "AI trends 2025 (English)", "follow_up_questions": null, "answer": null, "images": [], "results": [{"url": "https://www.technologyreview.com/2026/01/05/1130662/whats-next-for-ai-in-2026/", "title": "What's next for AI in 2026 | MIT Technology Review", "content": "How did we do last time? We picked five hot AI trends to look out for in 2025, including what we called generative virtual playgrounds, a.k.a world models (check: From Google DeepMind’s Genie 3 to World Labs’s Marble, tech that can generate realistic virtual environments on the fly keeps getting better and better); so-called reasoning models (check: Need we say more? Reasoning models have fast become the new paradigm for best-in-class problem solving); a boom in AI for science (check: OpenAI is now following Google DeepMind by setting up a dedicated team to focus on just that); AI companies that are cozier with national security (check: OpenAI reversed position on the use of its technology for warfare to sign a deal with the defense-tech startup Anduril to help it take down battlefield drones); and legitimate competition for Nvidia (check, kind of: China is going all in on developing advanced AI chips, but Nvidia’s dominance still [...] In place of state laws, Trump promises to work with Congress to establish a federal AI law. Don’t count on it. Congress failed to pass a moratorium on state legislation twice in 2025, and we aren’t holding out hope that it will deliver its own bill this year.\n\nAI companies like OpenAI and Meta will continue to deploy powerful super-PACs to support political candidates who back their agenda and target those who stand in their way. On the other side, super-PACs supporting AI regulation will build their own war chests to counter. Watch them duke it out at next year’s midterm elections.\n\nThe further AI advances, the more people will fight to steer its course, and 2026 will be another year of regulatory tug-of-war—with no end in sight.\n\n—Michelle Kim\n\n### Chatbots will change the way we shop [...] —James O’Donnell\n\n### Deep Dive\n\n### Artificial intelligence\n\n### OpenAI’s new LLM exposes the secrets of how AI really works\n\nThe experimental model won't compete with the biggest and best, but it could tell us why they behave in weird ways—and how trustworthy they really are.\n\nBy \n\n Will Douglas Heavenarchive page\n\n### The great AI hype correction of 2025\n\nFour ways to think about this year's reckoning.\n\nBy \n\n Will Douglas Heavenarchive page\n\n### Quantum physicists have shrunk and “de-censored” DeepSeek R1\n\nThey managed to cut the size of the AI reasoning model by more than half—and claim it can now answer politically sensitive questions once off limits in Chinese AI systems.\n\nBy \n\n Caiwei Chenarchive page\n\n### An AI model trained on prison phone calls now looks for planned crimes in those calls\n\nThe model is built to detect when crimes are being “contemplated.”\n\nBy", "score": 0.9345448, "raw_content": null, "summary": "Reasoning models have fast become the new paradigm for best-in-class problem solving); a boom in AI for science (check: OpenAI is now following Google DeepMind by setting up a dedicated team to focus on just that); AI companies that are cozier with national security (check: OpenAI reversed position on the use of its technology for warfare to sign a deal with the defense-tech startup Anduril to hel"}, {"url": "https://www.technologyreview.com/2025/01/08/1109188/whats-next-for-ai-in-2025/", "title": "What's next for AI in 2025 - MIT Technology Review", "content": "The US military has launched a number of initiatives that show it’s eager to adopt AI, from the Replicator program—which, inspired by the war in Ukraine, promises to spend $1 billion on small drones—to the Artificial Intelligence Rapid Capabilities Cell, a unit bringing AI into everything from battlefield decision-making to logistics. European militaries are under pressure to up their tech investment, triggered by concerns that Donald Trump’s administration will cut spending to Ukraine. Rising tensions between Taiwan and China weigh heavily on the minds of military planners, too.\n\nIn 2025, these trends will continue to be a boon for defense-tech companies like Palantir, Anduril, and others, which are now capitalizing on classified military data to train AI models. [...] Skip to Content\n\nMIT Technology Review\n\n Featured\n Topics\n Newsletters\n Events\n Audio\n\nMIT Technology Review\n\n Featured\n Topics\n Newsletters\n Events\n Audio\n\nArtificial intelligence\n\n# What’s next for AI in 2025\n\nYou already know that agents and small language models are the next big things. Here are five other hot trends you should watch out for this year.\n\nBy \n\n James O'Donnellarchive page\n Will Douglas Heavenarchive page\n Melissa Heikkiläarchive page\n\nJanuary 8, 2025\n\nStephanie Arnett/MIT Technology Review | Lummi\n\nMIT Technology Review’s What’s Next series looks across industries, trends, and technologies to give you a first look at the future. You can read the rest of them here. [...] The defense industry’s deep pockets will tempt mainstream AI companies into the fold too. OpenAI in December announced it is partnering with Anduril on a program to take down drones, completing a year-long pivot away from its policy of not working with the military. It joins the ranks of Microsoft, Amazon, and Google, which have worked with the Pentagon for years.\n\nOther AI competitors, which are spending billions to train and develop new models, will face more pressure in 2025 to think seriously about revenue. It’s possible that they’ll find enough non-defense customers who will pay handsomely for AI agents that can handle complex tasks, or creative industries willing to spend on image and video generators.", "score": 0.85567063, "raw_content": null, "summary": "The US military has launched a number of initiatives that show it’s eager to adopt AI, from the Replicator program—which, inspired by the war in Ukraine, promises to spend $1 billion on small drones—to the Artificial Intelligence Rapid Capabilities Cell, a unit bringing AI into everything from battlefield decision-making to logistics. [...] Skip to Content MIT Technology Review Featured Topics New"}, {"url": "https://www.technologyreview.com/2025/12/25/1130298/ai-wrapped-the-14-ai-terms-you-couldnt-avoid-in-2025/", "title": "AI Wrapped: The 14 AI terms you couldn't avoid in 2025", "content": "#### 9. Distillation\n\nEarly this year, DeepSeek unveiled its new model DeepSeek R1, an open-source reasoning model that matches top Western models but costs a fraction of the price. Its launch freaked Silicon Valley out, as many suddenly realized for the first time that huge scale and resources were not necessarily the key to high-level AI models. Nvidia stock plunged by 17% the day after R1 was released.\n\nThe key to R1’s success was distillation, a technique that makes AI models more efficient. It works by getting a bigger model to tutor a smaller model: You run the teacher model on a lot of examples and record the answers, and reward the student model as it copies those responses as closely as possible, so that it gains a compressed version of the teacher’s knowledge.  —Caiwei Chen\n\n#### 10. Sycophancy [...] #### 8. Agentic\n\nThis year, AI agents were everywhere. Every new feature announcement, model drop, or security report throughout 2025 was peppered with mentions of them, even though plenty of AI companies and experts disagree on exactly what counts as being truly “agentic,” a vague term if ever there was one. No matter that it’s virtually impossible to guarantee that an AI acting on your behalf out in the wide web will always do exactly what it’s supposed to do—it seems as though agentic AI is here to stay for the foreseeable. Want to sell something? Call it agentic! —Rhiannon Williams\n\n#### 9. Distillation [...] Sarah Rogers/Stephanie Arnett | Getty Images, Adobe Stock\n\nIf the past 12 months have taught us anything, it’s that the AI hype train is showing no signs of slowing. It’s hard to believe that at the beginning of the year, DeepSeek had yet to turn the entire industry on its head, Meta was better known for trying (and failing) to make the metaverse cool than for its relentless quest to dominate superintelligence, and vibe coding wasn’t a thing.\n\nIf that’s left you feeling a little confused, fear not. As we near the end of 2025, our writers have taken a look back over the AI terms that dominated the year, for better or worse.\n\nMake sure you take the time to brace yourself for what promises to be another bonkers year.\n\n—Rhiannon Williams\n\n#### 1. Superintelligence", "score": 0.8098936, "raw_content": null, "summary": "It works by getting a bigger model to tutor a smaller model: You run the teacher model on a lot of examples and record the answers, and reward the student model as it copies those responses as closely as possible, so that it gains a compressed version of the teacher’s knowledge. It’s hard to believe that at the beginning of the year, DeepSeek had yet to turn the entire industry on its head, Meta w"}, {"url": "https://wp.technologyreview.com/wp-content/uploads/2025/05/MITTR-ARM25_V10_041625_FINAL.pdf?utm_source=report_page&utm_medium=social&utm_campaign=insights_report&utm_term=04.22.25&utm_content=sponsored", "title": "[PDF] The future of AI processing - MIT Technology Review", "content": "Review Insights based on data from “Smart Home Market - Global Industry Assessment and Forecast,” Vantage Market Research, 2025 Compound annual growth rate: 10% $195.73 billion $91.3 billion 2022 2023 2024 2025 2026 2027 2028 2029 2030 10 MIT Technology Review Insights 04 04 Work he scale of AI usage at work is hard to calculate, but a 2025 McKinsey survey found that 78% of organizations have integrated AI into at least one business function, up from 72% in 2024 and 55% in 2023.26 In the near future, self-directed agents will likely increase the scale of AI in the workplace further. “In 2025, I think we’re going to see leading LLMs [becoming] much more agentic— meaning self-directed execution of AI agents—and they will become more agents than assistants,” [...] 38. Simmone Shah, “Refik Anadol Sees Artistic Possibilities in Data,” Time, February 10, 2025, \n39. “Adobe Firefly,” Adobe, \n40. Will Deller, “Horizon Scan 2025: Key Trends in Games & Esports,” Bird&Bird, February 11, 2025, \n41. “AI-powered responsible gaming transforms player protection,” SiGMA,  ai-powered-responsible-gaming-transforms-player-protection/.\n42. Christos G. Bampis, Li- Heng Chen, and Zhi Li, “For your eyes only: improving Netflix video quality with neural networks,”, Netflix Tech Blog, November 14, 2022, [...] 22. Asuka Kawanabe, “Future Voice Vol.4 Mobility’s Future: A Platform for Entertainment and Self Expression,”, Afeela, April 24, 2024, \n23. “Lotus: Eletre and Emeya,” Arm,  lotus.\n24. “The Road Ahead with Mercedes-Benz,” Arm,  made-possible/mercedes-benz. 25. Michelle Faverio, “Key findings about Americans and data privacy,” Pew Research Center, October 18, 2023, \n26. “The state of AI in 2025: Gen AI adoption spikes and starts to generate value,” McKinsey & Company, March 12, 2025, \n27. Daniel Howley, “Meta to spend as much as $65 billion on AI in 2025,” Yahoo Finance, January 24, 2025,", "score": 0.7511561, "raw_content": null, "summary": "Review Insights based on data from “Smart Home Market - Global Industry Assessment and Forecast,” Vantage Market Research, 2025 Compound annual growth rate: 10% $195.73 billion $91.3 billion 2022 2023 2024 2025 2026 2027 2028 2029 2030 10 MIT Technology Review Insights 04 04 Work he scale of AI usage at work is hard to calculate, but a 2025 McKinsey survey found that 78% of organizations have inte"}, {"url": "https://www.technologyreview.com/", "title": "MIT Technology Review", "content": "In partnership withDatabricks\n\nCollection\n\n## What's Next\n\nMIT Technology Review’s What’s Next series looks across industries, trends, and technologies to give you a first look at the future.\n\nClimate change and energy\n\n### What’s next for nuclear power\n\nGlobal shifts, advancing tech, and data center demand: Here’s what’s coming in 2025 and beyond.\n\nArtificial intelligence\n\n### What’s next for AI in 2025\n\nYou already know that agents and small language models are the next big things. Here are five other hot trends you should watch out for this year.\n\nPolicy\n\n### What’s next for our privacy?\n\nThe US still has no federal privacy law. But recent enforcement actions against data brokers may offer some new protections for Americans’ personal information.\n\nClimate change and energy\n\n### Why EVs are (mostly) set for solid growth in 2025 [...] ### The great AI hype correction of 2025\n\nFour ways to think about this year's reckoning.\n\nArtificial intelligence\n\n### What even is the AI bubble?\n\nEveryone in tech agrees we’re in a bubble. They just can’t agree on what it looks like — or what happens when it pops.\n\nArtificial intelligence\n\n### AI materials discovery now needs to move into the real world\n\nStartups flush with cash are building AI-assisted laboratories to find materials far faster and more cheaply, but are still waiting for their ChatGPT moment.\n\nBusiness\n\n### AI coding is now everywhere. But not everyone is convinced.\n\nDevelopers are navigating confusing gaps between expectation and reality. So are the rest of us.\n\nArtificial intelligence\n\n### A brief history of Sam Altman’s hype\n\nHere’s how pinning a utopian vision for AI on LLMs kicked off the hype cycle that’s causing fears of a bubble today.\n\nArtificial intelligence [...] The experimental model won't compete with the biggest and best, but it could tell us why they behave in weird ways—and how trustworthy they really are.\n\nArtificial intelligence\n\n### The great AI hype correction of 2025\n\nFour ways to think about this year's reckoning.\n\nClimate change and energy\n\n### China figured out how to sell EVs. Now it has to deal with their aging batteries.\n\nAs early electric cars age out, hundreds of thousands of used batteries are flooding the market, fueling a gray recycling economy even as Beijing and big manufacturers scramble to build a more orderly system.\n\nCulture\n\n### The 8 worst technology flops of 2025\n\nThe Cybertruck, sycophantic AI, and humanoid robots all made this year’s list of the biggest technology failures.\n\n## Hype Correction\n\nAn MIT Technology Review Series\n\nArtificial intelligence3 weeks\n\n### The great AI hype correction of 2025", "score": 0.7286136, "raw_content": null, "summary": "Climate change and energy ### Why EVs are (mostly) set for solid growth in 2025 [...] ### The great AI hype correction of 2025 Four ways to think about this year's reckoning. Artificial intelligence ### AI materials discovery now needs to move into the real world Startups flush with cash are building AI-assisted laboratories to find materials far faster and more cheaply, but are still waiting for"}], "response_time": 2.81, "request_id": "a4bbb79a-34f0-4651-a3ec-87ea35a03cb8"}, "query_summary": "Reasoning models have fast become the new paradigm for best-in-class problem solving); a boom in AI for science (check: OpenAI is now following Google DeepMind by setting up a dedicated team to focus on just that); AI companies that are cozier with national security (check: OpenAI reversed position on the use of its technology for warfare to sign a deal with the defense-tech startup Anduril to hel The US military has launched a number of initiatives that show it’s eager to adopt AI, from the Replicator program—which, inspired by the war in Ukraine, promises to spend $1 billion on small drones—", "lang_pref": "en", "preferred_results": [{"url": "https://www.technologyreview.com/2026/01/05/1130662/whats-next-for-ai-in-2026/", "title": "What's next for AI in 2026 | MIT Technology Review", "content": "How did we do last time? We picked five hot AI trends to look out for in 2025, including what we called generative virtual playgrounds, a.k.a world models (check: From Google DeepMind’s Genie 3 to World Labs’s Marble, tech that can generate realistic virtual environments on the fly keeps getting better and better); so-called reasoning models (check: Need we say more? Reasoning models have fast become the new paradigm for best-in-class problem solving); a boom in AI for science (check: OpenAI is now following Google DeepMind by setting up a dedicated team to focus on just that); AI companies that are cozier with national security (check: OpenAI reversed position on the use of its technology for warfare to sign a deal with the defense-tech startup Anduril to help it take down battlefield drones); and legitimate competition for Nvidia (check, kind of: China is going all in on developing advanced AI chips, but Nvidia’s dominance still [...] In place of state laws, Trump promises to work with Congress to establish a federal AI law. Don’t count on it. Congress failed to pass a moratorium on state legislation twice in 2025, and we aren’t holding out hope that it will deliver its own bill this year.\n\nAI companies like OpenAI and Meta will continue to deploy powerful super-PACs to support political candidates who back their agenda and target those who stand in their way. On the other side, super-PACs supporting AI regulation will build their own war chests to counter. Watch them duke it out at next year’s midterm elections.\n\nThe further AI advances, the more people will fight to steer its course, and 2026 will be another year of regulatory tug-of-war—with no end in sight.\n\n—Michelle Kim\n\n### Chatbots will change the way we shop [...] —James O’Donnell\n\n### Deep Dive\n\n### Artificial intelligence\n\n### OpenAI’s new LLM exposes the secrets of how AI really works\n\nThe experimental model won't compete with the biggest and best, but it could tell us why they behave in weird ways—and how trustworthy they really are.\n\nBy \n\n Will Douglas Heavenarchive page\n\n### The great AI hype correction of 2025\n\nFour ways to think about this year's reckoning.\n\nBy \n\n Will Douglas Heavenarchive page\n\n### Quantum physicists have shrunk and “de-censored” DeepSeek R1\n\nThey managed to cut the size of the AI reasoning model by more than half—and claim it can now answer politically sensitive questions once off limits in Chinese AI systems.\n\nBy \n\n Caiwei Chenarchive page\n\n### An AI model trained on prison phone calls now looks for planned crimes in those calls\n\nThe model is built to detect when crimes are being “contemplated.”\n\nBy", "score": 0.9345448, "raw_content": null, "summary": "Reasoning models have fast become the new paradigm for best-in-class problem solving); a boom in AI for science (check: OpenAI is now following Google DeepMind by setting up a dedicated team to focus on just that); AI companies that are cozier with national security (check: OpenAI reversed position on the use of its technology for warfare to sign a deal with the defense-tech startup Anduril to hel"}, {"url": "https://www.technologyreview.com/2025/01/08/1109188/whats-next-for-ai-in-2025/", "title": "What's next for AI in 2025 - MIT Technology Review", "content": "The US military has launched a number of initiatives that show it’s eager to adopt AI, from the Replicator program—which, inspired by the war in Ukraine, promises to spend $1 billion on small drones—to the Artificial Intelligence Rapid Capabilities Cell, a unit bringing AI into everything from battlefield decision-making to logistics. European militaries are under pressure to up their tech investment, triggered by concerns that Donald Trump’s administration will cut spending to Ukraine. Rising tensions between Taiwan and China weigh heavily on the minds of military planners, too.\n\nIn 2025, these trends will continue to be a boon for defense-tech companies like Palantir, Anduril, and others, which are now capitalizing on classified military data to train AI models. [...] Skip to Content\n\nMIT Technology Review\n\n Featured\n Topics\n Newsletters\n Events\n Audio\n\nMIT Technology Review\n\n Featured\n Topics\n Newsletters\n Events\n Audio\n\nArtificial intelligence\n\n# What’s next for AI in 2025\n\nYou already know that agents and small language models are the next big things. Here are five other hot trends you should watch out for this year.\n\nBy \n\n James O'Donnellarchive page\n Will Douglas Heavenarchive page\n Melissa Heikkiläarchive page\n\nJanuary 8, 2025\n\nStephanie Arnett/MIT Technology Review | Lummi\n\nMIT Technology Review’s What’s Next series looks across industries, trends, and technologies to give you a first look at the future. You can read the rest of them here. [...] The defense industry’s deep pockets will tempt mainstream AI companies into the fold too. OpenAI in December announced it is partnering with Anduril on a program to take down drones, completing a year-long pivot away from its policy of not working with the military. It joins the ranks of Microsoft, Amazon, and Google, which have worked with the Pentagon for years.\n\nOther AI competitors, which are spending billions to train and develop new models, will face more pressure in 2025 to think seriously about revenue. It’s possible that they’ll find enough non-defense customers who will pay handsomely for AI agents that can handle complex tasks, or creative industries willing to spend on image and video generators.", "score": 0.85567063, "raw_content": null, "summary": "The US military has launched a number of initiatives that show it’s eager to adopt AI, from the Replicator program—which, inspired by the war in Ukraine, promises to spend $1 billion on small drones—to the Artificial Intelligence Rapid Capabilities Cell, a unit bringing AI into everything from battlefield decision-making to logistics. [...] Skip to Content MIT Technology Review Featured Topics New"}, {"url": "https://www.technologyreview.com/2025/12/25/1130298/ai-wrapped-the-14-ai-terms-you-couldnt-avoid-in-2025/", "title": "AI Wrapped: The 14 AI terms you couldn't avoid in 2025", "content": "#### 9. Distillation\n\nEarly this year, DeepSeek unveiled its new model DeepSeek R1, an open-source reasoning model that matches top Western models but costs a fraction of the price. Its launch freaked Silicon Valley out, as many suddenly realized for the first time that huge scale and resources were not necessarily the key to high-level AI models. Nvidia stock plunged by 17% the day after R1 was released.\n\nThe key to R1’s success was distillation, a technique that makes AI models more efficient. It works by getting a bigger model to tutor a smaller model: You run the teacher model on a lot of examples and record the answers, and reward the student model as it copies those responses as closely as possible, so that it gains a compressed version of the teacher’s knowledge.  —Caiwei Chen\n\n#### 10. Sycophancy [...] #### 8. Agentic\n\nThis year, AI agents were everywhere. Every new feature announcement, model drop, or security report throughout 2025 was peppered with mentions of them, even though plenty of AI companies and experts disagree on exactly what counts as being truly “agentic,” a vague term if ever there was one. No matter that it’s virtually impossible to guarantee that an AI acting on your behalf out in the wide web will always do exactly what it’s supposed to do—it seems as though agentic AI is here to stay for the foreseeable. Want to sell something? Call it agentic! —Rhiannon Williams\n\n#### 9. Distillation [...] Sarah Rogers/Stephanie Arnett | Getty Images, Adobe Stock\n\nIf the past 12 months have taught us anything, it’s that the AI hype train is showing no signs of slowing. It’s hard to believe that at the beginning of the year, DeepSeek had yet to turn the entire industry on its head, Meta was better known for trying (and failing) to make the metaverse cool than for its relentless quest to dominate superintelligence, and vibe coding wasn’t a thing.\n\nIf that’s left you feeling a little confused, fear not. As we near the end of 2025, our writers have taken a look back over the AI terms that dominated the year, for better or worse.\n\nMake sure you take the time to brace yourself for what promises to be another bonkers year.\n\n—Rhiannon Williams\n\n#### 1. Superintelligence", "score": 0.8098936, "raw_content": null, "summary": "It works by getting a bigger model to tutor a smaller model: You run the teacher model on a lot of examples and record the answers, and reward the student model as it copies those responses as closely as possible, so that it gains a compressed version of the teacher’s knowledge. It’s hard to believe that at the beginning of the year, DeepSeek had yet to turn the entire industry on its head, Meta w"}, {"url": "https://wp.technologyreview.com/wp-content/uploads/2025/05/MITTR-ARM25_V10_041625_FINAL.pdf?utm_source=report_page&utm_medium=social&utm_campaign=insights_report&utm_term=04.22.25&utm_content=sponsored", "title": "[PDF] The future of AI processing - MIT Technology Review", "content": "Review Insights based on data from “Smart Home Market - Global Industry Assessment and Forecast,” Vantage Market Research, 2025 Compound annual growth rate: 10% $195.73 billion $91.3 billion 2022 2023 2024 2025 2026 2027 2028 2029 2030 10 MIT Technology Review Insights 04 04 Work he scale of AI usage at work is hard to calculate, but a 2025 McKinsey survey found that 78% of organizations have integrated AI into at least one business function, up from 72% in 2024 and 55% in 2023.26 In the near future, self-directed agents will likely increase the scale of AI in the workplace further. “In 2025, I think we’re going to see leading LLMs [becoming] much more agentic— meaning self-directed execution of AI agents—and they will become more agents than assistants,” [...] 38. Simmone Shah, “Refik Anadol Sees Artistic Possibilities in Data,” Time, February 10, 2025, \n39. “Adobe Firefly,” Adobe, \n40. Will Deller, “Horizon Scan 2025: Key Trends in Games & Esports,” Bird&Bird, February 11, 2025, \n41. “AI-powered responsible gaming transforms player protection,” SiGMA,  ai-powered-responsible-gaming-transforms-player-protection/.\n42. Christos G. Bampis, Li- Heng Chen, and Zhi Li, “For your eyes only: improving Netflix video quality with neural networks,”, Netflix Tech Blog, November 14, 2022, [...] 22. Asuka Kawanabe, “Future Voice Vol.4 Mobility’s Future: A Platform for Entertainment and Self Expression,”, Afeela, April 24, 2024, \n23. “Lotus: Eletre and Emeya,” Arm,  lotus.\n24. “The Road Ahead with Mercedes-Benz,” Arm,  made-possible/mercedes-benz. 25. Michelle Faverio, “Key findings about Americans and data privacy,” Pew Research Center, October 18, 2023, \n26. “The state of AI in 2025: Gen AI adoption spikes and starts to generate value,” McKinsey & Company, March 12, 2025, \n27. Daniel Howley, “Meta to spend as much as $65 billion on AI in 2025,” Yahoo Finance, January 24, 2025,", "score": 0.7511561, "raw_content": null, "summary": "Review Insights based on data from “Smart Home Market - Global Industry Assessment and Forecast,” Vantage Market Research, 2025 Compound annual growth rate: 10% $195.73 billion $91.3 billion 2022 2023 2024 2025 2026 2027 2028 2029 2030 10 MIT Technology Review Insights 04 04 Work he scale of AI usage at work is hard to calculate, but a 2025 McKinsey survey found that 78% of organizations have inte"}, {"url": "https://www.technologyreview.com/", "title": "MIT Technology Review", "content": "In partnership withDatabricks\n\nCollection\n\n## What's Next\n\nMIT Technology Review’s What’s Next series looks across industries, trends, and technologies to give you a first look at the future.\n\nClimate change and energy\n\n### What’s next for nuclear power\n\nGlobal shifts, advancing tech, and data center demand: Here’s what’s coming in 2025 and beyond.\n\nArtificial intelligence\n\n### What’s next for AI in 2025\n\nYou already know that agents and small language models are the next big things. Here are five other hot trends you should watch out for this year.\n\nPolicy\n\n### What’s next for our privacy?\n\nThe US still has no federal privacy law. But recent enforcement actions against data brokers may offer some new protections for Americans’ personal information.\n\nClimate change and energy\n\n### Why EVs are (mostly) set for solid growth in 2025 [...] ### The great AI hype correction of 2025\n\nFour ways to think about this year's reckoning.\n\nArtificial intelligence\n\n### What even is the AI bubble?\n\nEveryone in tech agrees we’re in a bubble. They just can’t agree on what it looks like — or what happens when it pops.\n\nArtificial intelligence\n\n### AI materials discovery now needs to move into the real world\n\nStartups flush with cash are building AI-assisted laboratories to find materials far faster and more cheaply, but are still waiting for their ChatGPT moment.\n\nBusiness\n\n### AI coding is now everywhere. But not everyone is convinced.\n\nDevelopers are navigating confusing gaps between expectation and reality. So are the rest of us.\n\nArtificial intelligence\n\n### A brief history of Sam Altman’s hype\n\nHere’s how pinning a utopian vision for AI on LLMs kicked off the hype cycle that’s causing fears of a bubble today.\n\nArtificial intelligence [...] The experimental model won't compete with the biggest and best, but it could tell us why they behave in weird ways—and how trustworthy they really are.\n\nArtificial intelligence\n\n### The great AI hype correction of 2025\n\nFour ways to think about this year's reckoning.\n\nClimate change and energy\n\n### China figured out how to sell EVs. Now it has to deal with their aging batteries.\n\nAs early electric cars age out, hundreds of thousands of used batteries are flooding the market, fueling a gray recycling economy even as Beijing and big manufacturers scramble to build a more orderly system.\n\nCulture\n\n### The 8 worst technology flops of 2025\n\nThe Cybertruck, sycophantic AI, and humanoid robots all made this year’s list of the biggest technology failures.\n\n## Hype Correction\n\nAn MIT Technology Review Series\n\nArtificial intelligence3 weeks\n\n### The great AI hype correction of 2025", "score": 0.7286136, "raw_content": null, "summary": "Climate change and energy ### Why EVs are (mostly) set for solid growth in 2025 [...] ### The great AI hype correction of 2025 Four ways to think about this year's reckoning. Artificial intelligence ### AI materials discovery now needs to move into the real world Startups flush with cash are building AI-assisted laboratories to find materials far faster and more cheaply, but are still waiting for"}]}
{"query": "site:ieee.org AI trends 2025 (English)", "result": {"query": "AI trends 2025 (English)", "follow_up_questions": null, "answer": null, "images": [], "results": [{"url": "https://www.ieee.org/about/news/2025/ieee-reveals-predictions-for-top-technology-trends-of-2025", "title": "IEEE Reveals Predictions for Top Technology Trends of 2025", "content": "1. Leveling of the AI playing field with new forms of Large Language Model (LLM) deployment: As AI continues to grow in accessibility, companies will seek out ways to efficiently leverage LLMs. For instance, open-source communities create ways for developers to efficiently tap into successful models, and cloud services are providing LLM solutions with integrated prompt engineering. Hardware evolution will continue to specifically accommodate for optimal run of LLMs, and model compression will continue. As a result, 2025 will see deployments of Small Language Models and exotic, special-purpose models, transforming industries through more domain-specific and efficient AI applications. [...] 3. Commercial success of AI agents: Building on the success of LLM accessibility, AI agents will combine LLMs, machine learning (ML) models, and rule-based systems to provide autonomous, highly specialized solutions for finance, manufacturing, and retail operations. The coinciding advancement of small language models will lower hardware requirements and enable easier fine-tuning of AI agent solutions, and open-source AI libraries and models will allow for model and data ownership. In addition, cloud solutions with friendly user interfaces and low code approaches will increase the accessibility of these solutions in 2025. Businesses will deploy AI agents for a variety of customer service and simplified operational tasks. [...] 4. More widespread evaluation of AI-enhanced robotics: In 2025, embodied intelligence will enable robots to perceive, learn, and collaborate in dynamic environments, achieving unprecedented autonomy and human-like adaptability. We can expect advancements in research settings, including work on LLMs, multimodal AI, and computer vision; advanced edge computing and 5G/6G networks; next-generation battery technology, wireless charging, and energy storage; integrated sensors with advanced fusion capabilities and real-time analytics to enable enhanced perception and seamless interaction; and robust data integration from the Internet of Things (IoT) for real-time adaptability. At the same time, engineers will continue exploring standardized protocols for robot-to-robot communication to ensure seamless interaction and collaboration.", "score": 0.90830135, "raw_content": null, "summary": "The coinciding advancement of small language models will lower hardware requirements and enable easier fine-tuning of AI agent solutions, and open-source AI libraries and models will allow for model and data ownership. We can expect advancements in research settings, including work on LLMs, multimodal AI, and computer vision; advanced edge computing and 5G/6G networks; next-generation battery tech"}, {"url": "https://www.ieee.org/about/news/2024/news-release-2024-survey-results", "title": "In New IEEE Global Survey, Twice as Many Technologists Expect AI ...", "content": "This is the second consecutive year that AI tops the list of most important technologies in the year ahead in the annual IEEE Impact of Technology global survey. When asked to select the top three areas of technology that will be most important in 2025 from over a dozen areas, respondents chose:\n\n●  (58%) AI (including predictive and generative AI, machine learning, natural language processing)\n\n●  (26%) Cloud computing\n\n●  (24%) Robotics\n\nOther important technologies in 2025 include extended reality (XR), including metaverse, augmented reality, virtual reality, and mixed reality (21%); industrial internet of things (19%); quantum, including quantum computing (17%), and electric vehicles/EV charging (17%). [...] In New IEEE Global Survey, Twice as Many Technologists Expect AI to Be the Most Important Tech in 2025 Compared to Other Areas | IEEE\n\nSkip to Content\n\n# In New IEEE Global Survey, Twice as Many Technologists Expect AI to Be the Most Important Tech in 2025 Compared to Other Areas\n\nAnnual Study of CIOs, CTOs and Technology Leaders Forecasts 2025 Trends\n\nCloud computing, robotics, extended reality (XR), industrial internet of things, quantum computing, and electric vehicles|EV charging among the most important technologies in 2025 [...] However, a strong majority of respondents (91%) agree in 2025 there will be a generative AI reckoning as public fascination and perception shift to a greater understanding of and expectations for, what the technology can and should do -- in terms of accuracy of results, transparency around deepfakes and more.\n\nRegarding the adoption of generative AI and which stage they expect their organization to reach in 2025, most respondents indicated they expect to embrace the technology. That said, nearly one-quarter expect to rethink their organization’s approach due to challenges or will start exploring the technology at their organization. Given these insights, it will be far from mass market integration next year.\n\n●  (33%) High Expectations: We are excited and will continue to try generative AI in small projects\n\n●  (24%) Learning: We will continue to find practical uses for generative AI and are seeing some benefits", "score": 0.84767824, "raw_content": null, "summary": "When asked to select the top three areas of technology that will be most important in 2025 from over a dozen areas, respondents chose: ● (58%) AI (including predictive and generative AI, machine learning, natural language processing) ● (26%) Cloud computing ● (24%) Robotics Other important technologies in 2025 include extended reality (XR), including metaverse, augmented reality, virtual reality,"}, {"url": "https://innovationatwork.ieee.org/top-tech-trends-of-2025-and-what-they-mean-for-2026/", "title": "Top Tech Trends of 2025 and What They Mean for 2026", "content": "_Large Language Models: Evolution, Impact, and Hands‑On Exercises:_ Developed in partnership with the IEEE Computer Society, this course traces the progression of language models from statistical approaches to modern transformer architectures. Learners explore milestones in AI development and examine real‑world applications. They also gain practical experience through a hands‑on gradient descent exercise on model optimization. By combining historical context with applied practice, the course equips participants to understand both the opportunities and challenges of deploying LLMs in engineering and technology.\n\nLooking Ahead to 2026\n\nThe trends of 2025 laid the foundation for what comes next. In 2026, expect deeper AI integration in manufacturing, wider adoption of battery storage, and continued advances in power systems and language models. By investing in your skills today, you position yourself to lead tomorrow’s innovations.\n\nTuesday, 23rd December 2025\n\n##### Related Tags [...] A Year of Rapid Change\n\nAs 2025 comes to a close, the pace of innovation has accelerated across every major industry. AI reshaped semiconductor manufacturing. Battery storage technologies advanced faster than expected. Power systems grew more intelligent and resilient. And large language models continued to redefine how engineers design, test, and communicate.\n\nThese shifts aren’t isolated events. Instead, they point directly to what professionals will need to understand in 2026. By tracking these trends now, you can apply the latest engineering practices with confidence. This way, you can stay competitive in a fast‑moving landscape.\n\nBelow, you’ll find the most influential tech trends of 2025 — each paired with a new IEEE Learning Network course developed by IEEE Educational Activities and partners across IEEE. These are designed to help you build the skills that matter most for the year ahead.\n\nAI Applications in Semiconductor Packaging [...] Mastering AI Integration in Semiconductor Manufacturing\n\nBeyond packaging, AI is reshaping semiconductor production from end to end. In 2025, factories expanded their use of AI-driven systems that combine IoT sensors, edge computing, and predictive analytics. These tools now monitor processes in real time and help engineers optimize production faster than ever.\n\nWhy it matters: AI scales manufacturing intelligence. When every stage of production becomes smarter, manufacturers reduce defects, improve yield, and accelerate innovation. This shift is essential for staying competitive in a global market.", "score": 0.84183896, "raw_content": null, "summary": "_Large Language Models: Evolution, Impact, and Hands‑On Exercises:_ Developed in partnership with the IEEE Computer Society, this course traces the progression of language models from statistical approaches to modern transformer architectures. In 2026, expect deeper AI integration in manufacturing, wider adoption of battery storage, and continued advances in power systems and language models."}, {"url": "https://spectrum.ieee.org/ai-index-2025", "title": "The State of AI 2025: 12 Eye-Opening Graphs - IEEE Spectrum", "content": "IEEE Spectrum\n\nIf you read the news about AI, you may feel bombarded with conflicting messages: AI is booming. AI is a bubble. AI’s current techniques and architectures will keep producing breakthroughs. AI is on an unsustainable path and needs radical new ideas. AI is going to take your job. AI is mostly good for turning your family photos into Studio Ghibli–style animated images.\n\nCutting through the confusion is the 2025 AI Index from Stanford University’s Institute for Human-Centered Artificial Intelligence. The 400+ page report is stuffed with graphs and data on the topics of R&D, technical performance, responsible AI, economic impacts, science and medicine, policy, education, and public opinion. As IEEE Spectrum does every year (see our coverage from 2021, 2022, 2023, and 2024), we’ve read the whole thing and plucked out the graphs that we think tell the real story of AI right now. [...] Joseph Park08 Apr, 2025\n\nSM\n\nThank you for the topical and informative article. Please consider to repost with legible graphic text in graphs 2-9,11,12. Thank you.\n\n0 Replies;)  Hide replies;) \n\nShow More Replies\n\nBob Whitcombe11 Apr, 2025\n\nM\n\nI find a conclusion that the US is in the lead on models given China has a low cost, public domain model that cost little to run and performs on par with ChatGPT 4. What's worse, are humans thinking they are so valuable that AI is not a threat. AI starting to rewrite the workplace rules and their value. Thank goodness I had the foresight to be born 70 years ago so I can now retire.\n\n1 Reply;)  Hide replies;) \n\nShow More Replies\n\nWilliam Adams10 Apr, 2025\n\nLS\n\nAI is genuine stupidity\n\nand\n\nModern tulipmania [...] ## 10. Dr. AI Will See You Soon, Maybe\n\nAI for science and medicine is a mini-boom within the AI boom. The report lists a variety of new foundation models that have been released to help researchers in fields such as materials science, weather forecasting, and quantum computing. Many companies are trying to turn AI’s predictive and generative powers into profitable drug discovery. And OpenAI’s o1 reasoning model recently scored 96 percent on a benchmark called MedQA, which has questions from medical board exams.", "score": 0.81489426, "raw_content": null, "summary": "The 400+ page report is stuffed with graphs and data on the topics of R&D, technical performance, responsible AI, economic impacts, science and medicine, policy, education, and public opinion. 0 Replies;) Hide replies;) Show More Replies Bob Whitcombe11 Apr, 2025 M I find a conclusion that the US is in the lead on models given China has a low cost, public domain model that cost little to run and p"}, {"url": "https://spectrum.ieee.org/topic/artificial-intelligence/", "title": "AI News & Articles - Artificial Intelligence Updates - IEEE Spectrum", "content": "01 Jan 2026\n\n5 min read\n\nAINews\n\n## IEEE Spectrum's Top 6 AI Stories of 2025\n\nAI coding, AGI, and more made up Spectrum’s best stories\n\n31 Dec 2025\n\n3 min read\n\nEnergySemiconductorsConsumer ElectronicsWhitepaper\n\n## Hermetic Sealing Solutions for High-Performance Miniaturized Battery Systems\n\nProcessing considerations for achieving optimal seal integrity\n\n24 Dec 2025\n\n## Get AI Alert in your inbox\n\nSign up for our FREE biweekly newsletter featuring the news you need about machine learning algorithms and applications\n\nSubscribe\n\nPlease enter a valid email address, and accept the Privacy Policy.\n\nThank you for your subscription!\n\nComputingAINews\n\n## This AI Can Beat You at Rock-Paper-Scissors\n\nA reservoir-computing chip offers fast and low-power predictions\n\n16 Dec 2025\n\n4 min read\n\nThe InstituteAICareersArticle [...] 3 min read\n\nRoboticsNewsJournal Watch\n\n## New Mapping Model Enhances Robot Terrain Navigation\n\n24 Sep 2025\n\n2 min read\n\nAIInterview\n\n## Are We Testing AI Intelligence the Wrong Way?\n\nMelanie Mitchell says today’s benchmarks aren’t cutting it\n\n04 Dec 2025\n\n5 min read\n\nComputingAerospaceAISemiconductorsNews\n\n## Room-Size Particle Accelerators Go Commercial\n\nNew devices to be used in radiation testing for space electronics\n\n04 Dec 2025\n\n4 min read\n\nAINews\n\n## AI Models’ Reasoning Flaws Impact Critical Fields\n\nAs AI takes on agent roles, flawed reasoning raises risks\n\n02 Dec 2025\n\n5 min read\n\n## The Scale Issue\n\nHumanity’s greatest challenges require us to radically scale up our ingenuity\n\n See the full report →\n\nEnergyAerospaceMagazineFeatureSpecial ReportsOctober 2025Climate TechThe Scale Issue", "score": 0.798643, "raw_content": null, "summary": "01 Jan 2026 5 min read AINews ## IEEE Spectrum's Top 6 AI Stories of 2025 AI coding, AGI, and more made up Spectrum’s best stories 31 Dec 2025 3 min read EnergySemiconductorsConsumer ElectronicsWhitepaper ## Hermetic Sealing Solutions for High-Performance Miniaturized Battery Systems Processing considerations for achieving optimal seal integrity 24 Dec 2025 ## Get AI Alert in your inbox Sign up fo"}], "response_time": 1.94, "request_id": "b49d8bd0-7314-4123-a52b-6606c5c1edc6"}, "query_summary": "The coinciding advancement of small language models will lower hardware requirements and enable easier fine-tuning of AI agent solutions, and open-source AI libraries and models will allow for model and data ownership. We can expect advancements in research settings, including work on LLMs, multimodal AI, and computer vision; advanced edge computing and 5G/6G networks; next-generation battery tech When asked to select the top three areas of technology that will be most important in 2025 from over a dozen areas, respondents chose: ● (58%) AI (including predictive and generative AI, machine lear", "lang_pref": "en", "preferred_results": [{"url": "https://www.ieee.org/about/news/2025/ieee-reveals-predictions-for-top-technology-trends-of-2025", "title": "IEEE Reveals Predictions for Top Technology Trends of 2025", "content": "1. Leveling of the AI playing field with new forms of Large Language Model (LLM) deployment: As AI continues to grow in accessibility, companies will seek out ways to efficiently leverage LLMs. For instance, open-source communities create ways for developers to efficiently tap into successful models, and cloud services are providing LLM solutions with integrated prompt engineering. Hardware evolution will continue to specifically accommodate for optimal run of LLMs, and model compression will continue. As a result, 2025 will see deployments of Small Language Models and exotic, special-purpose models, transforming industries through more domain-specific and efficient AI applications. [...] 3. Commercial success of AI agents: Building on the success of LLM accessibility, AI agents will combine LLMs, machine learning (ML) models, and rule-based systems to provide autonomous, highly specialized solutions for finance, manufacturing, and retail operations. The coinciding advancement of small language models will lower hardware requirements and enable easier fine-tuning of AI agent solutions, and open-source AI libraries and models will allow for model and data ownership. In addition, cloud solutions with friendly user interfaces and low code approaches will increase the accessibility of these solutions in 2025. Businesses will deploy AI agents for a variety of customer service and simplified operational tasks. [...] 4. More widespread evaluation of AI-enhanced robotics: In 2025, embodied intelligence will enable robots to perceive, learn, and collaborate in dynamic environments, achieving unprecedented autonomy and human-like adaptability. We can expect advancements in research settings, including work on LLMs, multimodal AI, and computer vision; advanced edge computing and 5G/6G networks; next-generation battery technology, wireless charging, and energy storage; integrated sensors with advanced fusion capabilities and real-time analytics to enable enhanced perception and seamless interaction; and robust data integration from the Internet of Things (IoT) for real-time adaptability. At the same time, engineers will continue exploring standardized protocols for robot-to-robot communication to ensure seamless interaction and collaboration.", "score": 0.90830135, "raw_content": null, "summary": "The coinciding advancement of small language models will lower hardware requirements and enable easier fine-tuning of AI agent solutions, and open-source AI libraries and models will allow for model and data ownership. We can expect advancements in research settings, including work on LLMs, multimodal AI, and computer vision; advanced edge computing and 5G/6G networks; next-generation battery tech"}, {"url": "https://www.ieee.org/about/news/2024/news-release-2024-survey-results", "title": "In New IEEE Global Survey, Twice as Many Technologists Expect AI ...", "content": "This is the second consecutive year that AI tops the list of most important technologies in the year ahead in the annual IEEE Impact of Technology global survey. When asked to select the top three areas of technology that will be most important in 2025 from over a dozen areas, respondents chose:\n\n●  (58%) AI (including predictive and generative AI, machine learning, natural language processing)\n\n●  (26%) Cloud computing\n\n●  (24%) Robotics\n\nOther important technologies in 2025 include extended reality (XR), including metaverse, augmented reality, virtual reality, and mixed reality (21%); industrial internet of things (19%); quantum, including quantum computing (17%), and electric vehicles/EV charging (17%). [...] In New IEEE Global Survey, Twice as Many Technologists Expect AI to Be the Most Important Tech in 2025 Compared to Other Areas | IEEE\n\nSkip to Content\n\n# In New IEEE Global Survey, Twice as Many Technologists Expect AI to Be the Most Important Tech in 2025 Compared to Other Areas\n\nAnnual Study of CIOs, CTOs and Technology Leaders Forecasts 2025 Trends\n\nCloud computing, robotics, extended reality (XR), industrial internet of things, quantum computing, and electric vehicles|EV charging among the most important technologies in 2025 [...] However, a strong majority of respondents (91%) agree in 2025 there will be a generative AI reckoning as public fascination and perception shift to a greater understanding of and expectations for, what the technology can and should do -- in terms of accuracy of results, transparency around deepfakes and more.\n\nRegarding the adoption of generative AI and which stage they expect their organization to reach in 2025, most respondents indicated they expect to embrace the technology. That said, nearly one-quarter expect to rethink their organization’s approach due to challenges or will start exploring the technology at their organization. Given these insights, it will be far from mass market integration next year.\n\n●  (33%) High Expectations: We are excited and will continue to try generative AI in small projects\n\n●  (24%) Learning: We will continue to find practical uses for generative AI and are seeing some benefits", "score": 0.84767824, "raw_content": null, "summary": "When asked to select the top three areas of technology that will be most important in 2025 from over a dozen areas, respondents chose: ● (58%) AI (including predictive and generative AI, machine learning, natural language processing) ● (26%) Cloud computing ● (24%) Robotics Other important technologies in 2025 include extended reality (XR), including metaverse, augmented reality, virtual reality,"}, {"url": "https://innovationatwork.ieee.org/top-tech-trends-of-2025-and-what-they-mean-for-2026/", "title": "Top Tech Trends of 2025 and What They Mean for 2026", "content": "_Large Language Models: Evolution, Impact, and Hands‑On Exercises:_ Developed in partnership with the IEEE Computer Society, this course traces the progression of language models from statistical approaches to modern transformer architectures. Learners explore milestones in AI development and examine real‑world applications. They also gain practical experience through a hands‑on gradient descent exercise on model optimization. By combining historical context with applied practice, the course equips participants to understand both the opportunities and challenges of deploying LLMs in engineering and technology.\n\nLooking Ahead to 2026\n\nThe trends of 2025 laid the foundation for what comes next. In 2026, expect deeper AI integration in manufacturing, wider adoption of battery storage, and continued advances in power systems and language models. By investing in your skills today, you position yourself to lead tomorrow’s innovations.\n\nTuesday, 23rd December 2025\n\n##### Related Tags [...] A Year of Rapid Change\n\nAs 2025 comes to a close, the pace of innovation has accelerated across every major industry. AI reshaped semiconductor manufacturing. Battery storage technologies advanced faster than expected. Power systems grew more intelligent and resilient. And large language models continued to redefine how engineers design, test, and communicate.\n\nThese shifts aren’t isolated events. Instead, they point directly to what professionals will need to understand in 2026. By tracking these trends now, you can apply the latest engineering practices with confidence. This way, you can stay competitive in a fast‑moving landscape.\n\nBelow, you’ll find the most influential tech trends of 2025 — each paired with a new IEEE Learning Network course developed by IEEE Educational Activities and partners across IEEE. These are designed to help you build the skills that matter most for the year ahead.\n\nAI Applications in Semiconductor Packaging [...] Mastering AI Integration in Semiconductor Manufacturing\n\nBeyond packaging, AI is reshaping semiconductor production from end to end. In 2025, factories expanded their use of AI-driven systems that combine IoT sensors, edge computing, and predictive analytics. These tools now monitor processes in real time and help engineers optimize production faster than ever.\n\nWhy it matters: AI scales manufacturing intelligence. When every stage of production becomes smarter, manufacturers reduce defects, improve yield, and accelerate innovation. This shift is essential for staying competitive in a global market.", "score": 0.84183896, "raw_content": null, "summary": "_Large Language Models: Evolution, Impact, and Hands‑On Exercises:_ Developed in partnership with the IEEE Computer Society, this course traces the progression of language models from statistical approaches to modern transformer architectures. In 2026, expect deeper AI integration in manufacturing, wider adoption of battery storage, and continued advances in power systems and language models."}, {"url": "https://spectrum.ieee.org/ai-index-2025", "title": "The State of AI 2025: 12 Eye-Opening Graphs - IEEE Spectrum", "content": "IEEE Spectrum\n\nIf you read the news about AI, you may feel bombarded with conflicting messages: AI is booming. AI is a bubble. AI’s current techniques and architectures will keep producing breakthroughs. AI is on an unsustainable path and needs radical new ideas. AI is going to take your job. AI is mostly good for turning your family photos into Studio Ghibli–style animated images.\n\nCutting through the confusion is the 2025 AI Index from Stanford University’s Institute for Human-Centered Artificial Intelligence. The 400+ page report is stuffed with graphs and data on the topics of R&D, technical performance, responsible AI, economic impacts, science and medicine, policy, education, and public opinion. As IEEE Spectrum does every year (see our coverage from 2021, 2022, 2023, and 2024), we’ve read the whole thing and plucked out the graphs that we think tell the real story of AI right now. [...] Joseph Park08 Apr, 2025\n\nSM\n\nThank you for the topical and informative article. Please consider to repost with legible graphic text in graphs 2-9,11,12. Thank you.\n\n0 Replies;)  Hide replies;) \n\nShow More Replies\n\nBob Whitcombe11 Apr, 2025\n\nM\n\nI find a conclusion that the US is in the lead on models given China has a low cost, public domain model that cost little to run and performs on par with ChatGPT 4. What's worse, are humans thinking they are so valuable that AI is not a threat. AI starting to rewrite the workplace rules and their value. Thank goodness I had the foresight to be born 70 years ago so I can now retire.\n\n1 Reply;)  Hide replies;) \n\nShow More Replies\n\nWilliam Adams10 Apr, 2025\n\nLS\n\nAI is genuine stupidity\n\nand\n\nModern tulipmania [...] ## 10. Dr. AI Will See You Soon, Maybe\n\nAI for science and medicine is a mini-boom within the AI boom. The report lists a variety of new foundation models that have been released to help researchers in fields such as materials science, weather forecasting, and quantum computing. Many companies are trying to turn AI’s predictive and generative powers into profitable drug discovery. And OpenAI’s o1 reasoning model recently scored 96 percent on a benchmark called MedQA, which has questions from medical board exams.", "score": 0.81489426, "raw_content": null, "summary": "The 400+ page report is stuffed with graphs and data on the topics of R&D, technical performance, responsible AI, economic impacts, science and medicine, policy, education, and public opinion. 0 Replies;) Hide replies;) Show More Replies Bob Whitcombe11 Apr, 2025 M I find a conclusion that the US is in the lead on models given China has a low cost, public domain model that cost little to run and p"}, {"url": "https://spectrum.ieee.org/topic/artificial-intelligence/", "title": "AI News & Articles - Artificial Intelligence Updates - IEEE Spectrum", "content": "01 Jan 2026\n\n5 min read\n\nAINews\n\n## IEEE Spectrum's Top 6 AI Stories of 2025\n\nAI coding, AGI, and more made up Spectrum’s best stories\n\n31 Dec 2025\n\n3 min read\n\nEnergySemiconductorsConsumer ElectronicsWhitepaper\n\n## Hermetic Sealing Solutions for High-Performance Miniaturized Battery Systems\n\nProcessing considerations for achieving optimal seal integrity\n\n24 Dec 2025\n\n## Get AI Alert in your inbox\n\nSign up for our FREE biweekly newsletter featuring the news you need about machine learning algorithms and applications\n\nSubscribe\n\nPlease enter a valid email address, and accept the Privacy Policy.\n\nThank you for your subscription!\n\nComputingAINews\n\n## This AI Can Beat You at Rock-Paper-Scissors\n\nA reservoir-computing chip offers fast and low-power predictions\n\n16 Dec 2025\n\n4 min read\n\nThe InstituteAICareersArticle [...] 3 min read\n\nRoboticsNewsJournal Watch\n\n## New Mapping Model Enhances Robot Terrain Navigation\n\n24 Sep 2025\n\n2 min read\n\nAIInterview\n\n## Are We Testing AI Intelligence the Wrong Way?\n\nMelanie Mitchell says today’s benchmarks aren’t cutting it\n\n04 Dec 2025\n\n5 min read\n\nComputingAerospaceAISemiconductorsNews\n\n## Room-Size Particle Accelerators Go Commercial\n\nNew devices to be used in radiation testing for space electronics\n\n04 Dec 2025\n\n4 min read\n\nAINews\n\n## AI Models’ Reasoning Flaws Impact Critical Fields\n\nAs AI takes on agent roles, flawed reasoning raises risks\n\n02 Dec 2025\n\n5 min read\n\n## The Scale Issue\n\nHumanity’s greatest challenges require us to radically scale up our ingenuity\n\n See the full report →\n\nEnergyAerospaceMagazineFeatureSpecial ReportsOctober 2025Climate TechThe Scale Issue", "score": 0.798643, "raw_content": null, "summary": "01 Jan 2026 5 min read AINews ## IEEE Spectrum's Top 6 AI Stories of 2025 AI coding, AGI, and more made up Spectrum’s best stories 31 Dec 2025 3 min read EnergySemiconductorsConsumer ElectronicsWhitepaper ## Hermetic Sealing Solutions for High-Performance Miniaturized Battery Systems Processing considerations for achieving optimal seal integrity 24 Dec 2025 ## Get AI Alert in your inbox Sign up fo"}]}
{"query": "site:ieee.org AI systems 2026 (English)", "result": {"query": "AI systems 2026 (English)", "follow_up_questions": null, "answer": null, "images": [], "results": [{"url": "https://spectrum.ieee.org/new-technology-2026", "title": "New Technology in 2026: Brain Chips and Space Missions", "content": "### An AI Supercomputer the Size of a City\n\nMeta is spending its way to AI excellence, experts say. The company plans to take its first “AI supercluster” online in 2026, consuming as much as 1 gigawatt of power. Prometheus, as it’s called, is on a site near Columbus, Ohio, with a footprint that approaches the size of Manhattan. But it’s just part of a wider project that will cost Meta hundreds of billions of dollars, according to CEO Mark Zuckerberg. In addition to Prometheus, Meta is developing an even larger data center, Hyperion, that will be able to scale up to 5 gigawatts and is expected to be operational in 2028.\n\n### Mining the Moon and Mars [...] ### Sending Humans Back to the Moon\n\nIn another giant leap for mankind, the first crewed mission to the moon since 1972 is scheduled to launch in April 2026. The 10-day flight will usher in NASA’s efforts to have a sustained human presence on the moon by testing hardware and systems for future lunar exploration. This will be the first time a crew assesses the SLS rocket and Orion spacecraft for human use. While the astronauts won’t actually land on the moon, they will get as close as 7,400 kilometers from its surface and spend time investigating how near-lunar space travel affects their health.\n\n### An AI Supercomputer the Size of a City [...] ### Social Media Ads Fully Created by AI\n\nSoon, an algorithm will determine not only what ads you see on social media, but also what’s in them. Meta plans to fully automate ad creation and delivery on its platforms by the end of 2026, putting every step of the process in the “hands” of AI. Though there are already some AI tools integrated into the company’s ad platform, Meta wants to do more. It’s developing a way for any brand to present only a product and budget to an AI tool, which will then create an entire ad (including text, images, and video), determine the users to target, and offer business suggestions.\n\n### “Robo-Umps” Make It to the Big Leagues", "score": 0.644248, "raw_content": null, "summary": "### Mining the Moon and Mars [...] ### Sending Humans Back to the Moon In another giant leap for mankind, the first crewed mission to the moon since 1972 is scheduled to launch in April 2026. Meta plans to fully automate ad creation and delivery on its platforms by the end of 2026, putting every step of the process in the “hands” of AI."}, {"url": "https://innovationatwork.ieee.org/top-tech-trends-of-2025-and-what-they-mean-for-2026/", "title": "Top Tech Trends of 2025 and What They Mean for 2026", "content": "A Year of Rapid Change\n\nAs 2025 comes to a close, the pace of innovation has accelerated across every major industry. AI reshaped semiconductor manufacturing. Battery storage technologies advanced faster than expected. Power systems grew more intelligent and resilient. And large language models continued to redefine how engineers design, test, and communicate.\n\nThese shifts aren’t isolated events. Instead, they point directly to what professionals will need to understand in 2026. By tracking these trends now, you can apply the latest engineering practices with confidence. This way, you can stay competitive in a fast‑moving landscape.\n\nBelow, you’ll find the most influential tech trends of 2025 — each paired with a new IEEE Learning Network course developed by IEEE Educational Activities and partners across IEEE. These are designed to help you build the skills that matter most for the year ahead.\n\nAI Applications in Semiconductor Packaging [...] _Large Language Models: Evolution, Impact, and Hands‑On Exercises:_ Developed in partnership with the IEEE Computer Society, this course traces the progression of language models from statistical approaches to modern transformer architectures. Learners explore milestones in AI development and examine real‑world applications. They also gain practical experience through a hands‑on gradient descent exercise on model optimization. By combining historical context with applied practice, the course equips participants to understand both the opportunities and challenges of deploying LLMs in engineering and technology.\n\nLooking Ahead to 2026\n\nThe trends of 2025 laid the foundation for what comes next. In 2026, expect deeper AI integration in manufacturing, wider adoption of battery storage, and continued advances in power systems and language models. By investing in your skills today, you position yourself to lead tomorrow’s innovations.\n\nTuesday, 23rd December 2025\n\n##### Related Tags [...] _Mastering AI Integration in Semiconductor Manufacturing:_ Developed in partnership with the IEEE Computer Society, this program provides a comprehensive roadmap for engineers and professionals. It covers AI fundamentals, data handling, and advanced techniques for integrating AI into semiconductor manufacturing. Learners explore case studies on process optimization, production efficiency, and quality assurance. They gain practical insights into how IoT sensors and edge computing can transform manufacturing environments. By the end, participants will be equipped with the skills to design and implement AI‑driven solutions. This enhances productivity and reliability in semiconductor production.\n\nAI for Power and Energy Systems: Applications, Challenges, and Opportunities\n\nPower systems grew more complex in 2025 as renewable energy, distributed generation, and smart grid technologies expanded worldwide. AI, especially convolutional neural networks (CNNs), helped solve challenges such as power flow analysis, fault detection, and grid stability.\n\nWhy it matters: AI strengthens grid resilience. Smarter power systems support sustainability goals while protecting communities from disruptions.", "score": 0.6152965, "raw_content": null, "summary": "AI Applications in Semiconductor Packaging [...] _Large Language Models: Evolution, Impact, and Hands‑On Exercises:_ Developed in partnership with the IEEE Computer Society, this course traces the progression of language models from statistical approaches to modern transformer architectures. AI for Power and Energy Systems: Applications, Challenges, and Opportunities Power systems grew more comple"}, {"url": "https://spectrum.ieee.org/topic/artificial-intelligence/", "title": "AI News & Articles - Artificial Intelligence Updates - IEEE Spectrum", "content": "CREATE AN ACCOUNTSIGN IN\n\nJOIN IEEESIGN IN\n\nClose\n\n## Access Thousands of Articles — Completely Free\n\n## Create an account and get exclusive content and features: Save articles, download collections, and post comments — all free! For full access and benefits, subscribe to Spectrum.\n\nCREATE AN ACCOUNTSIGN IN\n\n# AI\n\nThe latest advances in artificial intelligence and machine learning, generative AI, ChatGPT, LLMs, deepfakes, and more\n\nFollow\n\nAIMagazineEnergyArticleJanuary 2026\n\n## U.S. Leads in Global Data Center Growth\n\nBut China’s growth remains a mystery\n\n05 Jan 2026\n\n1 min read\n\nAIAerospaceMagazineFeatureTop Tech 2026Special ReportsConsumer ElectronicsJanuary 2026\n\n## Brain Chips and Foldable iPhones: New Tech in 2026\n\nRobo-umps, a supercomputer the size of a city, and more\n\n01 Jan 2026 [...] 22 Sep 2025\n\n12 min read\n\nAIAerospaceMagazineFeatureTop Tech 2026Special ReportsConsumer ElectronicsJanuary 2026\n\n## Brain Chips and Foldable iPhones: New Tech in 2026\n\nRobo-umps, a supercomputer the size of a city, and more\n\n01 Jan 2026\n\n5 min read\n\nAIGuest Article\n\n## The Next Frontier in AI Isn’t Just More Data\n\nReinforcement learning environments prepare AI for messy reality\n\n01 Dec 2025\n\n3 min read\n\nAINews\n\n## TraffickCam App Aids Human Trafficking Victims\n\nHotels offer particular challenges for AI image recognition\n\n26 Nov 2025\n\n7 min read\n\nAerospaceSemiconductorsWhitepaper\n\n## How to Accelerate Radar Cross Section Simulations for Large Structures\n\nAchieve accurate RCS predictions for electrically large aerospace structures in minutes instead of hours\n\n19 Dec 2025\n\nAIWhitepaper [...] 01 Jan 2026\n\n5 min read\n\nAINews\n\n## IEEE Spectrum's Top 6 AI Stories of 2025\n\nAI coding, AGI, and more made up Spectrum’s best stories\n\n31 Dec 2025\n\n3 min read\n\nEnergySemiconductorsConsumer ElectronicsWhitepaper\n\n## Hermetic Sealing Solutions for High-Performance Miniaturized Battery Systems\n\nProcessing considerations for achieving optimal seal integrity\n\n24 Dec 2025\n\n## Get AI Alert in your inbox\n\nSign up for our FREE biweekly newsletter featuring the news you need about machine learning algorithms and applications\n\nSubscribe\n\nPlease enter a valid email address, and accept the Privacy Policy.\n\nThank you for your subscription!\n\nComputingAINews\n\n## This AI Can Beat You at Rock-Paper-Scissors\n\nA reservoir-computing chip offers fast and low-power predictions\n\n16 Dec 2025\n\n4 min read\n\nThe InstituteAICareersArticle", "score": 0.57952, "raw_content": null, "summary": "CREATE AN ACCOUNTSIGN IN JOIN IEEESIGN IN Close ## Access Thousands of Articles — Completely Free ## Create an account and get exclusive content and features: Save articles, download collections, and post comments — all free! Leads in Global Data Center Growth But China’s growth remains a mystery 05 Jan 2026 1 min read AIAerospaceMagazineFeatureTop Tech 2026Special ReportsConsumer ElectronicsJanua"}, {"url": "https://spectrum.ieee.org/ai-index-2024/6-the-united-states-leads-in-foundation-models", "title": "6. The United States leads in foundation models - IEEE Spectrum", "content": "## Engineer Crafts Digital Accordions with Tech Skills\n\n5 min read\n\nEnergyMagazineComputingRoboticsOpinionJanuary 2026\n\n## Tech to Track in 2026\n\n01 Jan 2026\n\n3 min read\n\n## Related Stories\n\nRoboticsGuest Article\n\n## DeepMind's Robots Play Infinite Table Tennis\n\nAINews\n\n## Why the Nobel Prize in Physics Went to AI Research\n\nBiomedicalAINews\n\n## Deep Learning Picks Apart DNA Data-Copying Puzzles [...] ### 12. AI can’t beat humans at everything... yet\n\nIn recent years, AI systems have outperformed humans on a range of tasks, including reading comprehension and visual reasoning, and Maslej notes that the pace of AI performance improvement has also picked up. “A decade ago, with a benchmark like ImageNet, you could rely on that to challenge AI researchers for for five or six years,” he says. “Now, a new benchmark is introduced for competition-level mathematics and the AI starts at 30 percent, and then in a year it gets to 90 percent.” While there are still complex cognitive tasks where humans outperform AI systems, let’s check in next year to see how that’s going.\n\n### 13. Developing norms of AI responsibility", "score": 0.44941738, "raw_content": null, "summary": "## Engineer Crafts Digital Accordions with Tech Skills 5 min read EnergyMagazineComputingRoboticsOpinionJanuary 2026 ## Tech to Track in 2026 01 Jan 2026 3 min read ## Related Stories RoboticsGuest Article ## DeepMind's Robots Play Infinite Table Tennis AINews ## Why the Nobel Prize in Physics Went to AI Research BiomedicalAINews ## Deep Learning Picks Apart DNA Data-Copying Puzzles [...] ### 12."}, {"url": "https://events.vtools.ieee.org/m/515448", "title": "IEEE ISSATK'2026 - vTools Events", "content": "## Hammamet, Tunisia\n\nIEEE ISSATK (International Symposium of Systems, Advanced Technologies and Knowledge) is a multidisciplinary conference that serve as a platform for knowledge sharing about the recent trends and advancements in computer science, electrical engineering, and mechanical Engineering. ISSATK brings researchers and students to participate with original papers not submitted to another journal or conference.\n\n### Tracks\n\nTRACK 1: INFORMATION TECHNOLOGIES & AI\n\n Machine Learning and Artificial Intelligence\n Data Science and Big Data Analytics\n Software Engineering and Development\n Cybersecurity and Network Systems\n\nTRACK2:CONTROL, AUTOMATION & EMBEDDING SYSTEMS\n\n Control Theory and Applications\n Robotics and Autonomous Systems\n Embedded Systems Design\n Industrial Automation and Process Control\n\nTRACK3:MANUFACTURING ENGINEERING\n\n Advanced Manufacturing Technologies\n Materials Science and Engineering\n Product Design and Development\n Quality Control and Lean Manufacturing\n\nTRACK 4: RENEWABLE ENERGY AND APPLICATIONS [...] IEEE.org  | IEEE Xplore Digital Library | IEEE Standards | IEEE Spectrum | More Sites\n\n Sign In\n\nIt appears that your session has timed out. Please click here to sign in again.  \nNOTE that if there is any unsaved work on this page, it will be lost.\n\n## IEEE ISSATK'2026\n\n#IEEE\\_TUNISIA\\_CIS #Artificial\\_Intelligence #artificial-intelligence #learning #deep-learning #lead #collaboration #big-data #education #intelligent-systems #information-technology #data-mining #data-processing #application #computer-science #informatics\n\n---\n\n# IEEE ISSATK'2026\n\n## International Symposium of Systems, Advanced Technologies and Knowledge\n\n## April 25-27, 2026\n\n## Hammamet, Tunisia [...] TRACK 4: RENEWABLE ENERGY AND APPLICATIONS\n\n Solar Energy and Photovoltaics\n Wind Energy and Turbine Technology\n Bioenergy and Biomass Conversion\n Energy Storage and Grid Integration\n\nTRACK 5: Artificial Intelligence for Nanotechnology (AI4Nano)\n\n AI and machine learning models for nanoscale material discovery\n Predictive modeling of nanostructures and nanocomposites\n Deep learning for nanoscale imaging and microscopy analysis\n Computational nanotechnology and quantum-inspired AI models\n Data-driven design of nanomaterials and nanodevices\n AI-assisted drug delivery and nanosensors in biomedicine\n Robotics and automation for nanoscale fabrication\n Explainable AI and uncertainty quantification in nanoscience\n Hybrid approaches combining AI with first-principles simulations\n Ethical and sustainability aspects of AI in nanotechnology\n\n### Submission", "score": 0.4296453, "raw_content": null, "summary": "### Tracks TRACK 1: INFORMATION TECHNOLOGIES & AI Machine Learning and Artificial Intelligence Data Science and Big Data Analytics Software Engineering and Development Cybersecurity and Network Systems TRACK2:CONTROL, AUTOMATION & EMBEDDING SYSTEMS Control Theory and Applications Robotics and Autonomous Systems Embedded Systems Design Industrial Automation and Process Control TRACK3:MANUFACTURING"}], "response_time": 1.9, "request_id": "a54af921-f05e-4288-8527-3c1b3f68d592"}, "query_summary": "AI for Power and Energy Systems: Applications, Challenges, and Opportunities Power systems grew more comple CREATE AN ACCOUNTSIGN IN JOIN IEEESIGN IN Close ## Access Thousands of Articles — Completely Free ## Create an account and get exclusive content and features: Save articles, download collections, and post comments — all free! Leads in Global Data Center Growth But China’s growth remains a mystery 05 Jan 2026 1 min read AIAerospaceMagazineFeatureTop Tech 2026Special ReportsConsumer ElectronicsJanua ## Engineer Crafts Digital Accordions with Tech Skills 5 min read EnergyMagazineComputingRo", "lang_pref": "en", "preferred_results": [{"url": "https://spectrum.ieee.org/new-technology-2026", "title": "New Technology in 2026: Brain Chips and Space Missions", "content": "### An AI Supercomputer the Size of a City\n\nMeta is spending its way to AI excellence, experts say. The company plans to take its first “AI supercluster” online in 2026, consuming as much as 1 gigawatt of power. Prometheus, as it’s called, is on a site near Columbus, Ohio, with a footprint that approaches the size of Manhattan. But it’s just part of a wider project that will cost Meta hundreds of billions of dollars, according to CEO Mark Zuckerberg. In addition to Prometheus, Meta is developing an even larger data center, Hyperion, that will be able to scale up to 5 gigawatts and is expected to be operational in 2028.\n\n### Mining the Moon and Mars [...] ### Sending Humans Back to the Moon\n\nIn another giant leap for mankind, the first crewed mission to the moon since 1972 is scheduled to launch in April 2026. The 10-day flight will usher in NASA’s efforts to have a sustained human presence on the moon by testing hardware and systems for future lunar exploration. This will be the first time a crew assesses the SLS rocket and Orion spacecraft for human use. While the astronauts won’t actually land on the moon, they will get as close as 7,400 kilometers from its surface and spend time investigating how near-lunar space travel affects their health.\n\n### An AI Supercomputer the Size of a City [...] ### Social Media Ads Fully Created by AI\n\nSoon, an algorithm will determine not only what ads you see on social media, but also what’s in them. Meta plans to fully automate ad creation and delivery on its platforms by the end of 2026, putting every step of the process in the “hands” of AI. Though there are already some AI tools integrated into the company’s ad platform, Meta wants to do more. It’s developing a way for any brand to present only a product and budget to an AI tool, which will then create an entire ad (including text, images, and video), determine the users to target, and offer business suggestions.\n\n### “Robo-Umps” Make It to the Big Leagues", "score": 0.644248, "raw_content": null, "summary": "### Mining the Moon and Mars [...] ### Sending Humans Back to the Moon In another giant leap for mankind, the first crewed mission to the moon since 1972 is scheduled to launch in April 2026. Meta plans to fully automate ad creation and delivery on its platforms by the end of 2026, putting every step of the process in the “hands” of AI."}, {"url": "https://innovationatwork.ieee.org/top-tech-trends-of-2025-and-what-they-mean-for-2026/", "title": "Top Tech Trends of 2025 and What They Mean for 2026", "content": "A Year of Rapid Change\n\nAs 2025 comes to a close, the pace of innovation has accelerated across every major industry. AI reshaped semiconductor manufacturing. Battery storage technologies advanced faster than expected. Power systems grew more intelligent and resilient. And large language models continued to redefine how engineers design, test, and communicate.\n\nThese shifts aren’t isolated events. Instead, they point directly to what professionals will need to understand in 2026. By tracking these trends now, you can apply the latest engineering practices with confidence. This way, you can stay competitive in a fast‑moving landscape.\n\nBelow, you’ll find the most influential tech trends of 2025 — each paired with a new IEEE Learning Network course developed by IEEE Educational Activities and partners across IEEE. These are designed to help you build the skills that matter most for the year ahead.\n\nAI Applications in Semiconductor Packaging [...] _Large Language Models: Evolution, Impact, and Hands‑On Exercises:_ Developed in partnership with the IEEE Computer Society, this course traces the progression of language models from statistical approaches to modern transformer architectures. Learners explore milestones in AI development and examine real‑world applications. They also gain practical experience through a hands‑on gradient descent exercise on model optimization. By combining historical context with applied practice, the course equips participants to understand both the opportunities and challenges of deploying LLMs in engineering and technology.\n\nLooking Ahead to 2026\n\nThe trends of 2025 laid the foundation for what comes next. In 2026, expect deeper AI integration in manufacturing, wider adoption of battery storage, and continued advances in power systems and language models. By investing in your skills today, you position yourself to lead tomorrow’s innovations.\n\nTuesday, 23rd December 2025\n\n##### Related Tags [...] _Mastering AI Integration in Semiconductor Manufacturing:_ Developed in partnership with the IEEE Computer Society, this program provides a comprehensive roadmap for engineers and professionals. It covers AI fundamentals, data handling, and advanced techniques for integrating AI into semiconductor manufacturing. Learners explore case studies on process optimization, production efficiency, and quality assurance. They gain practical insights into how IoT sensors and edge computing can transform manufacturing environments. By the end, participants will be equipped with the skills to design and implement AI‑driven solutions. This enhances productivity and reliability in semiconductor production.\n\nAI for Power and Energy Systems: Applications, Challenges, and Opportunities\n\nPower systems grew more complex in 2025 as renewable energy, distributed generation, and smart grid technologies expanded worldwide. AI, especially convolutional neural networks (CNNs), helped solve challenges such as power flow analysis, fault detection, and grid stability.\n\nWhy it matters: AI strengthens grid resilience. Smarter power systems support sustainability goals while protecting communities from disruptions.", "score": 0.6152965, "raw_content": null, "summary": "AI Applications in Semiconductor Packaging [...] _Large Language Models: Evolution, Impact, and Hands‑On Exercises:_ Developed in partnership with the IEEE Computer Society, this course traces the progression of language models from statistical approaches to modern transformer architectures. AI for Power and Energy Systems: Applications, Challenges, and Opportunities Power systems grew more comple"}, {"url": "https://spectrum.ieee.org/topic/artificial-intelligence/", "title": "AI News & Articles - Artificial Intelligence Updates - IEEE Spectrum", "content": "CREATE AN ACCOUNTSIGN IN\n\nJOIN IEEESIGN IN\n\nClose\n\n## Access Thousands of Articles — Completely Free\n\n## Create an account and get exclusive content and features: Save articles, download collections, and post comments — all free! For full access and benefits, subscribe to Spectrum.\n\nCREATE AN ACCOUNTSIGN IN\n\n# AI\n\nThe latest advances in artificial intelligence and machine learning, generative AI, ChatGPT, LLMs, deepfakes, and more\n\nFollow\n\nAIMagazineEnergyArticleJanuary 2026\n\n## U.S. Leads in Global Data Center Growth\n\nBut China’s growth remains a mystery\n\n05 Jan 2026\n\n1 min read\n\nAIAerospaceMagazineFeatureTop Tech 2026Special ReportsConsumer ElectronicsJanuary 2026\n\n## Brain Chips and Foldable iPhones: New Tech in 2026\n\nRobo-umps, a supercomputer the size of a city, and more\n\n01 Jan 2026 [...] 22 Sep 2025\n\n12 min read\n\nAIAerospaceMagazineFeatureTop Tech 2026Special ReportsConsumer ElectronicsJanuary 2026\n\n## Brain Chips and Foldable iPhones: New Tech in 2026\n\nRobo-umps, a supercomputer the size of a city, and more\n\n01 Jan 2026\n\n5 min read\n\nAIGuest Article\n\n## The Next Frontier in AI Isn’t Just More Data\n\nReinforcement learning environments prepare AI for messy reality\n\n01 Dec 2025\n\n3 min read\n\nAINews\n\n## TraffickCam App Aids Human Trafficking Victims\n\nHotels offer particular challenges for AI image recognition\n\n26 Nov 2025\n\n7 min read\n\nAerospaceSemiconductorsWhitepaper\n\n## How to Accelerate Radar Cross Section Simulations for Large Structures\n\nAchieve accurate RCS predictions for electrically large aerospace structures in minutes instead of hours\n\n19 Dec 2025\n\nAIWhitepaper [...] 01 Jan 2026\n\n5 min read\n\nAINews\n\n## IEEE Spectrum's Top 6 AI Stories of 2025\n\nAI coding, AGI, and more made up Spectrum’s best stories\n\n31 Dec 2025\n\n3 min read\n\nEnergySemiconductorsConsumer ElectronicsWhitepaper\n\n## Hermetic Sealing Solutions for High-Performance Miniaturized Battery Systems\n\nProcessing considerations for achieving optimal seal integrity\n\n24 Dec 2025\n\n## Get AI Alert in your inbox\n\nSign up for our FREE biweekly newsletter featuring the news you need about machine learning algorithms and applications\n\nSubscribe\n\nPlease enter a valid email address, and accept the Privacy Policy.\n\nThank you for your subscription!\n\nComputingAINews\n\n## This AI Can Beat You at Rock-Paper-Scissors\n\nA reservoir-computing chip offers fast and low-power predictions\n\n16 Dec 2025\n\n4 min read\n\nThe InstituteAICareersArticle", "score": 0.57952, "raw_content": null, "summary": "CREATE AN ACCOUNTSIGN IN JOIN IEEESIGN IN Close ## Access Thousands of Articles — Completely Free ## Create an account and get exclusive content and features: Save articles, download collections, and post comments — all free! Leads in Global Data Center Growth But China’s growth remains a mystery 05 Jan 2026 1 min read AIAerospaceMagazineFeatureTop Tech 2026Special ReportsConsumer ElectronicsJanua"}, {"url": "https://spectrum.ieee.org/ai-index-2024/6-the-united-states-leads-in-foundation-models", "title": "6. The United States leads in foundation models - IEEE Spectrum", "content": "## Engineer Crafts Digital Accordions with Tech Skills\n\n5 min read\n\nEnergyMagazineComputingRoboticsOpinionJanuary 2026\n\n## Tech to Track in 2026\n\n01 Jan 2026\n\n3 min read\n\n## Related Stories\n\nRoboticsGuest Article\n\n## DeepMind's Robots Play Infinite Table Tennis\n\nAINews\n\n## Why the Nobel Prize in Physics Went to AI Research\n\nBiomedicalAINews\n\n## Deep Learning Picks Apart DNA Data-Copying Puzzles [...] ### 12. AI can’t beat humans at everything... yet\n\nIn recent years, AI systems have outperformed humans on a range of tasks, including reading comprehension and visual reasoning, and Maslej notes that the pace of AI performance improvement has also picked up. “A decade ago, with a benchmark like ImageNet, you could rely on that to challenge AI researchers for for five or six years,” he says. “Now, a new benchmark is introduced for competition-level mathematics and the AI starts at 30 percent, and then in a year it gets to 90 percent.” While there are still complex cognitive tasks where humans outperform AI systems, let’s check in next year to see how that’s going.\n\n### 13. Developing norms of AI responsibility", "score": 0.44941738, "raw_content": null, "summary": "## Engineer Crafts Digital Accordions with Tech Skills 5 min read EnergyMagazineComputingRoboticsOpinionJanuary 2026 ## Tech to Track in 2026 01 Jan 2026 3 min read ## Related Stories RoboticsGuest Article ## DeepMind's Robots Play Infinite Table Tennis AINews ## Why the Nobel Prize in Physics Went to AI Research BiomedicalAINews ## Deep Learning Picks Apart DNA Data-Copying Puzzles [...] ### 12."}, {"url": "https://events.vtools.ieee.org/m/515448", "title": "IEEE ISSATK'2026 - vTools Events", "content": "## Hammamet, Tunisia\n\nIEEE ISSATK (International Symposium of Systems, Advanced Technologies and Knowledge) is a multidisciplinary conference that serve as a platform for knowledge sharing about the recent trends and advancements in computer science, electrical engineering, and mechanical Engineering. ISSATK brings researchers and students to participate with original papers not submitted to another journal or conference.\n\n### Tracks\n\nTRACK 1: INFORMATION TECHNOLOGIES & AI\n\n Machine Learning and Artificial Intelligence\n Data Science and Big Data Analytics\n Software Engineering and Development\n Cybersecurity and Network Systems\n\nTRACK2:CONTROL, AUTOMATION & EMBEDDING SYSTEMS\n\n Control Theory and Applications\n Robotics and Autonomous Systems\n Embedded Systems Design\n Industrial Automation and Process Control\n\nTRACK3:MANUFACTURING ENGINEERING\n\n Advanced Manufacturing Technologies\n Materials Science and Engineering\n Product Design and Development\n Quality Control and Lean Manufacturing\n\nTRACK 4: RENEWABLE ENERGY AND APPLICATIONS [...] IEEE.org  | IEEE Xplore Digital Library | IEEE Standards | IEEE Spectrum | More Sites\n\n Sign In\n\nIt appears that your session has timed out. Please click here to sign in again.  \nNOTE that if there is any unsaved work on this page, it will be lost.\n\n## IEEE ISSATK'2026\n\n#IEEE\\_TUNISIA\\_CIS #Artificial\\_Intelligence #artificial-intelligence #learning #deep-learning #lead #collaboration #big-data #education #intelligent-systems #information-technology #data-mining #data-processing #application #computer-science #informatics\n\n---\n\n# IEEE ISSATK'2026\n\n## International Symposium of Systems, Advanced Technologies and Knowledge\n\n## April 25-27, 2026\n\n## Hammamet, Tunisia [...] TRACK 4: RENEWABLE ENERGY AND APPLICATIONS\n\n Solar Energy and Photovoltaics\n Wind Energy and Turbine Technology\n Bioenergy and Biomass Conversion\n Energy Storage and Grid Integration\n\nTRACK 5: Artificial Intelligence for Nanotechnology (AI4Nano)\n\n AI and machine learning models for nanoscale material discovery\n Predictive modeling of nanostructures and nanocomposites\n Deep learning for nanoscale imaging and microscopy analysis\n Computational nanotechnology and quantum-inspired AI models\n Data-driven design of nanomaterials and nanodevices\n AI-assisted drug delivery and nanosensors in biomedicine\n Robotics and automation for nanoscale fabrication\n Explainable AI and uncertainty quantification in nanoscience\n Hybrid approaches combining AI with first-principles simulations\n Ethical and sustainability aspects of AI in nanotechnology\n\n### Submission", "score": 0.4296453, "raw_content": null, "summary": "### Tracks TRACK 1: INFORMATION TECHNOLOGIES & AI Machine Learning and Artificial Intelligence Data Science and Big Data Analytics Software Engineering and Development Cybersecurity and Network Systems TRACK2:CONTROL, AUTOMATION & EMBEDDING SYSTEMS Control Theory and Applications Robotics and Autonomous Systems Embedded Systems Design Industrial Automation and Process Control TRACK3:MANUFACTURING"}]}
{"query": "site:venturebeat.com AI trends 2025 (English)", "result": {"query": "AI trends 2025 (English)", "follow_up_questions": null, "answer": null, "images": [], "results": [{"url": "https://venturebeat.com/ai/we-asked-openais-o1-about-the-top-ai-trends-in-2025-heres-a-look-into-our-conversation", "title": "We asked OpenAI's o1 about the top AI trends in 2025 - VentureBeat", "content": "Summary of the top 25 AI trends for 2025, ranked by how profoundly each trend might reshape society at its fullest realization.\n\n## Navigating AI's transformative impact\n\nWhile some AI breakthroughs are here now or seem just around the corner, others like AGI and ASI remain speculative, reminding us that there is much more to come from AI technologies. Yet it is already clear that AI, in all its manifestations, is reshaping human affairs in ways likely to become even more profound over time. These changes will extend to daily life and could even challenge our understanding of what it means to be human.\n\nAs AI continues to redefine industries and society, we are only at the beginning of a dramatic technological renaissance. These trends, ranging from generative models to humanoid robots powered by AI, highlight both the promise and complexity of integrating AI into our lives. [...] For example, these lifelike avatars are developed using the capabilities of generative AI (trend 1) for natural conversation, explainable AI (2) to build trust through transparency and agentic AI (3) for autonomous decision-making. With synthetic data generation, digital humans are trained on diverse, privacy-preserving datasets, ensuring they adapt to cultural and contextual nuances. Meanwhile, edge AI (5) enables near real-time responsiveness and multi-modal AI (17) enhances interactions by integrating text, audio and visual elements.\n\nBy using the technologies described by these trends, digital humans exemplify how advancements in one domain can accelerate progress in others, transforming industries and redefining human-AI collaboration. As digital humans continue to evolve, they not only exemplify the flywheel of innovation, but also underscore the transformative potential of AI to redefine how humans interact with technology.\n\n## Why are AGI and ASI so far down the list? [...] All Posts\n\n# We asked OpenAI's o1 about the top AI trends in 2025 — here's a look into our conversation\n\nGary Grossman, Edelman\n\nAI is already reshaping industries and society on a global scale. IDC predicts that AI will contribute $19.9 trillion to the global economy by 2030, comprising 3.5% of GDP. This momentum is exemplified by the recent announcement of “Project Stargate,” a partnership to invest up to $100 billion in new AI-focused data center capacity. This is all indicative of the tremendous activity going on with AI development. On a single day, AI made headlines for discovering proteins to counteract cobra venom, creating a Star Trek-style universal translator and paving the way for true AI assistants.\n\nThese and other developments highlight individual achievements, as well as their interconnected progress. This flywheel of innovation is where breakthroughs in one domain amplify advancements in others, compounding AI’s transformative potential.", "score": 0.8976328, "raw_content": null, "summary": "## Navigating AI's transformative impact While some AI breakthroughs are here now or seem just around the corner, others like AGI and ASI remain speculative, reminding us that there is much more to come from AI technologies. [...] For example, these lifelike avatars are developed using the capabilities of generative AI (trend 1) for natural conversation, explainable AI (2) to build trust through t"}, {"url": "https://venturebeat.com/ai/gradually-then-suddenly-is-ai-job-displacement-following-this-pattern", "title": "'Gradually then suddenly': Is AI job displacement following ...", "content": "## Canary in the coal mine\n\nOne of the first job categories likely to be hit by AI is software development. Numerous AI tools based on large language models (LLMs) exist to augment programming, and soon the function could be entirely automated. Anthropic CEO Dario Amodei said recently on Reddit that “we're 3 to 6 months from a world where AI is writing 90% of the code. And then in 12 months, we may be in a world where AI is writing essentially all of the code.”\n\nSource: Reddit\n\nThis trend is becoming clear, as evidenced by startups in the winter 2025 cohort of incubator Y Combinator. Managing partner Jared Friedman said that 25% of this startup batch have 95% of their codebases generated by AI. He added: “A year ago, [the companies] would have built their product from scratch — but now 95% of it is built by an AI.”", "score": 0.8559598, "raw_content": null, "summary": "## Canary in the coal mine One of the first job categories likely to be hit by AI is software development. And then in 12 months, we may be in a world where AI is writing essentially all of the code.” Source: Reddit This trend is becoming clear, as evidenced by startups in the winter 2025 cohort of incubator Y Combinator."}, {"url": "https://venturebeat.com/security/gartner-2025-will-see-the-rise-of-ai-agents-and-other-top-trends", "title": "Gartner: 2025 will see the rise of AI agents (and other top trends)", "content": "All Posts\n\n# Gartner: 2025 will see the rise of AI agents (and other top trends)\n\nTaryn Plumb\n\nThe pace of AI continues to accelerate, with capabilities never before thought possible now becoming a reality. This is particularly true of AI agents, or virtual co-workers, which will work alongside us and, eventually, autonomously.\n\nIn fact, Gartner predicts that by 2028, at least 15% of day-to-day work decisions will be made autonomously through agentic AI (up from 0% in 2024). Further emphasizing the technology’s potential, the firm has named it a top strategic technology trend in 2025. [...] ## AI enhancing our brains\n\nReaching more into the sci-fi arena, Gartner anticipates a rise in the use of bidirectional brain-machine interfaces (BBMIs) that read and decode brain activity and enhance human cognitive abilities. These could be directly integrated into our brains or made possible via wearables such as glasses or headbands, Alvarez explained.\n\nGartner anticipates that, by 2030, 30% of knowledge workers will be using technologies such as BBMIs to stay relevant in the AI-powered workplace (up from less than 1% in 2024). Alvarez said he sees potential in human upskilling and next-generation marketing — for instance, brands will be able to know what consumers are thinking and feeling to gauge sentiment. [...] Incremental improvements won’t be enough; enterprises need long term solutions, he said. New technologies — such as green cloud providers or new, more efficient algorithms — could improve efficiency by thousands or even tens or hundreds of thousands orders of magnitude.\n\n## Proactively addressing disinformation security\n\nAI is allowing threat actors to spread disinformation faster — and more easily — than ever before. They can push out deepfakes and craft convincing phishing emails; exploit vulnerabilities in workforce collaboration tools; use malware to steal credentials; and initiate account takeovers (among other tactics).", "score": 0.8342047, "raw_content": null, "summary": "All Posts # Gartner: 2025 will see the rise of AI agents (and other top trends) Taryn Plumb The pace of AI continues to accelerate, with capabilities never before thought possible now becoming a reality. [...] ## AI enhancing our brains Reaching more into the sci-fi arena, Gartner anticipates a rise in the use of bidirectional brain-machine interfaces (BBMIs) that read and decode brain activity an"}, {"url": "https://venturebeat.com/ai/what-to-be-thankful-for-in-ai-in-2025", "title": "What to be thankful for in AI in 2025 - VentureBeat", "content": "VentureBeat has been tracking these shifts, including Chinese math and reasoning models like Light-R1-32B and Weibo’s tiny VibeThinker-1.5B, which beat DeepSeek baselines on shoestring training budgets.\n\nIf you care about open ecosystems or on-premise options, this is the year China’s open-weight scene stopped being a curiosity and became a serious alternative.\n\n### 3. Small and local models grow up\n\nAnother thing I’m thankful for: We’re finally getting good small models, not just toys.\n\nLiquid AI spent 2025 pushing its Liquid Foundation Models (LFM2) and LFM2-VL vision-language variants, designed from day one for low-latency, device-aware deployments — edge boxes, robots and constrained servers, not just giant clusters. The newer LFM2-VL-3B targets embedded robotics and industrial autonomy, with demos planned at ROSCon. [...] As the company that undeniably birthed the \"generative AI\" era with its viral hit product ChatGPT in late 2022, OpenAI arguably had among the hardest tasks of any AI company in 2025: Continue its growth trajectory even as well-funded competitors like Google with its Gemini models and other startups like Anthropic fielded their own highly competitive offerings.\n\nThankfully, OpenAI rose to the challenge — and then some. Its headline act was GPT-5, unveiled in August as the next frontier reasoning model, followed in November by GPT-5.1 with new \"instant\" and \"thinking\" variants that dynamically adjust how much “thinking time” they spend per task. [...] ### 6. Wild cards I’m keeping an eye on\n\nA few more releases I’m thankful for, even if they don’t fit neatly into one bucket:\n\n Black Forest Labs’ Flux.2 image models, which launched in November with ambitions to challenge both Nano Banana Pro and Midjourney on quality and control. VentureBeat dug into the details in “Black Forest Labs launches Flux.2 AI image models to challenge Nano Banana Pro and Midjourney.\"\n Anthropic’s Claude Opus 4.5, a new flagship that aims for cheaper, more capable coding and long-horizon task execution, which we covered in “Anthropic’s Claude Opus 4.5 is here: Cheaper AI, infinite chats, and coding skills that beat humans.\"\n A steady drumbeat of open math/reasoning models — from Light-R1 to VibeThinker and others — that show you don’t need $100M training runs to move the needle.", "score": 0.8282873, "raw_content": null, "summary": "[...] As the company that undeniably birthed the \"generative AI\" era with its viral hit product ChatGPT in late 2022, OpenAI arguably had among the hardest tasks of any AI company in 2025: Continue its growth trajectory even as well-funded competitors like Google with its Gemini models and other startups like Anthropic fielded their own highly competitive offerings. VentureBeat dug into the detail"}, {"url": "https://venturebeat.com/ai/black-hat-2025-how-agentic-ai-is-finally-delivering-real-value", "title": "Black Hat 2025: Why your AI tools are becoming the next insider threat", "content": "## The agentic AI arms race shifts from promises to production\n\nThe conversation at Black Hat 2025 was dominated by agentic AI, with many of the sessions dedicated to how attackers have or can easily compromise agents. VentureBeat observed over 100 announcements promoting new agentic AI applications, platforms or services. Vendors are producing use cases and results. That's a welcome change from the many promises made in prior years and at previous years. There's an urgency to close hype gaps and deliver results.\n\nCrowdStrike's Adam Meyers, head of counter adversary operations, articulated what's driving this urgency in an interview with VentureBeat: \"Agentic AI really becomes the platform that allows SOC operators to build those automations, whether they're using MCP servers to get access to APIs. We're starting to see more and more organizations leveraging our agentic AI to help them integrate with the Falcon and CrowdStrike systems.\" [...] ## Competition shifts from features to results\n\nDespite fierce competition in the race ot deliver agentic AI solutions for the SOC, Black Hat 2025 ironically showed a more unified approach to cybersecurity than any previous event. Every major vendor emphasized three critical components: reasoning engines that can understand context and make nuanced decisions. These action frameworks enable autonomous response within defined boundaries and learning systems that continuously improve based on outcomes.\n\nGoogle Cloud Security's Chronicle SOAR exemplified this shift, introducing an agentic mode that automatically investigates alerts by querying multiple data sources, correlating findings and presenting analysts with complete investigation packages. Even traditionally conservative vendors have embraced the transformation, with IBM and others introducing autonomous investigation capabilities to their existing installations. The convergence was apparent: the industry has moved beyond competing on AI presence to competing on operational excellence.\n\nThe cybersecurity industry is witnessing adversaries leverage GenAI across three primary attack vectors, forcing defenders to adopt equally sophisticated AI-powered defenses. Source: CrowdStrike 2025 Threat Hunting Report [...] ## Many are predicting that AI will become the next insider threat\n\nLooking forward, Black Hat 2025 also highlighted emerging challenges. Meyers delivered perhaps the most sobering prediction of the conference: \"AI is going to be the next insider threat. Organizations trust those AIs implicitly. They are using it to do all of these tasks, and the more comfortable they become, the less they're going to check the output.\"\n\nThis concern sparked discussions about standardization and governance. The Cloud Security Alliance announced a working group focused on agentic AI security standards, while several vendors committed to collaborative efforts around AI agent interoperability. CrowdStrike's expansion of Falcon Shield to include governance for OpenAI GPT-based agents, combined with Cisco's AI supply chain security initiative with Hugging Face, signals the industry's recognition that securing AI agents themselves is becoming as important as using them for security.", "score": 0.80442166, "raw_content": null, "summary": "## The agentic AI arms race shifts from promises to production The conversation at Black Hat 2025 was dominated by agentic AI, with many of the sessions dedicated to how attackers have or can easily compromise agents. We're starting to see more and more organizations leveraging our agentic AI to help them integrate with the Falcon and CrowdStrike systems.\" [...] ## Competition shifts from features"}], "response_time": 1.94, "request_id": "68e9ddd4-1e24-4605-96a7-764222e412f1"}, "query_summary": "[...] For example, these lifelike avatars are developed using the capabilities of generative AI (trend 1) for natural conversation, explainable AI (2) to build trust through t ## Canary in the coal mine One of the first job categories likely to be hit by AI is software development. [...] ## AI enhancing our brains Reaching more into the sci-fi arena, Gartner anticipates a rise in the use of bidirectional brain-machine interfaces (BBMIs) that read and decode brain activity an [...] As the company that undeniably birthed the \"generative AI\" era with its viral hit product ChatGPT in late 2022, Op", "lang_pref": "en", "preferred_results": [{"url": "https://venturebeat.com/ai/we-asked-openais-o1-about-the-top-ai-trends-in-2025-heres-a-look-into-our-conversation", "title": "We asked OpenAI's o1 about the top AI trends in 2025 - VentureBeat", "content": "Summary of the top 25 AI trends for 2025, ranked by how profoundly each trend might reshape society at its fullest realization.\n\n## Navigating AI's transformative impact\n\nWhile some AI breakthroughs are here now or seem just around the corner, others like AGI and ASI remain speculative, reminding us that there is much more to come from AI technologies. Yet it is already clear that AI, in all its manifestations, is reshaping human affairs in ways likely to become even more profound over time. These changes will extend to daily life and could even challenge our understanding of what it means to be human.\n\nAs AI continues to redefine industries and society, we are only at the beginning of a dramatic technological renaissance. These trends, ranging from generative models to humanoid robots powered by AI, highlight both the promise and complexity of integrating AI into our lives. [...] For example, these lifelike avatars are developed using the capabilities of generative AI (trend 1) for natural conversation, explainable AI (2) to build trust through transparency and agentic AI (3) for autonomous decision-making. With synthetic data generation, digital humans are trained on diverse, privacy-preserving datasets, ensuring they adapt to cultural and contextual nuances. Meanwhile, edge AI (5) enables near real-time responsiveness and multi-modal AI (17) enhances interactions by integrating text, audio and visual elements.\n\nBy using the technologies described by these trends, digital humans exemplify how advancements in one domain can accelerate progress in others, transforming industries and redefining human-AI collaboration. As digital humans continue to evolve, they not only exemplify the flywheel of innovation, but also underscore the transformative potential of AI to redefine how humans interact with technology.\n\n## Why are AGI and ASI so far down the list? [...] All Posts\n\n# We asked OpenAI's o1 about the top AI trends in 2025 — here's a look into our conversation\n\nGary Grossman, Edelman\n\nAI is already reshaping industries and society on a global scale. IDC predicts that AI will contribute $19.9 trillion to the global economy by 2030, comprising 3.5% of GDP. This momentum is exemplified by the recent announcement of “Project Stargate,” a partnership to invest up to $100 billion in new AI-focused data center capacity. This is all indicative of the tremendous activity going on with AI development. On a single day, AI made headlines for discovering proteins to counteract cobra venom, creating a Star Trek-style universal translator and paving the way for true AI assistants.\n\nThese and other developments highlight individual achievements, as well as their interconnected progress. This flywheel of innovation is where breakthroughs in one domain amplify advancements in others, compounding AI’s transformative potential.", "score": 0.8976328, "raw_content": null, "summary": "## Navigating AI's transformative impact While some AI breakthroughs are here now or seem just around the corner, others like AGI and ASI remain speculative, reminding us that there is much more to come from AI technologies. [...] For example, these lifelike avatars are developed using the capabilities of generative AI (trend 1) for natural conversation, explainable AI (2) to build trust through t"}, {"url": "https://venturebeat.com/ai/gradually-then-suddenly-is-ai-job-displacement-following-this-pattern", "title": "'Gradually then suddenly': Is AI job displacement following ...", "content": "## Canary in the coal mine\n\nOne of the first job categories likely to be hit by AI is software development. Numerous AI tools based on large language models (LLMs) exist to augment programming, and soon the function could be entirely automated. Anthropic CEO Dario Amodei said recently on Reddit that “we're 3 to 6 months from a world where AI is writing 90% of the code. And then in 12 months, we may be in a world where AI is writing essentially all of the code.”\n\nSource: Reddit\n\nThis trend is becoming clear, as evidenced by startups in the winter 2025 cohort of incubator Y Combinator. Managing partner Jared Friedman said that 25% of this startup batch have 95% of their codebases generated by AI. He added: “A year ago, [the companies] would have built their product from scratch — but now 95% of it is built by an AI.”", "score": 0.8559598, "raw_content": null, "summary": "## Canary in the coal mine One of the first job categories likely to be hit by AI is software development. And then in 12 months, we may be in a world where AI is writing essentially all of the code.” Source: Reddit This trend is becoming clear, as evidenced by startups in the winter 2025 cohort of incubator Y Combinator."}, {"url": "https://venturebeat.com/security/gartner-2025-will-see-the-rise-of-ai-agents-and-other-top-trends", "title": "Gartner: 2025 will see the rise of AI agents (and other top trends)", "content": "All Posts\n\n# Gartner: 2025 will see the rise of AI agents (and other top trends)\n\nTaryn Plumb\n\nThe pace of AI continues to accelerate, with capabilities never before thought possible now becoming a reality. This is particularly true of AI agents, or virtual co-workers, which will work alongside us and, eventually, autonomously.\n\nIn fact, Gartner predicts that by 2028, at least 15% of day-to-day work decisions will be made autonomously through agentic AI (up from 0% in 2024). Further emphasizing the technology’s potential, the firm has named it a top strategic technology trend in 2025. [...] ## AI enhancing our brains\n\nReaching more into the sci-fi arena, Gartner anticipates a rise in the use of bidirectional brain-machine interfaces (BBMIs) that read and decode brain activity and enhance human cognitive abilities. These could be directly integrated into our brains or made possible via wearables such as glasses or headbands, Alvarez explained.\n\nGartner anticipates that, by 2030, 30% of knowledge workers will be using technologies such as BBMIs to stay relevant in the AI-powered workplace (up from less than 1% in 2024). Alvarez said he sees potential in human upskilling and next-generation marketing — for instance, brands will be able to know what consumers are thinking and feeling to gauge sentiment. [...] Incremental improvements won’t be enough; enterprises need long term solutions, he said. New technologies — such as green cloud providers or new, more efficient algorithms — could improve efficiency by thousands or even tens or hundreds of thousands orders of magnitude.\n\n## Proactively addressing disinformation security\n\nAI is allowing threat actors to spread disinformation faster — and more easily — than ever before. They can push out deepfakes and craft convincing phishing emails; exploit vulnerabilities in workforce collaboration tools; use malware to steal credentials; and initiate account takeovers (among other tactics).", "score": 0.8342047, "raw_content": null, "summary": "All Posts # Gartner: 2025 will see the rise of AI agents (and other top trends) Taryn Plumb The pace of AI continues to accelerate, with capabilities never before thought possible now becoming a reality. [...] ## AI enhancing our brains Reaching more into the sci-fi arena, Gartner anticipates a rise in the use of bidirectional brain-machine interfaces (BBMIs) that read and decode brain activity an"}, {"url": "https://venturebeat.com/ai/what-to-be-thankful-for-in-ai-in-2025", "title": "What to be thankful for in AI in 2025 - VentureBeat", "content": "VentureBeat has been tracking these shifts, including Chinese math and reasoning models like Light-R1-32B and Weibo’s tiny VibeThinker-1.5B, which beat DeepSeek baselines on shoestring training budgets.\n\nIf you care about open ecosystems or on-premise options, this is the year China’s open-weight scene stopped being a curiosity and became a serious alternative.\n\n### 3. Small and local models grow up\n\nAnother thing I’m thankful for: We’re finally getting good small models, not just toys.\n\nLiquid AI spent 2025 pushing its Liquid Foundation Models (LFM2) and LFM2-VL vision-language variants, designed from day one for low-latency, device-aware deployments — edge boxes, robots and constrained servers, not just giant clusters. The newer LFM2-VL-3B targets embedded robotics and industrial autonomy, with demos planned at ROSCon. [...] As the company that undeniably birthed the \"generative AI\" era with its viral hit product ChatGPT in late 2022, OpenAI arguably had among the hardest tasks of any AI company in 2025: Continue its growth trajectory even as well-funded competitors like Google with its Gemini models and other startups like Anthropic fielded their own highly competitive offerings.\n\nThankfully, OpenAI rose to the challenge — and then some. Its headline act was GPT-5, unveiled in August as the next frontier reasoning model, followed in November by GPT-5.1 with new \"instant\" and \"thinking\" variants that dynamically adjust how much “thinking time” they spend per task. [...] ### 6. Wild cards I’m keeping an eye on\n\nA few more releases I’m thankful for, even if they don’t fit neatly into one bucket:\n\n Black Forest Labs’ Flux.2 image models, which launched in November with ambitions to challenge both Nano Banana Pro and Midjourney on quality and control. VentureBeat dug into the details in “Black Forest Labs launches Flux.2 AI image models to challenge Nano Banana Pro and Midjourney.\"\n Anthropic’s Claude Opus 4.5, a new flagship that aims for cheaper, more capable coding and long-horizon task execution, which we covered in “Anthropic’s Claude Opus 4.5 is here: Cheaper AI, infinite chats, and coding skills that beat humans.\"\n A steady drumbeat of open math/reasoning models — from Light-R1 to VibeThinker and others — that show you don’t need $100M training runs to move the needle.", "score": 0.8282873, "raw_content": null, "summary": "[...] As the company that undeniably birthed the \"generative AI\" era with its viral hit product ChatGPT in late 2022, OpenAI arguably had among the hardest tasks of any AI company in 2025: Continue its growth trajectory even as well-funded competitors like Google with its Gemini models and other startups like Anthropic fielded their own highly competitive offerings. VentureBeat dug into the detail"}, {"url": "https://venturebeat.com/ai/black-hat-2025-how-agentic-ai-is-finally-delivering-real-value", "title": "Black Hat 2025: Why your AI tools are becoming the next insider threat", "content": "## The agentic AI arms race shifts from promises to production\n\nThe conversation at Black Hat 2025 was dominated by agentic AI, with many of the sessions dedicated to how attackers have or can easily compromise agents. VentureBeat observed over 100 announcements promoting new agentic AI applications, platforms or services. Vendors are producing use cases and results. That's a welcome change from the many promises made in prior years and at previous years. There's an urgency to close hype gaps and deliver results.\n\nCrowdStrike's Adam Meyers, head of counter adversary operations, articulated what's driving this urgency in an interview with VentureBeat: \"Agentic AI really becomes the platform that allows SOC operators to build those automations, whether they're using MCP servers to get access to APIs. We're starting to see more and more organizations leveraging our agentic AI to help them integrate with the Falcon and CrowdStrike systems.\" [...] ## Competition shifts from features to results\n\nDespite fierce competition in the race ot deliver agentic AI solutions for the SOC, Black Hat 2025 ironically showed a more unified approach to cybersecurity than any previous event. Every major vendor emphasized three critical components: reasoning engines that can understand context and make nuanced decisions. These action frameworks enable autonomous response within defined boundaries and learning systems that continuously improve based on outcomes.\n\nGoogle Cloud Security's Chronicle SOAR exemplified this shift, introducing an agentic mode that automatically investigates alerts by querying multiple data sources, correlating findings and presenting analysts with complete investigation packages. Even traditionally conservative vendors have embraced the transformation, with IBM and others introducing autonomous investigation capabilities to their existing installations. The convergence was apparent: the industry has moved beyond competing on AI presence to competing on operational excellence.\n\nThe cybersecurity industry is witnessing adversaries leverage GenAI across three primary attack vectors, forcing defenders to adopt equally sophisticated AI-powered defenses. Source: CrowdStrike 2025 Threat Hunting Report [...] ## Many are predicting that AI will become the next insider threat\n\nLooking forward, Black Hat 2025 also highlighted emerging challenges. Meyers delivered perhaps the most sobering prediction of the conference: \"AI is going to be the next insider threat. Organizations trust those AIs implicitly. They are using it to do all of these tasks, and the more comfortable they become, the less they're going to check the output.\"\n\nThis concern sparked discussions about standardization and governance. The Cloud Security Alliance announced a working group focused on agentic AI security standards, while several vendors committed to collaborative efforts around AI agent interoperability. CrowdStrike's expansion of Falcon Shield to include governance for OpenAI GPT-based agents, combined with Cisco's AI supply chain security initiative with Hugging Face, signals the industry's recognition that securing AI agents themselves is becoming as important as using them for security.", "score": 0.80442166, "raw_content": null, "summary": "## The agentic AI arms race shifts from promises to production The conversation at Black Hat 2025 was dominated by agentic AI, with many of the sessions dedicated to how attackers have or can easily compromise agents. We're starting to see more and more organizations leveraging our agentic AI to help them integrate with the Falcon and CrowdStrike systems.\" [...] ## Competition shifts from features"}]}
{"query": "site:arstechnica.com CES 2026 AI (English)", "result": {"query": "CES 2026 AI (English)", "follow_up_questions": null, "answer": null, "images": [], "results": [{"url": "https://arstechnica.com/gadgets/2026/01/dells-xps-revival-is-a-welcome-reprieve-from-the-ai-pc-fad/", "title": "Dell's XPS revival is a welcome reprieve from the “AI PC” fad", "content": "Story text\n\n\\ Subscribers only  \n   Learn more\n\nAfter making the obviously poor decision to kill its XPS laptops and desktops in January 2025, Dell started selling 16- and 14-inch XPS laptops again today.\n\n“It was obvious we needed to change,” Jeff Clarke, vice chairman and COO at Dell Technologies, said at a press event in New York City previewing Dell’s CES 2026 announcements.\n\nA year ago, Dell abandoned XPS branding, as well as its Latitude, Inspiron, and Precision PC lineups. The company replaced the reputable brands with Dell Premium, Dell Pro, and Dell Pro Max. Each series included a base model, as well as “Plus” and “Premium.” Dell isn’t resurrecting its Latitude, Inspiron, or Precision series, and it will still sell “Dell Pro” models.\n\n## XPS returns [...] The website for the new XPS laptops makes an obligatory nod to Microsoft’s Copilot+ PC program but is primarily focused on the computers’ thin build, low weight, battery life, and display. It seems Dell has accepted that these are the things that the average person cares about in their primary laptop, not the computer’s ability to run AI locally.\n\nThe XPS 14 launched today starting at $2,049, and the XPS 16 launched with a starting price of $2,200. A Dell spokesperson told Ars Technica that Dell will release additional configurations in February that are “well under $2,000.” Dell hasn’t shared final specs, pricing, or a release date for the 2026 XPS 13.\n\nScharon Harding  Senior Technology Reporter\n\nScharon Harding  Senior Technology Reporter [...] Skip to content  Ars Technica home \n\n AI\n Biz & IT\n Cars\n Culture\n Gaming\n Health\n Policy\n Science\n Security\n Space\n Tech\n\n Forum \n Subscribe \n\nStory text\n\n\\ Subscribers only  \n   Learn more\n\nSearch dialog...\n\nSign in dialog... \n\nSign in\n\nXPS 16, 14, and 13\n\n# Dell’s XPS revival is a welcome reprieve from the “AI PC” fad\n\nDell moves from pushing “AI PCs” and back to what matters in laptops.\n\nScharon Harding  –  |  84\n\nThe Dell XPS 16 clamshell laptop.  Credit: Dell\n\nThe Dell XPS 16 clamshell laptop.  Credit: Dell\n\nStory text\n\n\\ Subscribers only  \n   Learn more", "score": 0.46337196, "raw_content": null, "summary": "Story text \\ Subscribers only Learn more After making the obviously poor decision to kill its XPS laptops and desktops in January 2025, Dell started selling 16- and 14-inch XPS laptops again today. Sign in XPS 16, 14, and 13 # Dell’s XPS revival is a welcome reprieve from the “AI PC” fad Dell moves from pushing “AI PCs” and back to what matters in laptops."}, {"url": "https://arstechnica.com/tag/ces/", "title": "Tag: CES", "content": "# Topic: CES\n\n## AMD reheats last year’s Ryzen AI and X3D CPUs for 2026’s laptops and desktops\n\nBut it may become slightly cheaper to buy AMD’s fastest integrated Radeon GPUs.\n\n## Accessory maker will pay Nintendo after showing illicit Switch 2 mockups at CES\n\nGenki says it “didn’t obtain any unreleased Nintendo property” before launch.\n\n## The 8 most interesting PC monitors from CES 2025\n\nHere are upcoming computer screens with features that weren’t around last year.\n\nTwo fake cats, sitting on seats atop an air purifier at CES 2025\n\n## Three bizarre home devices and a couple good things at CES 2025\n\nSome quietly good things made an appearance at CES 2025, amidst the AI slush.\n\nHuman with AI TV Head collage art\n\n## Why I’m disappointed with the TVs at CES 2025 [...] It’s a laptop-sized tablet with a laptop-sized price tag.\n\n## Google’s HD map is coming to the Polestar 3 electric SUV\n\nThe more accurate map lets a car know exactly which lane it’s in.\n\nA rendering of a Mercedes charging hub with two Mercedes EVs charging\n\n## Mercedes-Benz will build a $1 billion EV fast-charging network in the US\n\nWorking with ChargePoint, it will install more than 2,500 chargers at 400 sites by 2027.\n\n## Sony announces new controller aimed at gamers with disabilities\n\nAnnouncement comes over 4 years after Microsoft’s Adaptive Controller launch.\n\n## Lenovo puts the legendary ThinkPad brand on a phone: Meet the ThinkPhone\n\nIt has business branding, but it forgot the business hardware features.\n\nThe front half of an Afeela prototype at sunset\n\n## Here’s the electric car that Sony is going to build with Honda [...] LG’s brighter TVs come as Samsung Display’s QD-OLED is poised to hit 2,000 nits.\n\n## New 13th-gen Intel Core desktop CPUs are handing out cores to everyone\n\nAll Core i5-and-up CPUs get E-cores, boosting multi-core performance.\n\nArs Technica has been separating the signal from\nthe noise for over 25 years. With our unique combination of\ntechnical savvy and wide-ranging interest in the technological arts\nand sciences, Ars is the trusted source in a sea of information. After\nall, you don’t need to know everything, only what’s important.", "score": 0.40967003, "raw_content": null, "summary": "Two fake cats, sitting on seats atop an air purifier at CES 2025 ## Three bizarre home devices and a couple good things at CES 2025 Some quietly good things made an appearance at CES 2025, amidst the AI slush. The front half of an Afeela prototype at sunset ## Here’s the electric car that Sony is going to build with Honda [...] LG’s brighter TVs come as Samsung Display’s QD-OLED is poised to hit 2"}, {"url": "https://arstechnica.com/gadgets/2026/01/amd-reheats-last-years-ryzen-ai-and-x3d-cpus-for-2026s-laptops-and-desktops/", "title": "AMD reheats last year's Ryzen AI and X3D CPUs for 2026's laptops ...", "content": "Story text\n\n\\ Subscribers only  \n   Learn more\n\nIntel, AMD, Nvidia, and other chip companies usually have some kind of news to announce at CES to kick off the year, but some of those announcements are more interesting than others. Sometimes you see new chips with significant speed boosts and other new technologies, and sometimes you get rebranded versions of old silicon meant to fill out a lineup or make an existing architecture seem newer and more exciting than it is.\n\nAMD’s Ryzen CPU announcements this year fall firmly into the latter camp—these are all gently tweaked variants of chips that launched in 2024 and 2025.\n\n## “New,” for certain values of “new”\n\nThese Ryzen AI 400-series chips are slightly faster than, but otherwise functionally identical to, the Ryzen AI 300 series.\n\nAMD\n\nThese Ryzen AI 400-series chips are slightly faster than, but otherwise functionally identical to, the Ryzen AI 300 series.   AMD [...] Skip to content  Ars Technica home \n\n AI\n Biz & IT\n Cars\n Culture\n Gaming\n Health\n Policy\n Science\n Security\n Space\n Tech\n\n Forum \n Subscribe \n\nStory text\n\n\\ Subscribers only  \n   Learn more\n\nSearch dialog...\n\nSign in dialog... \n\nSign in\n\nlook who’s back\n\n# AMD reheats last year’s Ryzen AI and X3D CPUs for 2026’s laptops and desktops\n\nBut it may become slightly cheaper to buy AMD’s fastest integrated Radeon GPUs.\n\nAndrew Cunningham  –  |  2\n\nCredit: AMD\n\nCredit: AMD\n\nStory text\n\n\\ Subscribers only  \n   Learn more [...] One side effect of soldiering on with existing architectures in all of these chips, particularly the RDNA 3 graphics architecture, is that none of these integrated GPUs will ever benefit from “FSR Redstone,” the basket of graphics upscaling and frame generation technologies that AMD just announced to try to close the gap between FSR and Nvidia’s competing DLSS features. The Redstone technologies all require hardware only available in the RDNA 4 architecture, which is used only in dedicated Radeon RX 9060 and 9070 series graphics cards. These “new” chips, while still capable of using older FSR versions, will miss out on all those improvements.", "score": 0.400703, "raw_content": null, "summary": "Story text \\ Subscribers only Learn more Intel, AMD, Nvidia, and other chip companies usually have some kind of news to announce at CES to kick off the year, but some of those announcements are more interesting than others. Andrew Cunningham – | 2 Credit: AMD Credit: AMD Story text \\ Subscribers only Learn more [...] One side effect of soldiering on with existing architectures in all of these chip"}, {"url": "https://arstechnica.com/google/2026/01/gemini-expands-on-google-tv-bringing-nano-banana-and-veo-models-to-your-tv/", "title": "Google TV's big Gemini update adds image and video generation ...", "content": "Story text\n\n\\ Subscribers only  \n   Learn more\n\nSoon, even loafing around on the couch won’t help you steer clear of AI. TV makers are busily integrating AI models into the experience, and Google is no different. At CES, the company announced a big expansion of Gemini features on the Google TV platform, starting with TCL smart TVs.\n\nGoogle began integrating Gemini with the TV Streamer box this past fall, but the new expansion brings some of the company’s most popular AI features to TVs: Nano Banana (image) and Veo (video), which offered a huge leap in visual fidelity at launch and have only improved with subsequent updates. Both models will be part of the TV experience, allowing users to modify or create new content.\n\nTV photos remix \n\nGoogle Photos AI remixing in Google TV.\n\nCredit: Google\n\nGoogle Photos AI remixing in Google TV.  Credit: Google [...] Skip to content  Ars Technica home \n\n AI\n Biz & IT\n Cars\n Culture\n Gaming\n Health\n Policy\n Science\n Security\n Space\n Tech\n\n Forum \n Subscribe \n\nStory text\n\n\\ Subscribers only  \n   Learn more\n\nSearch dialog...\n\nSign in dialog... \n\nSign in\n\nAI-assisted couch rotting\n\n# Google TV’s big Gemini update adds image and video generation, voice control for settings\n\nGoogle TV will let you generate and watch AI content on the big screen.\n\nRyan Whitwam  –  |  86\n\nGemini Google TV Gemini Google TV \n\nCredit: Google\n\nCredit: Google\n\nStory text\n\n\\ Subscribers only  \n   Learn more [...] The new Gemini features will debut on TCL TVs that run Google TV, but most other devices, even Google’s own TV Streamer, will have to wait a few months. Even then, you won’t see Gemini taking over every TV or streaming box with Google’s software. The new Gemini features require the full Google TV experience with Android OS version 14 or higher.\n\nPhoto of Ryan Whitwam\n\nRyan Whitwam  Senior Technology Reporter\n\nRyan Whitwam  Senior Technology Reporter\n\nRyan Whitwam is a senior technology reporter at Ars Technica, covering the ways Google, AI, and mobile technology continue to change the world. Over his 20-year career, he's written for Android Police, ExtremeTech, Wirecutter, NY Times, and more. He has reviewed more phones than most people will ever own. You can follow him on Bluesky, where you will see photos of his dozens of mechanical keyboards.\n\n86 Comments\n\nComments\n\n Forum view", "score": 0.3817962, "raw_content": null, "summary": "Google began integrating Gemini with the TV Streamer box this past fall, but the new expansion brings some of the company’s most popular AI features to TVs: Nano Banana (image) and Veo (video), which offered a huge leap in visual fidelity at launch and have only improved with subsequent updates. Ryan Whitwam – | 86 Gemini Google TV Gemini Google TV Credit: Google Credit: Google Story text \\ Subscr"}, {"url": "https://arstechnica.com/cars/2026/01/sony-wants-its-afeela-ev-to-be-heavy-on-ai-also-shows-crossover/", "title": "Spot the difference: Sony's electric car gets a crossover version", "content": "## It’s all about AI\n\nThe big news, at least in terms of detail, wasn’t the crossover, which Sony Honda Mobility says will arrive on sale here in 2028. Rather, like seemingly every other corporation out there, it’s all about AI. A “vision-language model” will “elevate” the Afeela’s partially automated driver assist—which requires the human to pay attention while the car steers, accelerates, and brakes—into something more fully autonomous, capable of point-to-point driving without any other human input, at least under some conditions. [...] Skip to content  Ars Technica home \n\n AI\n Biz & IT\n Cars\n Culture\n Gaming\n Health\n Policy\n Science\n Security\n Space\n Tech\n\n Forum \n Subscribe \n\nStory text\n\n\\ Subscribers only  \n   Learn more\n\nSearch dialog...\n\nSign in dialog... \n\nSign in\n\nSUV on sale 2028\n\n# Spot the difference: Sony’s electric car gets a crossover version\n\nAI will help drive you and entertain you, according to Sony Honda Mobility.\n\nJonathan M. Gitlin  –  |  53\n\nSony Honda Mobility CEO Yasuhide Mizuno on stage with the Afeela 1 sedan (left) and the new Afeela Concept (right)  Credit: Sony Honda Mobility\n\nSony Honda Mobility CEO Yasuhide Mizuno on stage with the Afeela 1 sedan (left) and the new Afeela Concept (right)  Credit: Sony Honda Mobility\n\nStory text [...] “Specifically, we are constantly reviewing sensor devices and layouts, further improving computing power, and making our End-to-End Driving AI stronger,” said Izumi Kawanishi, president and COO of Sony Honda Mobility. “As a result, the cabin will evolve into a drive-less environment, reducing the task of manual driving, and providing more freedom to relax and enjoy entertainment content. In the future, the drive-less environment will transform the cabin into a true ‘Creative Entertainment Space,’” Kawanishi said.\n\nNot having to drive will free you up to interact with the onboard personal AI, which uses Microsoft’s OpenAI tech. The AI agent “enhances mobility interactions through personalized natural dialogue. This elevates the relationship between people and mobility into something more personal and long-lasting,” Kawanishi said, adding that Sony Honda Mobility wants to use AI “sensitively while carefully considering personal information and privacy.”", "score": 0.16114885, "raw_content": null, "summary": "A “vision-language model” will “elevate” the Afeela’s partially automated driver assist—which requires the human to pay attention while the car steers, accelerates, and brakes—into something more fully autonomous, capable of point-to-point driving without any other human input, at least under some conditions. Gitlin – | 53 Sony Honda Mobility CEO Yasuhide Mizuno on stage with the Afeela 1 sedan (l"}], "response_time": 2.68, "request_id": "5d65d94f-455d-4292-b55b-2b4e3ae8a3d9"}, "query_summary": "The front half of an Afeela prototype at sunset ## Here’s the electric car that Sony is going to build with Honda [...] LG’s brighter TVs come as Samsung Display’s QD-OLED is poised to hit 2 Story text \\ Subscribers only Learn more Intel, AMD, Nvidia, and other chip companies usually have some kind of news to announce at CES to kick off the year, but some of those announcements are more interesting than others. Andrew Cunningham – | 2 Credit: AMD Credit: AMD Story text \\ Subscribers only Learn more [...] One side effect of soldiering on with existing architectures in all of these chip Google b", "lang_pref": "en", "preferred_results": [{"url": "https://arstechnica.com/gadgets/2026/01/dells-xps-revival-is-a-welcome-reprieve-from-the-ai-pc-fad/", "title": "Dell's XPS revival is a welcome reprieve from the “AI PC” fad", "content": "Story text\n\n\\ Subscribers only  \n   Learn more\n\nAfter making the obviously poor decision to kill its XPS laptops and desktops in January 2025, Dell started selling 16- and 14-inch XPS laptops again today.\n\n“It was obvious we needed to change,” Jeff Clarke, vice chairman and COO at Dell Technologies, said at a press event in New York City previewing Dell’s CES 2026 announcements.\n\nA year ago, Dell abandoned XPS branding, as well as its Latitude, Inspiron, and Precision PC lineups. The company replaced the reputable brands with Dell Premium, Dell Pro, and Dell Pro Max. Each series included a base model, as well as “Plus” and “Premium.” Dell isn’t resurrecting its Latitude, Inspiron, or Precision series, and it will still sell “Dell Pro” models.\n\n## XPS returns [...] The website for the new XPS laptops makes an obligatory nod to Microsoft’s Copilot+ PC program but is primarily focused on the computers’ thin build, low weight, battery life, and display. It seems Dell has accepted that these are the things that the average person cares about in their primary laptop, not the computer’s ability to run AI locally.\n\nThe XPS 14 launched today starting at $2,049, and the XPS 16 launched with a starting price of $2,200. A Dell spokesperson told Ars Technica that Dell will release additional configurations in February that are “well under $2,000.” Dell hasn’t shared final specs, pricing, or a release date for the 2026 XPS 13.\n\nScharon Harding  Senior Technology Reporter\n\nScharon Harding  Senior Technology Reporter [...] Skip to content  Ars Technica home \n\n AI\n Biz & IT\n Cars\n Culture\n Gaming\n Health\n Policy\n Science\n Security\n Space\n Tech\n\n Forum \n Subscribe \n\nStory text\n\n\\ Subscribers only  \n   Learn more\n\nSearch dialog...\n\nSign in dialog... \n\nSign in\n\nXPS 16, 14, and 13\n\n# Dell’s XPS revival is a welcome reprieve from the “AI PC” fad\n\nDell moves from pushing “AI PCs” and back to what matters in laptops.\n\nScharon Harding  –  |  84\n\nThe Dell XPS 16 clamshell laptop.  Credit: Dell\n\nThe Dell XPS 16 clamshell laptop.  Credit: Dell\n\nStory text\n\n\\ Subscribers only  \n   Learn more", "score": 0.46337196, "raw_content": null, "summary": "Story text \\ Subscribers only Learn more After making the obviously poor decision to kill its XPS laptops and desktops in January 2025, Dell started selling 16- and 14-inch XPS laptops again today. Sign in XPS 16, 14, and 13 # Dell’s XPS revival is a welcome reprieve from the “AI PC” fad Dell moves from pushing “AI PCs” and back to what matters in laptops."}, {"url": "https://arstechnica.com/tag/ces/", "title": "Tag: CES", "content": "# Topic: CES\n\n## AMD reheats last year’s Ryzen AI and X3D CPUs for 2026’s laptops and desktops\n\nBut it may become slightly cheaper to buy AMD’s fastest integrated Radeon GPUs.\n\n## Accessory maker will pay Nintendo after showing illicit Switch 2 mockups at CES\n\nGenki says it “didn’t obtain any unreleased Nintendo property” before launch.\n\n## The 8 most interesting PC monitors from CES 2025\n\nHere are upcoming computer screens with features that weren’t around last year.\n\nTwo fake cats, sitting on seats atop an air purifier at CES 2025\n\n## Three bizarre home devices and a couple good things at CES 2025\n\nSome quietly good things made an appearance at CES 2025, amidst the AI slush.\n\nHuman with AI TV Head collage art\n\n## Why I’m disappointed with the TVs at CES 2025 [...] It’s a laptop-sized tablet with a laptop-sized price tag.\n\n## Google’s HD map is coming to the Polestar 3 electric SUV\n\nThe more accurate map lets a car know exactly which lane it’s in.\n\nA rendering of a Mercedes charging hub with two Mercedes EVs charging\n\n## Mercedes-Benz will build a $1 billion EV fast-charging network in the US\n\nWorking with ChargePoint, it will install more than 2,500 chargers at 400 sites by 2027.\n\n## Sony announces new controller aimed at gamers with disabilities\n\nAnnouncement comes over 4 years after Microsoft’s Adaptive Controller launch.\n\n## Lenovo puts the legendary ThinkPad brand on a phone: Meet the ThinkPhone\n\nIt has business branding, but it forgot the business hardware features.\n\nThe front half of an Afeela prototype at sunset\n\n## Here’s the electric car that Sony is going to build with Honda [...] LG’s brighter TVs come as Samsung Display’s QD-OLED is poised to hit 2,000 nits.\n\n## New 13th-gen Intel Core desktop CPUs are handing out cores to everyone\n\nAll Core i5-and-up CPUs get E-cores, boosting multi-core performance.\n\nArs Technica has been separating the signal from\nthe noise for over 25 years. With our unique combination of\ntechnical savvy and wide-ranging interest in the technological arts\nand sciences, Ars is the trusted source in a sea of information. After\nall, you don’t need to know everything, only what’s important.", "score": 0.40967003, "raw_content": null, "summary": "Two fake cats, sitting on seats atop an air purifier at CES 2025 ## Three bizarre home devices and a couple good things at CES 2025 Some quietly good things made an appearance at CES 2025, amidst the AI slush. The front half of an Afeela prototype at sunset ## Here’s the electric car that Sony is going to build with Honda [...] LG’s brighter TVs come as Samsung Display’s QD-OLED is poised to hit 2"}, {"url": "https://arstechnica.com/gadgets/2026/01/amd-reheats-last-years-ryzen-ai-and-x3d-cpus-for-2026s-laptops-and-desktops/", "title": "AMD reheats last year's Ryzen AI and X3D CPUs for 2026's laptops ...", "content": "Story text\n\n\\ Subscribers only  \n   Learn more\n\nIntel, AMD, Nvidia, and other chip companies usually have some kind of news to announce at CES to kick off the year, but some of those announcements are more interesting than others. Sometimes you see new chips with significant speed boosts and other new technologies, and sometimes you get rebranded versions of old silicon meant to fill out a lineup or make an existing architecture seem newer and more exciting than it is.\n\nAMD’s Ryzen CPU announcements this year fall firmly into the latter camp—these are all gently tweaked variants of chips that launched in 2024 and 2025.\n\n## “New,” for certain values of “new”\n\nThese Ryzen AI 400-series chips are slightly faster than, but otherwise functionally identical to, the Ryzen AI 300 series.\n\nAMD\n\nThese Ryzen AI 400-series chips are slightly faster than, but otherwise functionally identical to, the Ryzen AI 300 series.   AMD [...] Skip to content  Ars Technica home \n\n AI\n Biz & IT\n Cars\n Culture\n Gaming\n Health\n Policy\n Science\n Security\n Space\n Tech\n\n Forum \n Subscribe \n\nStory text\n\n\\ Subscribers only  \n   Learn more\n\nSearch dialog...\n\nSign in dialog... \n\nSign in\n\nlook who’s back\n\n# AMD reheats last year’s Ryzen AI and X3D CPUs for 2026’s laptops and desktops\n\nBut it may become slightly cheaper to buy AMD’s fastest integrated Radeon GPUs.\n\nAndrew Cunningham  –  |  2\n\nCredit: AMD\n\nCredit: AMD\n\nStory text\n\n\\ Subscribers only  \n   Learn more [...] One side effect of soldiering on with existing architectures in all of these chips, particularly the RDNA 3 graphics architecture, is that none of these integrated GPUs will ever benefit from “FSR Redstone,” the basket of graphics upscaling and frame generation technologies that AMD just announced to try to close the gap between FSR and Nvidia’s competing DLSS features. The Redstone technologies all require hardware only available in the RDNA 4 architecture, which is used only in dedicated Radeon RX 9060 and 9070 series graphics cards. These “new” chips, while still capable of using older FSR versions, will miss out on all those improvements.", "score": 0.400703, "raw_content": null, "summary": "Story text \\ Subscribers only Learn more Intel, AMD, Nvidia, and other chip companies usually have some kind of news to announce at CES to kick off the year, but some of those announcements are more interesting than others. Andrew Cunningham – | 2 Credit: AMD Credit: AMD Story text \\ Subscribers only Learn more [...] One side effect of soldiering on with existing architectures in all of these chip"}, {"url": "https://arstechnica.com/google/2026/01/gemini-expands-on-google-tv-bringing-nano-banana-and-veo-models-to-your-tv/", "title": "Google TV's big Gemini update adds image and video generation ...", "content": "Story text\n\n\\ Subscribers only  \n   Learn more\n\nSoon, even loafing around on the couch won’t help you steer clear of AI. TV makers are busily integrating AI models into the experience, and Google is no different. At CES, the company announced a big expansion of Gemini features on the Google TV platform, starting with TCL smart TVs.\n\nGoogle began integrating Gemini with the TV Streamer box this past fall, but the new expansion brings some of the company’s most popular AI features to TVs: Nano Banana (image) and Veo (video), which offered a huge leap in visual fidelity at launch and have only improved with subsequent updates. Both models will be part of the TV experience, allowing users to modify or create new content.\n\nTV photos remix \n\nGoogle Photos AI remixing in Google TV.\n\nCredit: Google\n\nGoogle Photos AI remixing in Google TV.  Credit: Google [...] Skip to content  Ars Technica home \n\n AI\n Biz & IT\n Cars\n Culture\n Gaming\n Health\n Policy\n Science\n Security\n Space\n Tech\n\n Forum \n Subscribe \n\nStory text\n\n\\ Subscribers only  \n   Learn more\n\nSearch dialog...\n\nSign in dialog... \n\nSign in\n\nAI-assisted couch rotting\n\n# Google TV’s big Gemini update adds image and video generation, voice control for settings\n\nGoogle TV will let you generate and watch AI content on the big screen.\n\nRyan Whitwam  –  |  86\n\nGemini Google TV Gemini Google TV \n\nCredit: Google\n\nCredit: Google\n\nStory text\n\n\\ Subscribers only  \n   Learn more [...] The new Gemini features will debut on TCL TVs that run Google TV, but most other devices, even Google’s own TV Streamer, will have to wait a few months. Even then, you won’t see Gemini taking over every TV or streaming box with Google’s software. The new Gemini features require the full Google TV experience with Android OS version 14 or higher.\n\nPhoto of Ryan Whitwam\n\nRyan Whitwam  Senior Technology Reporter\n\nRyan Whitwam  Senior Technology Reporter\n\nRyan Whitwam is a senior technology reporter at Ars Technica, covering the ways Google, AI, and mobile technology continue to change the world. Over his 20-year career, he's written for Android Police, ExtremeTech, Wirecutter, NY Times, and more. He has reviewed more phones than most people will ever own. You can follow him on Bluesky, where you will see photos of his dozens of mechanical keyboards.\n\n86 Comments\n\nComments\n\n Forum view", "score": 0.3817962, "raw_content": null, "summary": "Google began integrating Gemini with the TV Streamer box this past fall, but the new expansion brings some of the company’s most popular AI features to TVs: Nano Banana (image) and Veo (video), which offered a huge leap in visual fidelity at launch and have only improved with subsequent updates. Ryan Whitwam – | 86 Gemini Google TV Gemini Google TV Credit: Google Credit: Google Story text \\ Subscr"}, {"url": "https://arstechnica.com/cars/2026/01/sony-wants-its-afeela-ev-to-be-heavy-on-ai-also-shows-crossover/", "title": "Spot the difference: Sony's electric car gets a crossover version", "content": "## It’s all about AI\n\nThe big news, at least in terms of detail, wasn’t the crossover, which Sony Honda Mobility says will arrive on sale here in 2028. Rather, like seemingly every other corporation out there, it’s all about AI. A “vision-language model” will “elevate” the Afeela’s partially automated driver assist—which requires the human to pay attention while the car steers, accelerates, and brakes—into something more fully autonomous, capable of point-to-point driving without any other human input, at least under some conditions. [...] Skip to content  Ars Technica home \n\n AI\n Biz & IT\n Cars\n Culture\n Gaming\n Health\n Policy\n Science\n Security\n Space\n Tech\n\n Forum \n Subscribe \n\nStory text\n\n\\ Subscribers only  \n   Learn more\n\nSearch dialog...\n\nSign in dialog... \n\nSign in\n\nSUV on sale 2028\n\n# Spot the difference: Sony’s electric car gets a crossover version\n\nAI will help drive you and entertain you, according to Sony Honda Mobility.\n\nJonathan M. Gitlin  –  |  53\n\nSony Honda Mobility CEO Yasuhide Mizuno on stage with the Afeela 1 sedan (left) and the new Afeela Concept (right)  Credit: Sony Honda Mobility\n\nSony Honda Mobility CEO Yasuhide Mizuno on stage with the Afeela 1 sedan (left) and the new Afeela Concept (right)  Credit: Sony Honda Mobility\n\nStory text [...] “Specifically, we are constantly reviewing sensor devices and layouts, further improving computing power, and making our End-to-End Driving AI stronger,” said Izumi Kawanishi, president and COO of Sony Honda Mobility. “As a result, the cabin will evolve into a drive-less environment, reducing the task of manual driving, and providing more freedom to relax and enjoy entertainment content. In the future, the drive-less environment will transform the cabin into a true ‘Creative Entertainment Space,’” Kawanishi said.\n\nNot having to drive will free you up to interact with the onboard personal AI, which uses Microsoft’s OpenAI tech. The AI agent “enhances mobility interactions through personalized natural dialogue. This elevates the relationship between people and mobility into something more personal and long-lasting,” Kawanishi said, adding that Sony Honda Mobility wants to use AI “sensitively while carefully considering personal information and privacy.”", "score": 0.16114885, "raw_content": null, "summary": "A “vision-language model” will “elevate” the Afeela’s partially automated driver assist—which requires the human to pay attention while the car steers, accelerates, and brakes—into something more fully autonomous, capable of point-to-point driving without any other human input, at least under some conditions. Gitlin – | 53 Sony Honda Mobility CEO Yasuhide Mizuno on stage with the Afeela 1 sedan (l"}]}
{"query": "site:theverge.com CES 2026 AI (English)", "result": {"query": "CES 2026 AI (English)", "follow_up_questions": null, "answer": null, "images": [], "results": [{"url": "https://www.theverge.com/news/856207/ces-2026-trend-ai-companion-robot-pet", "title": "AI moves into the real world as companion robots and pets | The Verge", "content": "The homepage\n\nThe homepage\n\nNavigation Drawer\n\n Login\n  Sign Up\n\nSubscribe\n\nComments Drawer\n\nComments\n\nLoading comments\n\nGetting the conversation ready...\n\n# AI moves into the real world as companion robots and pets\n\n﻿Sometimes AI doesn’t need to be a know-it-all, it just wants to keep you company.\n\n﻿Sometimes AI doesn’t need to be a know-it-all, it just wants to keep you company.\n\nby Robert Hart\n\nUncanny valley meets Bichon Frisé.\n\n Image: Ecovacs\n\nPart Of\n\nLIVE\n\nCES 2026 live: all the news, announcements, and innovations from the show floor and beyond\n\nsee all updates\n\nRobert Hart\nis a London-based reporter at The Verge covering all things AI and Senior Tarbell Fellow. Previously, he wrote about health, science and tech for Forbes. [...] Artificial intelligence doesn’t always want to optimize your life or steal your job. Sometimes, AI just wants to be your friend. And while robot pets weren’t the biggest stars of CES 2026, they’ve become more than just noise and are signaling how AI is apparently leaving our screens and taking on a physical presence in our lives. [...] Portable puffs.\n\n Image: Robopoet\n\nRobovac company Ecovacs was also marketing a robot that resembles a Bichon Frisé. It says the emotional companion robot, LilMilo, uses AI and “lifelike biometrics” to recognize voices, develop a personality, and adapt to user habits. As with other products, details on the AI element inside LilMilo are generic and nondescript. It’s an odd product for a company that just launched a robotic pool cleaner, and a telling sign of how companies increasingly expect us to welcome physical AI companions into our homes not for what they do, but simply for being there.\n\nFollow topics and authors from this story to see more like this in your personalized homepage feed and to receive email updates.\n\n Robert Hart\n\n## More in: CES 2026 live: all the news, announcements, and innovations from the show floor and beyond", "score": 0.6894943, "raw_content": null, "summary": "# AI moves into the real world as companion robots and pets ﻿Sometimes AI doesn’t need to be a know-it-all, it just wants to keep you company. Image: Ecovacs Part Of LIVE CES 2026 live: all the news, announcements, and innovations from the show floor and beyond see all updates Robert Hart is a London-based reporter at The Verge covering all things AI and Senior Tarbell Fellow."}, {"url": "https://www.theverge.com/ces", "title": "CES 2026 News - The Verge", "content": "It’s a double Vergecast week for CES 2026.\n\nIn the first of two episodes this week, Nilay and David unpack the flurry of “is this a thing?” AI gadgets that flooded CES, including LG’s CLOiD robot that struggled to put a single towel in a laundry machine.\n\nThe Vergecast will be back tomorrow for a live episode from the Brooklyn Bowl in Las Vegas!\n\nA\n\nAndrew Liszewski\n\nGenki will help you get a better grip on your Switch 2.\n\nThe accessory maker launched a new Kickstarter today for Genki Grips: a modular grip system for Nintendo’s latest console. A $99 pledge gets you get a kit with solid and split shells (that lets the Joy-Cons detach) plus multiple sets of grips with various designs you can regularly swap to improve your hold on the handheld based on the game you’re playing.\n\n1/2 [...] 1/2\n\nThe Genki Grips improve the ergonomics of your Switch 2 in handheld mode.\n\n Image: Genki\n\nTech\n\nTech\n\nAt CES, EVs take a backseat to robotaxis and AI\n\nAndrew J. Hawkins\n\nTech\n\nTech\n\nWi-Fi 8 is appearing at CES before most of us have switched to Wi-Fi 7\n\nStevie Bonifield\n\nTech\n\nTech\n\nCES promises the robot butler, but delivers better Roombas instead\n\nDominic Preston\n\nTech\n\nTech\n\nThe biggest Nvidia announcements at CES 2026\n\nJess Weatherbed\n\nNews\n\nNews\n\nAI moves into the real world as companion robots and pets\n\nRobert Hart\n\nTech\n\nTech\n\nThis robot pool cleaner lifts itself out of the water to charge\n\nEmma Roth\n\nPower bank feature creep is out of control\n\nSomething has gone horribly wrong when your portable battery has a screensaver.\n\nThomas Ricker\n\nT\n\nThomas Ricker [...] Sean Hollister\n\nThis is what the Lego Smart Brick actually does.\n\nToday I toyed with the Lego Smart Brick, touted as the “most significant evolution” to the Lego system in 50 years, and I came away impressed. I have a whole hands-on preview story coming Wednesday, but here’s a whirlwind two-minute video tour of what it can actually do. (Also on YouTube.)\n\nA\n\nAllison Johnson\n\nWell well well, if it isn’t another AI wearable.\n\nThis one’s a concept from Motorola called Maxwell. It includes a microphone and camera for multimodal input, and an integrated magnet means it can be worn as a pendant around your neck or as a pin on your shirt. The idea is that it’ll take meeting notes and hands-free photos, answer questions in natural language — all the usual stuff. Having picked it up, I can at least confirm that it’s much lighter than that other, ill-fated AI pin.", "score": 0.6852132, "raw_content": null, "summary": "A $99 pledge gets you get a kit with solid and split shells (that lets the Joy-Cons detach) plus multiple sets of grips with various designs you can regularly swap to improve your hold on the handheld based on the game you’re playing. Hawkins Tech Tech Wi-Fi 8 is appearing at CES before most of us have switched to Wi-Fi 7 Stevie Bonifield Tech Tech CES promises the robot butler, but delivers bette"}, {"url": "https://www.theverge.com/tech/854159/ces-2026-best-tech-gadgets-smartphones-appliances-robots-tvs-ai-smart-home", "title": "The best tech announced at CES 2026 so far - The Verge", "content": "Acer Swift 16 AI laptop\n\nImage 10: An Acer laptop on a stool with a stylus resting on its touchpad.\n\nPhoto: Antonio G. Di Benedetto / The Verge\n\nAcer announced several new laptops at CES 2026 but the standout is its Swift 16 AI featuring what the company claims is the world’s largest haptic trackpad. It will give your fingers a good workout as they slide back and forth across its wide expanse, but the laptop includes a stylus turning the trackpad into a tablet for sketching or annotating documents. The Swift 16 AI will be available with Intel Panther Lake chips (up to the Core Ultra X9 388H), plenty of ports, and an optional OLED display when it launches in Q1 2026.\n\nHP Eliteboard G1a keyboard computer\n\nImage 11: A person types on the HP Eliteboard G1a keyboard computer connected to a screen.\n\nImage: HP [...] Image: Samsung\n\nSamsung hasn’t changed much with the design of its third-generation Freestyle projector. The new Freestyle Plus still looks like an oversized soda can and features an integrated stand, speakers, and Wi-Fi. But it’s nearly twice as bright as its predecessor at 430 ISO lumens, and it’s getting a host of new AI-powered automatic adjustment features. We got to try them out at CES 2026 and were impressed with the Freestyle Plus’ ability to automatically correct its alignment when projected on challenging surfaces like the corner of a room or even a wavy curtain.\n\n8BitDo Ultimate 3E Controller for Xbox\n\nImage 18: The 8BitDo Ultimate 3E Controller for Xbox on a wooden desk surrounded by parts with its faceplate removed.\n\nImage: 8BitDo [...] Image: Yukai Engineering\n\nIt’s not quite as adorable as the furry Mirumi robot that debuted at last year’s CES, but Yukai Engineering’s new Baby FuFu is potentially more practical. It looks like a cuddly cat that’s huffing and puffing and features an internal fan that will keep young kids cool while preventing tiny fingers from reaching any dangerous moving parts. It’s expected to arrive in mid-2026 for $50 to $60.\n\n_Update, January 6th: Added new announcements from the show._\n\nFollow topics and authors from this story to see more like this in your personalized homepage feed and to receive email updates.\n   Andrew LiszewskiImage 30: Andrew Liszewski \nAndrew Liszewski\n\nSenior Reporter, News  \nPosts from this author will be added to your daily email digest and your homepage feed.\n\nFollow\nSee All by Andrew Liszewski \n   AI AI\n--", "score": 0.6701125, "raw_content": null, "summary": "Di Benedetto / The Verge Acer announced several new laptops at CES 2026 but the standout is its Swift 16 AI featuring what the company claims is the world’s largest haptic trackpad. We got to try them out at CES 2026 and were impressed with the Freestyle Plus’ ability to automatically correct its alignment when projected on challenging surfaces like the corner of a room or even a wavy curtain."}, {"url": "https://www.theverge.com/ai-artificial-intelligence/857077/elon-musks-xai-raised-20-billion-in-funding", "title": "Elon Musk's xAI raised $20 billion in funding. | The Verge", "content": "Lenovo’s joining the bandwagon with concept AI glasses\n\nVictoria Song\n\nDid America just lose the AI race to China?\n\nTina Nguyen\n\nGrok is undressing children — can the law stop it?\n\nHayden Field\n\nUniversal Music signs a new AI deal with Nvidia\n\nElissa Welle\n\nAI moves into the real world as companion robots and pets\n\nRobert Hart\n\nRazer thinks you’d rather have AI headphones instead of glasses\n\nVictoria Song\n\nAdvertiser Content From\n\nThis is the title for the native ad\n\n## Top Stories\n\nThe best tech announced at CES 2026 so far\n\nLenovo’s new concept rollable could be the ideal gaming laptop\n\nGrok is undressing children — can the law stop it?\n\nDid America just lose the AI race to China?\n\nCES 2026 live: all the news, announcements, and innovations from the show floor and beyond [...] Getting the conversation ready...\n\n## Most Popular\n\nMost Popular\n\n1. Lego announces Smart Brick, the ‘most significant evolution’ in 50 years\n2. The best tech announced at CES 2026 so far\n3. CES 2026: all the news, gadgets, and innovations from the biggest tech show\n4. Corsair fit a whole Stream Deck into its new gaming keyboard\n5. I tested Apple’s hands-free Home Key — and it’s a big upgrade\n\n## More in AI\n\nLenovo’s joining the bandwagon with concept AI glasses\n\nDid America just lose the AI race to China?\n\nGrok is undressing children — can the law stop it?\n\nUniversal Music signs a new AI deal with Nvidia\n\nAI moves into the real world as companion robots and pets\n\nRazer thinks you’d rather have AI headphones instead of glasses\n\nLenovo’s joining the bandwagon with concept AI glasses\n\nVictoria Song", "score": 0.6399392, "raw_content": null, "summary": "Hayden Field Universal Music signs a new AI deal with Nvidia Elissa Welle AI moves into the real world as companion robots and pets Robert Hart Razer thinks you’d rather have AI headphones instead of glasses Victoria Song Advertiser Content From This is the title for the native ad ## Top Stories The best tech announced at CES 2026 so far Lenovo’s new concept rollable could be the ideal gaming lapt"}, {"url": "https://www.theverge.com/news/842213/rivian-ai-autonomous-chip-specs", "title": "Rivian is designing its own powerful AI chips for autonomous driving", "content": "All in all, it’s a grab-bag of announcements designed to better position Rivian in the race for autonomous driving. Most of its rivals have a huge head start, but Rivian has proven itself a scrappy and capable player, and there’s no reason to assume that it can’t eventually catch up to any of the big names, including Tesla.\n\nImages from Rivian\n\nFollow topics and authors from this story to see more like this in your personalized homepage feed and to receive email updates.\n\n Andrew J. Hawkins\n\n## Most Popular\n\nMost Popular\n\n1. Lego announces Smart Brick, the ‘most significant evolution’ in 50 years\n2. CES 2026 live: all the news, announcements, and innovations from the show floor and beyond\n3. I played with the Lego Smart Brick\n4. The best tech announced at CES 2026 so far\n5. OpenAI launches ChatGPT Health, encouraging users to connect their medical records [...] Dell admits consumers don’t care about AI PCs\n\nTom Warren\n\nSony’s new ‘Hyperpop’ PS5 covers are bursting with RGB color\n\nTom Warren\n\nAdvertiser Content From\n\nThis is the title for the native ad\n\n## Top Stories\n\nSnatching Maduro was all about the spectacle\n\nOpenAI launches ChatGPT Health, encouraging users to connect their medical records\n\nCES 2026 live: all the news, announcements, and innovations from the show floor and beyond\n\nI played with the Lego Smart Brick\n\nThe weirdest tech we’ve seen at CES 2026\n\nNetflix is bringing back some big franchises in 2026", "score": 0.5663309, "raw_content": null, "summary": "Most of its rivals have a huge head start, but Rivian has proven itself a scrappy and capable player, and there’s no reason to assume that it can’t eventually catch up to any of the big names, including Tesla. OpenAI launches ChatGPT Health, encouraging users to connect their medical records [...] Dell admits consumers don’t care about AI PCs Tom Warren Sony’s new ‘Hyperpop’ PS5 covers are burstin"}], "response_time": 1.42, "request_id": "0d468f66-8d4b-4402-90ee-13023aded585"}, "query_summary": "Image: Ecovacs Part Of LIVE CES 2026 live: all the news, announcements, and innovations from the show floor and beyond see all updates Robert Hart is a London-based reporter at The Verge covering all things AI and Senior Tarbell Fellow. Hawkins Tech Tech Wi-Fi 8 is appearing at CES before most of us have switched to Wi-Fi 7 Stevie Bonifield Tech Tech CES promises the robot butler, but delivers bette Di Benedetto / The Verge Acer announced several new laptops at CES 2026 but the standout is its Swift 16 AI featuring what the company claims is the world’s largest haptic trackpad. Hayden Field Un", "lang_pref": "en", "preferred_results": [{"url": "https://www.theverge.com/news/856207/ces-2026-trend-ai-companion-robot-pet", "title": "AI moves into the real world as companion robots and pets | The Verge", "content": "The homepage\n\nThe homepage\n\nNavigation Drawer\n\n Login\n  Sign Up\n\nSubscribe\n\nComments Drawer\n\nComments\n\nLoading comments\n\nGetting the conversation ready...\n\n# AI moves into the real world as companion robots and pets\n\n﻿Sometimes AI doesn’t need to be a know-it-all, it just wants to keep you company.\n\n﻿Sometimes AI doesn’t need to be a know-it-all, it just wants to keep you company.\n\nby Robert Hart\n\nUncanny valley meets Bichon Frisé.\n\n Image: Ecovacs\n\nPart Of\n\nLIVE\n\nCES 2026 live: all the news, announcements, and innovations from the show floor and beyond\n\nsee all updates\n\nRobert Hart\nis a London-based reporter at The Verge covering all things AI and Senior Tarbell Fellow. Previously, he wrote about health, science and tech for Forbes. [...] Artificial intelligence doesn’t always want to optimize your life or steal your job. Sometimes, AI just wants to be your friend. And while robot pets weren’t the biggest stars of CES 2026, they’ve become more than just noise and are signaling how AI is apparently leaving our screens and taking on a physical presence in our lives. [...] Portable puffs.\n\n Image: Robopoet\n\nRobovac company Ecovacs was also marketing a robot that resembles a Bichon Frisé. It says the emotional companion robot, LilMilo, uses AI and “lifelike biometrics” to recognize voices, develop a personality, and adapt to user habits. As with other products, details on the AI element inside LilMilo are generic and nondescript. It’s an odd product for a company that just launched a robotic pool cleaner, and a telling sign of how companies increasingly expect us to welcome physical AI companions into our homes not for what they do, but simply for being there.\n\nFollow topics and authors from this story to see more like this in your personalized homepage feed and to receive email updates.\n\n Robert Hart\n\n## More in: CES 2026 live: all the news, announcements, and innovations from the show floor and beyond", "score": 0.6894943, "raw_content": null, "summary": "# AI moves into the real world as companion robots and pets ﻿Sometimes AI doesn’t need to be a know-it-all, it just wants to keep you company. Image: Ecovacs Part Of LIVE CES 2026 live: all the news, announcements, and innovations from the show floor and beyond see all updates Robert Hart is a London-based reporter at The Verge covering all things AI and Senior Tarbell Fellow."}, {"url": "https://www.theverge.com/ces", "title": "CES 2026 News - The Verge", "content": "It’s a double Vergecast week for CES 2026.\n\nIn the first of two episodes this week, Nilay and David unpack the flurry of “is this a thing?” AI gadgets that flooded CES, including LG’s CLOiD robot that struggled to put a single towel in a laundry machine.\n\nThe Vergecast will be back tomorrow for a live episode from the Brooklyn Bowl in Las Vegas!\n\nA\n\nAndrew Liszewski\n\nGenki will help you get a better grip on your Switch 2.\n\nThe accessory maker launched a new Kickstarter today for Genki Grips: a modular grip system for Nintendo’s latest console. A $99 pledge gets you get a kit with solid and split shells (that lets the Joy-Cons detach) plus multiple sets of grips with various designs you can regularly swap to improve your hold on the handheld based on the game you’re playing.\n\n1/2 [...] 1/2\n\nThe Genki Grips improve the ergonomics of your Switch 2 in handheld mode.\n\n Image: Genki\n\nTech\n\nTech\n\nAt CES, EVs take a backseat to robotaxis and AI\n\nAndrew J. Hawkins\n\nTech\n\nTech\n\nWi-Fi 8 is appearing at CES before most of us have switched to Wi-Fi 7\n\nStevie Bonifield\n\nTech\n\nTech\n\nCES promises the robot butler, but delivers better Roombas instead\n\nDominic Preston\n\nTech\n\nTech\n\nThe biggest Nvidia announcements at CES 2026\n\nJess Weatherbed\n\nNews\n\nNews\n\nAI moves into the real world as companion robots and pets\n\nRobert Hart\n\nTech\n\nTech\n\nThis robot pool cleaner lifts itself out of the water to charge\n\nEmma Roth\n\nPower bank feature creep is out of control\n\nSomething has gone horribly wrong when your portable battery has a screensaver.\n\nThomas Ricker\n\nT\n\nThomas Ricker [...] Sean Hollister\n\nThis is what the Lego Smart Brick actually does.\n\nToday I toyed with the Lego Smart Brick, touted as the “most significant evolution” to the Lego system in 50 years, and I came away impressed. I have a whole hands-on preview story coming Wednesday, but here’s a whirlwind two-minute video tour of what it can actually do. (Also on YouTube.)\n\nA\n\nAllison Johnson\n\nWell well well, if it isn’t another AI wearable.\n\nThis one’s a concept from Motorola called Maxwell. It includes a microphone and camera for multimodal input, and an integrated magnet means it can be worn as a pendant around your neck or as a pin on your shirt. The idea is that it’ll take meeting notes and hands-free photos, answer questions in natural language — all the usual stuff. Having picked it up, I can at least confirm that it’s much lighter than that other, ill-fated AI pin.", "score": 0.6852132, "raw_content": null, "summary": "A $99 pledge gets you get a kit with solid and split shells (that lets the Joy-Cons detach) plus multiple sets of grips with various designs you can regularly swap to improve your hold on the handheld based on the game you’re playing. Hawkins Tech Tech Wi-Fi 8 is appearing at CES before most of us have switched to Wi-Fi 7 Stevie Bonifield Tech Tech CES promises the robot butler, but delivers bette"}, {"url": "https://www.theverge.com/tech/854159/ces-2026-best-tech-gadgets-smartphones-appliances-robots-tvs-ai-smart-home", "title": "The best tech announced at CES 2026 so far - The Verge", "content": "Acer Swift 16 AI laptop\n\nImage 10: An Acer laptop on a stool with a stylus resting on its touchpad.\n\nPhoto: Antonio G. Di Benedetto / The Verge\n\nAcer announced several new laptops at CES 2026 but the standout is its Swift 16 AI featuring what the company claims is the world’s largest haptic trackpad. It will give your fingers a good workout as they slide back and forth across its wide expanse, but the laptop includes a stylus turning the trackpad into a tablet for sketching or annotating documents. The Swift 16 AI will be available with Intel Panther Lake chips (up to the Core Ultra X9 388H), plenty of ports, and an optional OLED display when it launches in Q1 2026.\n\nHP Eliteboard G1a keyboard computer\n\nImage 11: A person types on the HP Eliteboard G1a keyboard computer connected to a screen.\n\nImage: HP [...] Image: Samsung\n\nSamsung hasn’t changed much with the design of its third-generation Freestyle projector. The new Freestyle Plus still looks like an oversized soda can and features an integrated stand, speakers, and Wi-Fi. But it’s nearly twice as bright as its predecessor at 430 ISO lumens, and it’s getting a host of new AI-powered automatic adjustment features. We got to try them out at CES 2026 and were impressed with the Freestyle Plus’ ability to automatically correct its alignment when projected on challenging surfaces like the corner of a room or even a wavy curtain.\n\n8BitDo Ultimate 3E Controller for Xbox\n\nImage 18: The 8BitDo Ultimate 3E Controller for Xbox on a wooden desk surrounded by parts with its faceplate removed.\n\nImage: 8BitDo [...] Image: Yukai Engineering\n\nIt’s not quite as adorable as the furry Mirumi robot that debuted at last year’s CES, but Yukai Engineering’s new Baby FuFu is potentially more practical. It looks like a cuddly cat that’s huffing and puffing and features an internal fan that will keep young kids cool while preventing tiny fingers from reaching any dangerous moving parts. It’s expected to arrive in mid-2026 for $50 to $60.\n\n_Update, January 6th: Added new announcements from the show._\n\nFollow topics and authors from this story to see more like this in your personalized homepage feed and to receive email updates.\n   Andrew LiszewskiImage 30: Andrew Liszewski \nAndrew Liszewski\n\nSenior Reporter, News  \nPosts from this author will be added to your daily email digest and your homepage feed.\n\nFollow\nSee All by Andrew Liszewski \n   AI AI\n--", "score": 0.6701125, "raw_content": null, "summary": "Di Benedetto / The Verge Acer announced several new laptops at CES 2026 but the standout is its Swift 16 AI featuring what the company claims is the world’s largest haptic trackpad. We got to try them out at CES 2026 and were impressed with the Freestyle Plus’ ability to automatically correct its alignment when projected on challenging surfaces like the corner of a room or even a wavy curtain."}, {"url": "https://www.theverge.com/ai-artificial-intelligence/857077/elon-musks-xai-raised-20-billion-in-funding", "title": "Elon Musk's xAI raised $20 billion in funding. | The Verge", "content": "Lenovo’s joining the bandwagon with concept AI glasses\n\nVictoria Song\n\nDid America just lose the AI race to China?\n\nTina Nguyen\n\nGrok is undressing children — can the law stop it?\n\nHayden Field\n\nUniversal Music signs a new AI deal with Nvidia\n\nElissa Welle\n\nAI moves into the real world as companion robots and pets\n\nRobert Hart\n\nRazer thinks you’d rather have AI headphones instead of glasses\n\nVictoria Song\n\nAdvertiser Content From\n\nThis is the title for the native ad\n\n## Top Stories\n\nThe best tech announced at CES 2026 so far\n\nLenovo’s new concept rollable could be the ideal gaming laptop\n\nGrok is undressing children — can the law stop it?\n\nDid America just lose the AI race to China?\n\nCES 2026 live: all the news, announcements, and innovations from the show floor and beyond [...] Getting the conversation ready...\n\n## Most Popular\n\nMost Popular\n\n1. Lego announces Smart Brick, the ‘most significant evolution’ in 50 years\n2. The best tech announced at CES 2026 so far\n3. CES 2026: all the news, gadgets, and innovations from the biggest tech show\n4. Corsair fit a whole Stream Deck into its new gaming keyboard\n5. I tested Apple’s hands-free Home Key — and it’s a big upgrade\n\n## More in AI\n\nLenovo’s joining the bandwagon with concept AI glasses\n\nDid America just lose the AI race to China?\n\nGrok is undressing children — can the law stop it?\n\nUniversal Music signs a new AI deal with Nvidia\n\nAI moves into the real world as companion robots and pets\n\nRazer thinks you’d rather have AI headphones instead of glasses\n\nLenovo’s joining the bandwagon with concept AI glasses\n\nVictoria Song", "score": 0.6399392, "raw_content": null, "summary": "Hayden Field Universal Music signs a new AI deal with Nvidia Elissa Welle AI moves into the real world as companion robots and pets Robert Hart Razer thinks you’d rather have AI headphones instead of glasses Victoria Song Advertiser Content From This is the title for the native ad ## Top Stories The best tech announced at CES 2026 so far Lenovo’s new concept rollable could be the ideal gaming lapt"}, {"url": "https://www.theverge.com/news/842213/rivian-ai-autonomous-chip-specs", "title": "Rivian is designing its own powerful AI chips for autonomous driving", "content": "All in all, it’s a grab-bag of announcements designed to better position Rivian in the race for autonomous driving. Most of its rivals have a huge head start, but Rivian has proven itself a scrappy and capable player, and there’s no reason to assume that it can’t eventually catch up to any of the big names, including Tesla.\n\nImages from Rivian\n\nFollow topics and authors from this story to see more like this in your personalized homepage feed and to receive email updates.\n\n Andrew J. Hawkins\n\n## Most Popular\n\nMost Popular\n\n1. Lego announces Smart Brick, the ‘most significant evolution’ in 50 years\n2. CES 2026 live: all the news, announcements, and innovations from the show floor and beyond\n3. I played with the Lego Smart Brick\n4. The best tech announced at CES 2026 so far\n5. OpenAI launches ChatGPT Health, encouraging users to connect their medical records [...] Dell admits consumers don’t care about AI PCs\n\nTom Warren\n\nSony’s new ‘Hyperpop’ PS5 covers are bursting with RGB color\n\nTom Warren\n\nAdvertiser Content From\n\nThis is the title for the native ad\n\n## Top Stories\n\nSnatching Maduro was all about the spectacle\n\nOpenAI launches ChatGPT Health, encouraging users to connect their medical records\n\nCES 2026 live: all the news, announcements, and innovations from the show floor and beyond\n\nI played with the Lego Smart Brick\n\nThe weirdest tech we’ve seen at CES 2026\n\nNetflix is bringing back some big franchises in 2026", "score": 0.5663309, "raw_content": null, "summary": "Most of its rivals have a huge head start, but Rivian has proven itself a scrappy and capable player, and there’s no reason to assume that it can’t eventually catch up to any of the big names, including Tesla. OpenAI launches ChatGPT Health, encouraging users to connect their medical records [...] Dell admits consumers don’t care about AI PCs Tom Warren Sony’s new ‘Hyperpop’ PS5 covers are burstin"}]}
{"query": "site:nature.com Nature Communications AI open access (English)", "result": {"query": "Nature Communications AI open access (English)", "follow_up_questions": null, "answer": null, "images": [], "results": [{"url": "https://www.nature.com/articles/s41467-024-51714-x", "title": "The global geography of artificial intelligence in life science ...", "content": "Article Open access 23 January 2024\n\n## Introduction\n\nArtificial intelligence (AI) promises to transform the life sciences and, ultimately, medical care1.\"). Broadly defined, AI refers to the ability of a digital computer or computer-controlled robot to perform tasks commonly associated with intelligent beings2.\"). In the life sciences, AI is already widely used, for example, when computers analyze large amounts of patient data to aid in initial diagnoses, or when algorithms optimize patient enrollment in clinical trials for drug development3.\"),4.\"),5.\"). The high hopes for the growing use of AI technology are reflected in estimates that the global market for AI-based medical care will grow eightfold by 20276.\"). [...] Thank you for visiting nature.com. You are using a browser version with limited support for CSS. To obtain the best experience, we recommend you use a more up to date browser (or turn off compatibility mode in Internet Explorer). In the meantime, to ensure continued support, we are displaying the site without styles and JavaScript.\n\n View all journals\n Search\n Log in\n\n Content Explore content\n About the journal\n Publish with us\n\n Sign up for alerts\n RSS feed\n\nThe global geography of artificial intelligence in life science research\n\nDownload PDF\n\nDownload PDF\n\n Article\n Open access\n Published:\n\n# The global geography of artificial intelligence in life science research\n\n Leo Schmallenbach  ORCID: orcid.org/0000-0001-5302-25781,\n Till W. Bärnighausen2,3,4 &\n Marc J. Lerchenmueller  ORCID: orcid.org/0000-0001-8875-36021,5 [...] ### Similar content being viewed by others\n\n### Disparities in clinical studies of AI enabled applications from a global perspective\n\nArticle Open access 10 August 2024\n\n### Beijing’s central role in global artificial intelligence research\n\nArticle Open access 12 December 2022\n\n### An intriguing vision for transatlantic collaborative health data use and artificial intelligence development\n\nArticle Open access 23 January 2024\n\n## Introduction", "score": 0.6175132, "raw_content": null, "summary": "View all journals Search Log in Content Explore content About the journal Publish with us Sign up for alerts RSS feed The global geography of artificial intelligence in life science research Download PDF Download PDF Article Open access Published: # The global geography of artificial intelligence in life science research Leo Schmallenbach ORCID: orcid.org/0000-0001-5302-25781, Till W. Lerchenmuell"}, {"url": "https://www.nature.com/ncomms/submit/how-to-submit", "title": "How to submit | Nature Communications", "content": "## Costs\n\nNature Communications does not charge submission fees or page charges. However, authors submitting to Nature Communications from 20th October 2014 are required to publish their work open access, through payment of an article processing charge (APC), in the case of eventual acceptance. Please see the open access page for APC pricing and details of our free funding support service.\n\n## General information for preparing manuscripts\n\nManuscripts should be prepared for online submission. Online submissions include a cover letter, a manuscript text file, individual figure files and optional Supplementary Information files. For first submissions (i.e. not revised manuscripts), authors may choose to incorporate the manuscript text and figures into a single file (Microsoft Word, TeX/LaTeX or PDF) up to 30 MB in size — the figures may be inserted within the text at the appropriate positions, or grouped at the end. Supplementary Information should be combined and supplied as a separate file, preferably in Word format. [...] 1. Line art, graphs, charts and schematics\n\nAll line art, graphs, charts and schematics should be supplied in vector format, such as Encapsulated PostScript (.EPS), Adobe Illustrator (.AI), or Portable Document Format (.PDF), and should be saved or exported as such directly from the application in which they were made.\n\nWe prefer to work with Adobe Illustrator but can accept Word and PowerPoint files.\n\nThey should not be flattened, compressed, converted or saved as bitmaps, jpegs or other non-vector file types. If line-art figures cannot be supplied as vector files they should be supplied at 1,200 DPI and prepared to fit the page size.\n\n2. Photographic and bitmapped images [...] Figure lettering should be in a clear, sans-serif typeface (for example, Helvetica); if possible, the same typeface in approximately the same font size should be used for all figures in a paper. Use symbol font for Greek letters. All display items should be on a white background, and should avoid excessive boxing, unnecessary colour, spurious decorative effects (such as three-dimensional 'skyscraper' histograms) and highly pixelated computer drawings. The vertical axis of histograms should not be truncated to exaggerate small differences. Labelling must be of sufficient size and contrast to be readable, even after appropriate reduction. The thinnest lines in the final figure should be no smaller than one point wide. Reasonable requests to enlarge figures will be considered, but editors will make the final decision on figure size. Authors will see a proof of figures.", "score": 0.523494, "raw_content": null, "summary": "not revised manuscripts), authors may choose to incorporate the manuscript text and figures into a single file (Microsoft Word, TeX/LaTeX or PDF) up to 30 MB in size — the figures may be inserted within the text at the appropriate positions, or grouped at the end. Line art, graphs, charts and schematics All line art, graphs, charts and schematics should be supplied in vector format, such as Encaps"}, {"url": "https://www.nature.com/ncomms/journal-information", "title": "Journal Information | Nature Communications", "content": "Why publish in Nature Communications?\n\n Publishes in all areas of life, health, social, physical, chemical and Earth sciences\n Presents important advances of significance to specialists within each field\n High visibility for your work with open access\n\n## Aims & Scope\n\nMore on the aims and scope of Nature Communications is available in this section, as well as article and journal metrics, indexing and archiving information.\n\n## Editors\n\nInformation about the Editors of Nature Communications can be found here.\n\n## Open Access\n\nNature Communications is a fully open access journal. More on Creative Commons Attribution licenses and the benefits of publishing open access can be found in this section.\n\n## Article Processing Charges\n\nTo allow immediate global open access to all articles, Nature Communications levies an article processing charge (APC). Current APCs and waiver information are available in this section. [...] Thank you for visiting nature.com. You are using a browser version with limited support for CSS. To obtain the best experience, we recommend you use a more up to date browser (or turn off compatibility mode in Internet Explorer). In the meantime, to ensure continued support, we are displaying the site without styles and JavaScript.\n\n View all journals\n Search\n Log in\n\n Content Explore content\n About the journal\n Publish with us\n\n Sign up for alerts\n RSS feed\n\n# Journal Information\n\nNature Communications is an open access journal that publishes high-quality research from all areas of the natural sciences. Papers published by the journal represent important advances of significance to specialists within each field.\n\nNature Communications has a 2-year impact factor: 15.7 (2024),  5-year Journal Impact Factor: 17.2 (2024), Article downloads of 177,272,701 (2024), and 8 days (median) from submission to the first editorial decision. [...] Disclaimer   \n Nature Portfolio journals occasionally use internal Springer Nature-developed artificial intelligence tools to support the generation of accessory content, such as summary points. These are always edited and fact-checked by the author and/or editor to meet Nature Portfolio publication standards. Any substantive use of artificial intelligence beyond accessory content will be declared on an individual article basis.\n\n## Search\n\nAdvanced search\n\n### Quick links\n\n Explore articles by subject\n Find a job\n Guide to authors\n Editorial policies", "score": 0.5148644, "raw_content": null, "summary": "Publishes in all areas of life, health, social, physical, chemical and Earth sciences Presents important advances of significance to specialists within each field High visibility for your work with open access ## Aims & Scope More on the aims and scope of Nature Communications is available in this section, as well as article and journal metrics, indexing and archiving information. View all journal"}, {"url": "https://www.nature.com/ncomms/", "title": "Nature Communications", "content": "Aircraft contrails are not just streaks in clear blue skies - they represent a significant source of warming from the aviation sector. Two new studies reveal that their climate impact is more complex than previously thought, as many contrails may form within existing cirrus clouds – a factor often overlooked in past assessments. Drawing on aircraft, satellite and meteorological data, Petzold et al. and Seelig et al. provide fresh insights into the occurrence frequency and the radiative properties of these often “hidden” contrails.\n\n  + Ziming Wang\n  + Christiane Voigt\n\n  CommentOpen Access\n\n## Collections\n\n### AI and machine learning\n\nA periscope into the broad-ranging applications of machine learning and how it is enabling new research and tools, reducing inequality and increasing quality of life – with a focus on the general pursuit of laying the foundations of Artificial Intelligence.\n\nFocus\n\nAdvertisement\n\n## Trending - Altmetric [...] Skip to main content\n\n## A multisynaptic spiking neuron for simultaneously encoding spatiotemporal dynamics\n\nLiangwei Fan et al. propose a multi synaptic firing neuron, that allows to encode spatiotemporal data in neuromorphic computing more effectively.\n\n ### 50 years of weather forecasting at the ECMWF\n ### Machine learning applied to biocatalysis research\n ### A mining reality check on net zero\n\n  Projections show a massive shortfall in the supply of lithium and copper required to reach net zero emissions by 2050. We won’t run out of resources but with some mines taking decades to bring into production, we may run out of time.\n\n  EditorialOpen Access\n ### Q&A Europa Clipper mission [...] This study surveyed key informants across 26 countries on burning plastic for waste management and energy needs. It finds high awareness of this practice, with potential drivers including inadequate waste collection and a lack of affordable fuels.\n\n  + Bishal Bharadwaj\n  + Tara Gates\n  + Peta Ashworth\n\n  ArticleOpen Access\n ### Historical reconstruction of human moralization with word association and text corpora\n\n  People have moralized different concepts over history. Here, the authors show that the historical time courses of moralization can be restored computationally by combining machine learning with psychological data of word association and text corpora.\n\n  + Aida Ramezani\n  + Jennifer E. Stellar\n  + Yang Xu\n\n  ArticleOpen Access\n ### Behavioral uncertainty in EV charging drives heterogeneous grid load variability under climate goals", "score": 0.50227106, "raw_content": null, "summary": "+ Ziming Wang + Christiane Voigt CommentOpen Access ## Collections ### AI and machine learning A periscope into the broad-ranging applications of machine learning and how it is enabling new research and tools, reducing inequality and increasing quality of life – with a focus on the general pursuit of laying the foundations of Artificial Intelligence. ### 50 years of weather forecasting at the ECMW"}, {"title": "Browse Articles | Nature", "url": "https://www.nature.com/nature/articles", "content": "### Science in 2026: what to expect this year\n\nMore refined AI models, advancements in human gene editing and the continuing impact of the Trump Team on science — we run through what to look out for over the next 12 months. \n       Nick Petrić Howe\n       Miryam Naddaf\n\nNature Podcast 01 Jan 2026\n\n   \nImage 14 \n\n### A chiral fermionic valve driven by quantum geometry\n\nFermionic currents of opposing chirality can be spatially filtered without the need for a magnetic field using the quantum geometry of topological bands in single-crystal PdGa. \n       Anvesh Dixit\n       Pranava K. Sivakumar\n       Stuart S. P. Parkin\n\nArticle Open Access 31 Dec 2025\n\n   \nImage 15 \n\n### Random heteropolymers as enzyme mimics [...] Show results from \n\nSearch\n\nAdvanced search\n\n### Quick links\n\n   Explore articles by subject\n   Find a job\n   Guide to authors\n   Editorial policies\n\nNature  (_Nature_)\n\nISSN 1476-4687 (online)\n\nISSN 0028-0836 (print)\n\nnature.com sitemap\n\n### About Nature Portfolio\n\n   About us\n   Press releases\n   Press office\n   Contact us\n\n### Discover content\n\n   Journals A-Z\n   Articles by subject\n   protocols.io\n   Nature Index\n\n### Publishing policies\n\n   Nature portfolio policies\n   Open access\n\n### Author & Researcher services\n\n   Reprints & permissions\n   Research data\n   Language editing\n   Scientific editing\n   Nature Masterclasses\n   Research Solutions\n\n### Libraries & institutions\n\n   Librarian service & tools\n   Librarian portal\n   Open research\n   Recommend to library\n\n### Advertising & partnerships [...] Explore content\n\n   Research articles\n   News\n   Opinion\n   Research Analysis\n   Careers\n   Books & Culture\n   Podcasts\n   Videos\n   Current issue\n   Browse issues\n   Collections\n   Subjects\n\n   Follow us on Facebook\n   Follow us on Twitter\n   Subscribe\n   Sign up for alerts\n   RSS feed\n\nAbout the journal\n\n   Journal Staff\n   About the Editors\n   Journal Information\n   Journal Metrics\n   Our publishing models\n   Editorial Values Statement\n   Editorial policies\n   Journalistic Principles\n   History of Nature\n   Awards\n   Contact\n   Send a news tip\n\nPublish with us\n\n   For Authors\n   For Referees\n   Language editing services\n   Open access funding\n   Submit manuscript\n\nSearch\n\nSearch articles by subject, keyword or author \n\nShow results from \n\nSearch\n\nAdvanced search\n\n### Quick links", "score": 0.35575303, "raw_content": null, "summary": "Nick Petrić Howe Miryam Naddaf Nature Podcast 01 Jan 2026 Image 14 ### A chiral fermionic valve driven by quantum geometry Fermionic currents of opposing chirality can be spatially filtered without the need for a magnetic field using the quantum geometry of topological bands in single-crystal PdGa. Parkin Article Open Access 31 Dec 2025 Image 15 ### Random heteropolymers as enzyme mimics [...] Sho"}], "response_time": 3.94, "request_id": "bf22eda3-10e2-4d68-bedd-dcbcedb253d7"}, "query_summary": "View all journals Search Log in Content Explore content About the journal Publish with us Sign up for alerts RSS feed The global geography of artificial intelligence in life science research Download PDF Download PDF Article Open access Published: # The global geography of artificial intelligence in life science research Leo Schmallenbach ORCID: orcid.org/0000-0001-5302-25781, Till W. Line art, graphs, charts and schematics All line art, graphs, charts and schematics should be supplied in vector format, such as Encaps Publishes in all areas of life, health, social, physical, chemical and Earth", "lang_pref": "en", "preferred_results": [{"url": "https://www.nature.com/articles/s41467-024-51714-x", "title": "The global geography of artificial intelligence in life science ...", "content": "Article Open access 23 January 2024\n\n## Introduction\n\nArtificial intelligence (AI) promises to transform the life sciences and, ultimately, medical care1.\"). Broadly defined, AI refers to the ability of a digital computer or computer-controlled robot to perform tasks commonly associated with intelligent beings2.\"). In the life sciences, AI is already widely used, for example, when computers analyze large amounts of patient data to aid in initial diagnoses, or when algorithms optimize patient enrollment in clinical trials for drug development3.\"),4.\"),5.\"). The high hopes for the growing use of AI technology are reflected in estimates that the global market for AI-based medical care will grow eightfold by 20276.\"). [...] Thank you for visiting nature.com. You are using a browser version with limited support for CSS. To obtain the best experience, we recommend you use a more up to date browser (or turn off compatibility mode in Internet Explorer). In the meantime, to ensure continued support, we are displaying the site without styles and JavaScript.\n\n View all journals\n Search\n Log in\n\n Content Explore content\n About the journal\n Publish with us\n\n Sign up for alerts\n RSS feed\n\nThe global geography of artificial intelligence in life science research\n\nDownload PDF\n\nDownload PDF\n\n Article\n Open access\n Published:\n\n# The global geography of artificial intelligence in life science research\n\n Leo Schmallenbach  ORCID: orcid.org/0000-0001-5302-25781,\n Till W. Bärnighausen2,3,4 &\n Marc J. Lerchenmueller  ORCID: orcid.org/0000-0001-8875-36021,5 [...] ### Similar content being viewed by others\n\n### Disparities in clinical studies of AI enabled applications from a global perspective\n\nArticle Open access 10 August 2024\n\n### Beijing’s central role in global artificial intelligence research\n\nArticle Open access 12 December 2022\n\n### An intriguing vision for transatlantic collaborative health data use and artificial intelligence development\n\nArticle Open access 23 January 2024\n\n## Introduction", "score": 0.6175132, "raw_content": null, "summary": "View all journals Search Log in Content Explore content About the journal Publish with us Sign up for alerts RSS feed The global geography of artificial intelligence in life science research Download PDF Download PDF Article Open access Published: # The global geography of artificial intelligence in life science research Leo Schmallenbach ORCID: orcid.org/0000-0001-5302-25781, Till W. Lerchenmuell"}, {"url": "https://www.nature.com/ncomms/submit/how-to-submit", "title": "How to submit | Nature Communications", "content": "## Costs\n\nNature Communications does not charge submission fees or page charges. However, authors submitting to Nature Communications from 20th October 2014 are required to publish their work open access, through payment of an article processing charge (APC), in the case of eventual acceptance. Please see the open access page for APC pricing and details of our free funding support service.\n\n## General information for preparing manuscripts\n\nManuscripts should be prepared for online submission. Online submissions include a cover letter, a manuscript text file, individual figure files and optional Supplementary Information files. For first submissions (i.e. not revised manuscripts), authors may choose to incorporate the manuscript text and figures into a single file (Microsoft Word, TeX/LaTeX or PDF) up to 30 MB in size — the figures may be inserted within the text at the appropriate positions, or grouped at the end. Supplementary Information should be combined and supplied as a separate file, preferably in Word format. [...] 1. Line art, graphs, charts and schematics\n\nAll line art, graphs, charts and schematics should be supplied in vector format, such as Encapsulated PostScript (.EPS), Adobe Illustrator (.AI), or Portable Document Format (.PDF), and should be saved or exported as such directly from the application in which they were made.\n\nWe prefer to work with Adobe Illustrator but can accept Word and PowerPoint files.\n\nThey should not be flattened, compressed, converted or saved as bitmaps, jpegs or other non-vector file types. If line-art figures cannot be supplied as vector files they should be supplied at 1,200 DPI and prepared to fit the page size.\n\n2. Photographic and bitmapped images [...] Figure lettering should be in a clear, sans-serif typeface (for example, Helvetica); if possible, the same typeface in approximately the same font size should be used for all figures in a paper. Use symbol font for Greek letters. All display items should be on a white background, and should avoid excessive boxing, unnecessary colour, spurious decorative effects (such as three-dimensional 'skyscraper' histograms) and highly pixelated computer drawings. The vertical axis of histograms should not be truncated to exaggerate small differences. Labelling must be of sufficient size and contrast to be readable, even after appropriate reduction. The thinnest lines in the final figure should be no smaller than one point wide. Reasonable requests to enlarge figures will be considered, but editors will make the final decision on figure size. Authors will see a proof of figures.", "score": 0.523494, "raw_content": null, "summary": "not revised manuscripts), authors may choose to incorporate the manuscript text and figures into a single file (Microsoft Word, TeX/LaTeX or PDF) up to 30 MB in size — the figures may be inserted within the text at the appropriate positions, or grouped at the end. Line art, graphs, charts and schematics All line art, graphs, charts and schematics should be supplied in vector format, such as Encaps"}, {"url": "https://www.nature.com/ncomms/journal-information", "title": "Journal Information | Nature Communications", "content": "Why publish in Nature Communications?\n\n Publishes in all areas of life, health, social, physical, chemical and Earth sciences\n Presents important advances of significance to specialists within each field\n High visibility for your work with open access\n\n## Aims & Scope\n\nMore on the aims and scope of Nature Communications is available in this section, as well as article and journal metrics, indexing and archiving information.\n\n## Editors\n\nInformation about the Editors of Nature Communications can be found here.\n\n## Open Access\n\nNature Communications is a fully open access journal. More on Creative Commons Attribution licenses and the benefits of publishing open access can be found in this section.\n\n## Article Processing Charges\n\nTo allow immediate global open access to all articles, Nature Communications levies an article processing charge (APC). Current APCs and waiver information are available in this section. [...] Thank you for visiting nature.com. You are using a browser version with limited support for CSS. To obtain the best experience, we recommend you use a more up to date browser (or turn off compatibility mode in Internet Explorer). In the meantime, to ensure continued support, we are displaying the site without styles and JavaScript.\n\n View all journals\n Search\n Log in\n\n Content Explore content\n About the journal\n Publish with us\n\n Sign up for alerts\n RSS feed\n\n# Journal Information\n\nNature Communications is an open access journal that publishes high-quality research from all areas of the natural sciences. Papers published by the journal represent important advances of significance to specialists within each field.\n\nNature Communications has a 2-year impact factor: 15.7 (2024),  5-year Journal Impact Factor: 17.2 (2024), Article downloads of 177,272,701 (2024), and 8 days (median) from submission to the first editorial decision. [...] Disclaimer   \n Nature Portfolio journals occasionally use internal Springer Nature-developed artificial intelligence tools to support the generation of accessory content, such as summary points. These are always edited and fact-checked by the author and/or editor to meet Nature Portfolio publication standards. Any substantive use of artificial intelligence beyond accessory content will be declared on an individual article basis.\n\n## Search\n\nAdvanced search\n\n### Quick links\n\n Explore articles by subject\n Find a job\n Guide to authors\n Editorial policies", "score": 0.5148644, "raw_content": null, "summary": "Publishes in all areas of life, health, social, physical, chemical and Earth sciences Presents important advances of significance to specialists within each field High visibility for your work with open access ## Aims & Scope More on the aims and scope of Nature Communications is available in this section, as well as article and journal metrics, indexing and archiving information. View all journal"}, {"url": "https://www.nature.com/ncomms/", "title": "Nature Communications", "content": "Aircraft contrails are not just streaks in clear blue skies - they represent a significant source of warming from the aviation sector. Two new studies reveal that their climate impact is more complex than previously thought, as many contrails may form within existing cirrus clouds – a factor often overlooked in past assessments. Drawing on aircraft, satellite and meteorological data, Petzold et al. and Seelig et al. provide fresh insights into the occurrence frequency and the radiative properties of these often “hidden” contrails.\n\n  + Ziming Wang\n  + Christiane Voigt\n\n  CommentOpen Access\n\n## Collections\n\n### AI and machine learning\n\nA periscope into the broad-ranging applications of machine learning and how it is enabling new research and tools, reducing inequality and increasing quality of life – with a focus on the general pursuit of laying the foundations of Artificial Intelligence.\n\nFocus\n\nAdvertisement\n\n## Trending - Altmetric [...] Skip to main content\n\n## A multisynaptic spiking neuron for simultaneously encoding spatiotemporal dynamics\n\nLiangwei Fan et al. propose a multi synaptic firing neuron, that allows to encode spatiotemporal data in neuromorphic computing more effectively.\n\n ### 50 years of weather forecasting at the ECMWF\n ### Machine learning applied to biocatalysis research\n ### A mining reality check on net zero\n\n  Projections show a massive shortfall in the supply of lithium and copper required to reach net zero emissions by 2050. We won’t run out of resources but with some mines taking decades to bring into production, we may run out of time.\n\n  EditorialOpen Access\n ### Q&A Europa Clipper mission [...] This study surveyed key informants across 26 countries on burning plastic for waste management and energy needs. It finds high awareness of this practice, with potential drivers including inadequate waste collection and a lack of affordable fuels.\n\n  + Bishal Bharadwaj\n  + Tara Gates\n  + Peta Ashworth\n\n  ArticleOpen Access\n ### Historical reconstruction of human moralization with word association and text corpora\n\n  People have moralized different concepts over history. Here, the authors show that the historical time courses of moralization can be restored computationally by combining machine learning with psychological data of word association and text corpora.\n\n  + Aida Ramezani\n  + Jennifer E. Stellar\n  + Yang Xu\n\n  ArticleOpen Access\n ### Behavioral uncertainty in EV charging drives heterogeneous grid load variability under climate goals", "score": 0.50227106, "raw_content": null, "summary": "+ Ziming Wang + Christiane Voigt CommentOpen Access ## Collections ### AI and machine learning A periscope into the broad-ranging applications of machine learning and how it is enabling new research and tools, reducing inequality and increasing quality of life – with a focus on the general pursuit of laying the foundations of Artificial Intelligence. ### 50 years of weather forecasting at the ECMW"}, {"title": "Browse Articles | Nature", "url": "https://www.nature.com/nature/articles", "content": "### Science in 2026: what to expect this year\n\nMore refined AI models, advancements in human gene editing and the continuing impact of the Trump Team on science — we run through what to look out for over the next 12 months. \n       Nick Petrić Howe\n       Miryam Naddaf\n\nNature Podcast 01 Jan 2026\n\n   \nImage 14 \n\n### A chiral fermionic valve driven by quantum geometry\n\nFermionic currents of opposing chirality can be spatially filtered without the need for a magnetic field using the quantum geometry of topological bands in single-crystal PdGa. \n       Anvesh Dixit\n       Pranava K. Sivakumar\n       Stuart S. P. Parkin\n\nArticle Open Access 31 Dec 2025\n\n   \nImage 15 \n\n### Random heteropolymers as enzyme mimics [...] Show results from \n\nSearch\n\nAdvanced search\n\n### Quick links\n\n   Explore articles by subject\n   Find a job\n   Guide to authors\n   Editorial policies\n\nNature  (_Nature_)\n\nISSN 1476-4687 (online)\n\nISSN 0028-0836 (print)\n\nnature.com sitemap\n\n### About Nature Portfolio\n\n   About us\n   Press releases\n   Press office\n   Contact us\n\n### Discover content\n\n   Journals A-Z\n   Articles by subject\n   protocols.io\n   Nature Index\n\n### Publishing policies\n\n   Nature portfolio policies\n   Open access\n\n### Author & Researcher services\n\n   Reprints & permissions\n   Research data\n   Language editing\n   Scientific editing\n   Nature Masterclasses\n   Research Solutions\n\n### Libraries & institutions\n\n   Librarian service & tools\n   Librarian portal\n   Open research\n   Recommend to library\n\n### Advertising & partnerships [...] Explore content\n\n   Research articles\n   News\n   Opinion\n   Research Analysis\n   Careers\n   Books & Culture\n   Podcasts\n   Videos\n   Current issue\n   Browse issues\n   Collections\n   Subjects\n\n   Follow us on Facebook\n   Follow us on Twitter\n   Subscribe\n   Sign up for alerts\n   RSS feed\n\nAbout the journal\n\n   Journal Staff\n   About the Editors\n   Journal Information\n   Journal Metrics\n   Our publishing models\n   Editorial Values Statement\n   Editorial policies\n   Journalistic Principles\n   History of Nature\n   Awards\n   Contact\n   Send a news tip\n\nPublish with us\n\n   For Authors\n   For Referees\n   Language editing services\n   Open access funding\n   Submit manuscript\n\nSearch\n\nSearch articles by subject, keyword or author \n\nShow results from \n\nSearch\n\nAdvanced search\n\n### Quick links", "score": 0.35575303, "raw_content": null, "summary": "Nick Petrić Howe Miryam Naddaf Nature Podcast 01 Jan 2026 Image 14 ### A chiral fermionic valve driven by quantum geometry Fermionic currents of opposing chirality can be spatially filtered without the need for a magnetic field using the quantum geometry of topological bands in single-crystal PdGa. Parkin Article Open Access 31 Dec 2025 Image 15 ### Random heteropolymers as enzyme mimics [...] Sho"}]}
{"query": "NeurIPS 2025 best papers AI trends (English)", "result": {"query": "NeurIPS 2025 best papers AI trends (English)", "follow_up_questions": null, "answer": null, "images": [], "results": [{"url": "https://intuitionlabs.ai/articles/neurips-2025-conference-summary-trends", "title": "NeurIPS 2025: A Guide to Key Papers, Trends & Stats | IntuitionLabs", "content": "NeurIPS (Neural Information Processing Systems) 2025 – the 39th annual meeting – represents both continuity and change in the world’s premier machine learning conference. Held December 2–7, 2025 in San Diego (with a simultaneous secondary site in Mexico City), NeurIPS 2025 attracted over 5,200 accepted papers (24.5% of ~21,575 submissions) and enormous attention from industry, academia, and media. Major trends in 2025 included an emphasis on large language and foundation models, reproducibility and data-centric research via the growing Datasets & Benchmarks Track, and explicit attention to societal impacts of AI. For the first time, NeurIPS introduced a Position Paper Track to host perspective pieces on broad AI implications, and a Journal Track featuring 34 top papers from leading journals (14 from JMLR and 20 from AoS) embedded as posters (( \"Highlights: This year, we are thrilled,enrich [...] The NeurIPS 2025 call for papers followed the traditional schedule (abstract due May 11, 2025; full papers May 15, 2025). In response, the Main Track received 21,575 valid paper submissions by the deadline (( \"Highlights: Like most AI conferences, NeurIPS,not only is a challenge\")), a roughly 61% increase over 2024. Such unprecedented volume strained resources but reflects the global surge in AI research productivity. After peer review and calibration, 5,290 papers were accepted, yielding an acceptance rate of ~24.52% (( \"Highlights: years,with the PCs manually\")). Notably, this acceptance rate is comparable to previous years (~24–25%) despite the doubled submissions, indicating the program aimed to expand capacity rather than tighten selectivity. (Program chairs explicitly noted they could have accepted more if needed; the venue size did not constrain acceptances (( \"Highlights: as our physical venues can,during [...] Subject Areas. While NeurIPS submission categories are broad (e.g. learning theory, speech, robotics, vision, etc.), the 2025 cycle showed a pronounced tilt toward generative and foundation models, large-scale machine learning, and interdisciplinary applications. For example, many accepted papers focused on language models, multimodal AI, reinforcement learning, and real-world deployment issues. This aligns with invited talk themes (see Section 5). The Datasets track reported that 84% of accepted datasets introduced new successor benchmarks (rather than repackaging old tasks), often linked to LLM evaluation or science domains (( \"Highlights: The distribution of accepted papers,applications and socially beneficial AI\")).\n\n## 3.2 Review Process and Responsible Practices", "score": 0.9263638, "raw_content": null, "summary": "For the first time, NeurIPS introduced a Position Paper Track to host perspective pieces on broad AI implications, and a Journal Track featuring 34 top papers from leading journals (14 from JMLR and 20 from AoS) embedded as posters (( \"Highlights: This year, we are thrilled,enrich [...] The NeurIPS 2025 call for papers followed the traditional schedule (abstract due May 11, 2025; full papers May 1"}, {"url": "https://blog.neurips.cc/2025/11/26/announcing-the-neurips-2025-best-paper-awards/", "title": "Announcing the NeurIPS 2025 Best Paper Awards", "content": "Jacob Andreas (MIT, United States)\n   Sander Dieleman (Google DeepMind, UK) \n   Dilek Hakkani-Tur (University of Illinois Urbana-Champaign, United States) \n   Brian Kingsbury (IBM, United States) \n   Mirella Lapata (University of Edinburgh, Scotland) \n   Vincent Lepetit (Ecole des Ponts ParisTech, France) \n   Ulrich Paquet (AIMES & Google DeepMind, Africa) \n   Violet Peng (UCLA, United States) \n   Doina Precup (McGill University, Canada) \n   Masashi Sugiyama (RIKEN & University of Tokyo, Japan) \n   Vincent Tan (National University of Singapore, Singapore) \n   Yee Whye Teh (University of Oxford, United Kingdom) \n   Xing Xie (Microsoft, China) [...] With that, we are excited to share the news that the best and runner-up paper awards this year go to seven groundbreaking papers, including four best papers (one of which is from the datasets and benchmarks track) and three runner-ups. The seven papers highlight advances in diffusion model theory, self-supervised reinforcement learning, attention mechanisms for large language models, reasoning capabilities in LLMs, online learning theory, neural scaling laws, and benchmarking methodologies for language model diversity.\n\nThe winners are presented here in alphabetical order by title.\n\nArtificial Hivemind: The Open-Ended Homogeneity of Language Models (and Beyond)\n\nLiwei Jiang, Yuanjun Chai, Margaret Li, Mickel Liu, Raymond Fok, Nouha Dziri, Yulia Tsvetkov, Maarten Sap, Yejin Choi\n\nAbstract [...] Gated Attention for Large Language Models: Non-linearity, Sparsity, and Attention-Sink-Free\n\n### Zihan Qiu,Zekun Wang,Bo Zheng,Zeyu Huang,Kaiyue Wen,Songlin Yang,Rui Men,Le Yu,Fei Huang,Suozhi Huang,Dayiheng Liu,Jingren Zhou,Junyang Lin\n\nAbstract", "score": 0.90102744, "raw_content": null, "summary": "Jacob Andreas (MIT, United States) Sander Dieleman (Google DeepMind, UK) Dilek Hakkani-Tur (University of Illinois Urbana-Champaign, United States) Brian Kingsbury (IBM, United States) Mirella Lapata (University of Edinburgh, Scotland) Vincent Lepetit (Ecole des Ponts ParisTech, France) Ulrich Paquet (AIMES & Google DeepMind, Africa) Violet Peng (UCLA, United States) Doina Precup (McGill Universit"}, {"url": "https://siebelschool.illinois.edu/news/llinois-ai-research-neurips-2025", "title": "Illinois AI research among the top five most-published at NeurIPS 2025", "content": "|  |  |  |\n --- \n| 1 | Improving Data Efficiency for LLM Reinforcement Fine-tuning Through Difficulty-targeted Online Data Selection and Rollout Replay Yifan Sun, Huan Zhang | LLM |\n| 2 | AlphaOne: Reasoning Models Thinking Slow and Fast at Test Time (\\workshop paper) Junyu Zhang, Han Wang, Huan Zhang | LLM |\n| 3 | RAST: Reasoning Activation in LLMs via Small-model Transfer Siru Ouyang, Xinyu Zhu, Zilin Xiao, Minhao Jiang, Yu Meng, Jiawei Han | LLM |\n| 4 | When Reasoning Meets Its Laws (\\workshop paper) Junyu Zhang, Yifan Sun, Huan Zhang | LLM | [...] | 28 | One Token per Highly Selective Frame: Towards Extreme Compression for Long Video UnderstandingZheyu Zhang, Ziqi Pang, Yuxiong Wang | Vision |\n| 29 | DiffEye: Diffusion-Based Continuous Eye-Tracking Data Generation Conditioned on Natural Images Ozgur Kara, Harris Nisar,  James M. Rehg | Vision, Generative |\n| 30 | DMol: A Schedule-Driven Diffusion Model for Highly Efficient and Versatile Molecule Generation Peizhi Niu, Shane Wang, Olgica Milenkovic | Generative |\n| 31 | FalconWing: An Ultra-Light Fixed-Wing Platform for Indoor Aerial Applications Yan Miao, Will Shen, Hang Cui, Sayan Mitra (workshop paper) | Vision | [...] | 24 | HoloScene: Simulation-Ready Interactive 3D Worlds from a Single Video Hongchi Xia, Chih-Hao Lin, Hao-Yu Hsu, Quentin Leboutet, Katelyn Gao, Michael Paulitsch, Benjamin Ummenhofer, Shenlong Wang | Vision |\n| 25 | MR. Video: MapReduce as an Effective Principle for Long Video Understanding Ziqi Pang, Yuxiong Wang | Vision |\n| 26 | RGB-Only Supervised Camera Parameter Optimization in Dynamic ScenesFang Li, Hao Zhang, Narendra Ahuja | Vision |\n| 27 | Virtual Fitting Room: Generating Arbitrarily Long Videos of Virtual Try-On from a Single Image Junkun Chen, Yuxiong Wang | Vision |", "score": 0.84707206, "raw_content": null, "summary": "| | | | --- | 1 | Improving Data Efficiency for LLM Reinforcement Fine-tuning Through Difficulty-targeted Online Data Selection and Rollout Replay Yifan Sun, Huan Zhang | LLM | | 2 | AlphaOne: Reasoning Models Thinking Slow and Fast at Test Time (\\workshop paper) Junyu Zhang, Han Wang, Huan Zhang | LLM | | 3 | RAST: Reasoning Activation in LLMs via Small-model Transfer Siru Ouyang, Xinyu Zhu, Zili"}, {"url": "https://litslink.com/blog/best-research-papers-on-ai-at-neurips-2025", "title": "Best research papers on AI at NeurIPS 2025 - Litslink", "content": "## 4. 1000 Layer Networks for Self-Supervised RL: Scaling Depth Can Enable New Goal-Reaching Capabilities\n\n| Category | Details |\n| Award | Outstanding Paper Award Runner-Up |\n| Authors | Kevin Wang, Ishaan Javali, Michał Bortkiewicz, Tomasz Trzciński, Benjamin Eysenbach |\n| Affiliation | Princeton University / University of Warsaw |\n| Country | USA / Poland |\n| Resources | Read Paper • Project Page |\n\nSecuring a Runner-Up position in the list of the latest research papers in AI, this work challenges the conventional wisdom of neural network architecture. The researchers successfully trained networks with an astounding 1000 layers.\n\nThe technical breakthrough here lies in how depth affects “temporal abstraction.” Shallow networks struggle to plan far into the future because the signal gets lost. A 1000-layer network, however, develops a hierarchical understanding of time and tasks. [...] | Category | Details |\n| Award | Outstanding Paper Award Runner-Up |\n| Authors | Yang Yue · Zhiqi Chen · Rui Lu · Andrew Zhao · Zhaokai Wang · Yang Yue · Shiji Song · Gao Huang |\n| Affiliation | LeapLab, Tsinghua University |\n| Country | China |\n| Resources | Read Paper • Project Page |\n\nThis is one of the most discussed research paper topics on artificial intelligence this year. It addresses a practical question: Does Reinforcement Learning from Human Feedback (RLHF) make models smarter? [...] ## 5. Optimal Mistake Bounds for Transductive Online Learning\n\n| Category | Details |\n| Award | Outstanding Paper Award (Main Winner) |\n| Authors | Zachary Chase, Steve Hanneke, Shay Moran, Jonathan Shafer |\n| Affiliation | Technion / Purdue University / UC Berkeley |\n| Country | Israel / USA |\n| Resources | Read Paper |\n\nThis paper took home the top prize—the Outstanding Paper Award. It is a theoretical masterpiece that addresses reliability in learning systems. The paper focuses on Transductive Online Learning, where the AI sees questions but not answers beforehand, and must learn from its errors instantly.\n\nThe authors derive a mathematical proof establishing the absolute limit of mistakes an algorithm must make. This moves AI from “empirical alchemy” to a rigorous science. By establishing the “Optimal Mistake Bound,” the paper provides a yardstick for performance.\n\nWhy This Matters for FinTech and Cybersecurity:", "score": 0.8440111, "raw_content": null, "summary": "1000 Layer Networks for Self-Supervised RL: Scaling Depth Can Enable New Goal-Reaching Capabilities | Category | Details | | Award | Outstanding Paper Award Runner-Up | | Authors | Kevin Wang, Ishaan Javali, Michał Bortkiewicz, Tomasz Trzciński, Benjamin Eysenbach | | Affiliation | Princeton University / University of Warsaw | | Country | USA / Poland | | Resources | Read Paper • Project Page | Se"}, {"url": "https://www.theneuron.ai/explainer-articles/the-best-papers-at-neurips-2025-explained", "title": "The Best Papers at NeurIPS 2025, Explained - The Neuron", "content": "Home\n\n/\n\nArticles\n\n/\n\nThe Best Papers at NeurIPS 2025, Explained\n\n# The Best Papers at NeurIPS 2025, Explained\n\nNeurIPS Just Crowned the Year's Best AI Research (And You Can Actually Understand It)\n\nGrant Harvey\n\nDecember 5, 2025\n\nwww.theneuron.ai/newsletter/\n\nDecember 5, 2025\n\nEver wonder which AI breakthroughs researchers actually think matter? The machine learning Olympics just wrapped up, and the winners are addressing the questions keeping AI scientists up at night.\n\nNeurIPS, short for Neural Information Processing Systems, is basically the Oscars of AI research. Every December, thousands of researchers gather to share cutting-edge work. Getting a paper accepted here is tough. Winning Best Paper? That's career-defining.", "score": 0.8380581, "raw_content": null, "summary": "Home / Articles / The Best Papers at NeurIPS 2025, Explained # The Best Papers at NeurIPS 2025, Explained NeurIPS Just Crowned the Year's Best AI Research (And You Can Actually Understand It) Grant Harvey December 5, 2025 www.theneuron.ai/newsletter/ December 5, 2025 Ever wonder which AI breakthroughs researchers actually think matter? The machine learning Olympics just wrapped up, and the winners"}], "response_time": 1.66, "request_id": "5a526c1e-7467-49a2-9ef6-8b14c0ea251e"}, "query_summary": "For the first time, NeurIPS introduced a Position Paper Track to host perspective pieces on broad AI implications, and a Journal Track featuring 34 top papers from leading journals (14 from JMLR and 20 from AoS) embedded as posters (( \"Highlights: This year, we are thrilled,enrich [...] The NeurIPS 2025 call for papers followed the traditional schedule (abstract due May 11, 2025; full papers May 1 Jacob Andreas (MIT, United States) Sander Dieleman (Google DeepMind, UK) Dilek Hakkani-Tur (University of Illinois Urbana-Champaign, United States) Brian Kingsbury (IBM, United States) Mirella Lapata", "lang_pref": "en", "preferred_results": [{"url": "https://intuitionlabs.ai/articles/neurips-2025-conference-summary-trends", "title": "NeurIPS 2025: A Guide to Key Papers, Trends & Stats | IntuitionLabs", "content": "NeurIPS (Neural Information Processing Systems) 2025 – the 39th annual meeting – represents both continuity and change in the world’s premier machine learning conference. Held December 2–7, 2025 in San Diego (with a simultaneous secondary site in Mexico City), NeurIPS 2025 attracted over 5,200 accepted papers (24.5% of ~21,575 submissions) and enormous attention from industry, academia, and media. Major trends in 2025 included an emphasis on large language and foundation models, reproducibility and data-centric research via the growing Datasets & Benchmarks Track, and explicit attention to societal impacts of AI. For the first time, NeurIPS introduced a Position Paper Track to host perspective pieces on broad AI implications, and a Journal Track featuring 34 top papers from leading journals (14 from JMLR and 20 from AoS) embedded as posters (( \"Highlights: This year, we are thrilled,enrich [...] The NeurIPS 2025 call for papers followed the traditional schedule (abstract due May 11, 2025; full papers May 15, 2025). In response, the Main Track received 21,575 valid paper submissions by the deadline (( \"Highlights: Like most AI conferences, NeurIPS,not only is a challenge\")), a roughly 61% increase over 2024. Such unprecedented volume strained resources but reflects the global surge in AI research productivity. After peer review and calibration, 5,290 papers were accepted, yielding an acceptance rate of ~24.52% (( \"Highlights: years,with the PCs manually\")). Notably, this acceptance rate is comparable to previous years (~24–25%) despite the doubled submissions, indicating the program aimed to expand capacity rather than tighten selectivity. (Program chairs explicitly noted they could have accepted more if needed; the venue size did not constrain acceptances (( \"Highlights: as our physical venues can,during [...] Subject Areas. While NeurIPS submission categories are broad (e.g. learning theory, speech, robotics, vision, etc.), the 2025 cycle showed a pronounced tilt toward generative and foundation models, large-scale machine learning, and interdisciplinary applications. For example, many accepted papers focused on language models, multimodal AI, reinforcement learning, and real-world deployment issues. This aligns with invited talk themes (see Section 5). The Datasets track reported that 84% of accepted datasets introduced new successor benchmarks (rather than repackaging old tasks), often linked to LLM evaluation or science domains (( \"Highlights: The distribution of accepted papers,applications and socially beneficial AI\")).\n\n## 3.2 Review Process and Responsible Practices", "score": 0.9263638, "raw_content": null, "summary": "For the first time, NeurIPS introduced a Position Paper Track to host perspective pieces on broad AI implications, and a Journal Track featuring 34 top papers from leading journals (14 from JMLR and 20 from AoS) embedded as posters (( \"Highlights: This year, we are thrilled,enrich [...] The NeurIPS 2025 call for papers followed the traditional schedule (abstract due May 11, 2025; full papers May 1"}, {"url": "https://blog.neurips.cc/2025/11/26/announcing-the-neurips-2025-best-paper-awards/", "title": "Announcing the NeurIPS 2025 Best Paper Awards", "content": "Jacob Andreas (MIT, United States)\n   Sander Dieleman (Google DeepMind, UK) \n   Dilek Hakkani-Tur (University of Illinois Urbana-Champaign, United States) \n   Brian Kingsbury (IBM, United States) \n   Mirella Lapata (University of Edinburgh, Scotland) \n   Vincent Lepetit (Ecole des Ponts ParisTech, France) \n   Ulrich Paquet (AIMES & Google DeepMind, Africa) \n   Violet Peng (UCLA, United States) \n   Doina Precup (McGill University, Canada) \n   Masashi Sugiyama (RIKEN & University of Tokyo, Japan) \n   Vincent Tan (National University of Singapore, Singapore) \n   Yee Whye Teh (University of Oxford, United Kingdom) \n   Xing Xie (Microsoft, China) [...] With that, we are excited to share the news that the best and runner-up paper awards this year go to seven groundbreaking papers, including four best papers (one of which is from the datasets and benchmarks track) and three runner-ups. The seven papers highlight advances in diffusion model theory, self-supervised reinforcement learning, attention mechanisms for large language models, reasoning capabilities in LLMs, online learning theory, neural scaling laws, and benchmarking methodologies for language model diversity.\n\nThe winners are presented here in alphabetical order by title.\n\nArtificial Hivemind: The Open-Ended Homogeneity of Language Models (and Beyond)\n\nLiwei Jiang, Yuanjun Chai, Margaret Li, Mickel Liu, Raymond Fok, Nouha Dziri, Yulia Tsvetkov, Maarten Sap, Yejin Choi\n\nAbstract [...] Gated Attention for Large Language Models: Non-linearity, Sparsity, and Attention-Sink-Free\n\n### Zihan Qiu,Zekun Wang,Bo Zheng,Zeyu Huang,Kaiyue Wen,Songlin Yang,Rui Men,Le Yu,Fei Huang,Suozhi Huang,Dayiheng Liu,Jingren Zhou,Junyang Lin\n\nAbstract", "score": 0.90102744, "raw_content": null, "summary": "Jacob Andreas (MIT, United States) Sander Dieleman (Google DeepMind, UK) Dilek Hakkani-Tur (University of Illinois Urbana-Champaign, United States) Brian Kingsbury (IBM, United States) Mirella Lapata (University of Edinburgh, Scotland) Vincent Lepetit (Ecole des Ponts ParisTech, France) Ulrich Paquet (AIMES & Google DeepMind, Africa) Violet Peng (UCLA, United States) Doina Precup (McGill Universit"}, {"url": "https://siebelschool.illinois.edu/news/llinois-ai-research-neurips-2025", "title": "Illinois AI research among the top five most-published at NeurIPS 2025", "content": "|  |  |  |\n --- \n| 1 | Improving Data Efficiency for LLM Reinforcement Fine-tuning Through Difficulty-targeted Online Data Selection and Rollout Replay Yifan Sun, Huan Zhang | LLM |\n| 2 | AlphaOne: Reasoning Models Thinking Slow and Fast at Test Time (\\workshop paper) Junyu Zhang, Han Wang, Huan Zhang | LLM |\n| 3 | RAST: Reasoning Activation in LLMs via Small-model Transfer Siru Ouyang, Xinyu Zhu, Zilin Xiao, Minhao Jiang, Yu Meng, Jiawei Han | LLM |\n| 4 | When Reasoning Meets Its Laws (\\workshop paper) Junyu Zhang, Yifan Sun, Huan Zhang | LLM | [...] | 28 | One Token per Highly Selective Frame: Towards Extreme Compression for Long Video UnderstandingZheyu Zhang, Ziqi Pang, Yuxiong Wang | Vision |\n| 29 | DiffEye: Diffusion-Based Continuous Eye-Tracking Data Generation Conditioned on Natural Images Ozgur Kara, Harris Nisar,  James M. Rehg | Vision, Generative |\n| 30 | DMol: A Schedule-Driven Diffusion Model for Highly Efficient and Versatile Molecule Generation Peizhi Niu, Shane Wang, Olgica Milenkovic | Generative |\n| 31 | FalconWing: An Ultra-Light Fixed-Wing Platform for Indoor Aerial Applications Yan Miao, Will Shen, Hang Cui, Sayan Mitra (workshop paper) | Vision | [...] | 24 | HoloScene: Simulation-Ready Interactive 3D Worlds from a Single Video Hongchi Xia, Chih-Hao Lin, Hao-Yu Hsu, Quentin Leboutet, Katelyn Gao, Michael Paulitsch, Benjamin Ummenhofer, Shenlong Wang | Vision |\n| 25 | MR. Video: MapReduce as an Effective Principle for Long Video Understanding Ziqi Pang, Yuxiong Wang | Vision |\n| 26 | RGB-Only Supervised Camera Parameter Optimization in Dynamic ScenesFang Li, Hao Zhang, Narendra Ahuja | Vision |\n| 27 | Virtual Fitting Room: Generating Arbitrarily Long Videos of Virtual Try-On from a Single Image Junkun Chen, Yuxiong Wang | Vision |", "score": 0.84707206, "raw_content": null, "summary": "| | | | --- | 1 | Improving Data Efficiency for LLM Reinforcement Fine-tuning Through Difficulty-targeted Online Data Selection and Rollout Replay Yifan Sun, Huan Zhang | LLM | | 2 | AlphaOne: Reasoning Models Thinking Slow and Fast at Test Time (\\workshop paper) Junyu Zhang, Han Wang, Huan Zhang | LLM | | 3 | RAST: Reasoning Activation in LLMs via Small-model Transfer Siru Ouyang, Xinyu Zhu, Zili"}, {"url": "https://litslink.com/blog/best-research-papers-on-ai-at-neurips-2025", "title": "Best research papers on AI at NeurIPS 2025 - Litslink", "content": "## 4. 1000 Layer Networks for Self-Supervised RL: Scaling Depth Can Enable New Goal-Reaching Capabilities\n\n| Category | Details |\n| Award | Outstanding Paper Award Runner-Up |\n| Authors | Kevin Wang, Ishaan Javali, Michał Bortkiewicz, Tomasz Trzciński, Benjamin Eysenbach |\n| Affiliation | Princeton University / University of Warsaw |\n| Country | USA / Poland |\n| Resources | Read Paper • Project Page |\n\nSecuring a Runner-Up position in the list of the latest research papers in AI, this work challenges the conventional wisdom of neural network architecture. The researchers successfully trained networks with an astounding 1000 layers.\n\nThe technical breakthrough here lies in how depth affects “temporal abstraction.” Shallow networks struggle to plan far into the future because the signal gets lost. A 1000-layer network, however, develops a hierarchical understanding of time and tasks. [...] | Category | Details |\n| Award | Outstanding Paper Award Runner-Up |\n| Authors | Yang Yue · Zhiqi Chen · Rui Lu · Andrew Zhao · Zhaokai Wang · Yang Yue · Shiji Song · Gao Huang |\n| Affiliation | LeapLab, Tsinghua University |\n| Country | China |\n| Resources | Read Paper • Project Page |\n\nThis is one of the most discussed research paper topics on artificial intelligence this year. It addresses a practical question: Does Reinforcement Learning from Human Feedback (RLHF) make models smarter? [...] ## 5. Optimal Mistake Bounds for Transductive Online Learning\n\n| Category | Details |\n| Award | Outstanding Paper Award (Main Winner) |\n| Authors | Zachary Chase, Steve Hanneke, Shay Moran, Jonathan Shafer |\n| Affiliation | Technion / Purdue University / UC Berkeley |\n| Country | Israel / USA |\n| Resources | Read Paper |\n\nThis paper took home the top prize—the Outstanding Paper Award. It is a theoretical masterpiece that addresses reliability in learning systems. The paper focuses on Transductive Online Learning, where the AI sees questions but not answers beforehand, and must learn from its errors instantly.\n\nThe authors derive a mathematical proof establishing the absolute limit of mistakes an algorithm must make. This moves AI from “empirical alchemy” to a rigorous science. By establishing the “Optimal Mistake Bound,” the paper provides a yardstick for performance.\n\nWhy This Matters for FinTech and Cybersecurity:", "score": 0.8440111, "raw_content": null, "summary": "1000 Layer Networks for Self-Supervised RL: Scaling Depth Can Enable New Goal-Reaching Capabilities | Category | Details | | Award | Outstanding Paper Award Runner-Up | | Authors | Kevin Wang, Ishaan Javali, Michał Bortkiewicz, Tomasz Trzciński, Benjamin Eysenbach | | Affiliation | Princeton University / University of Warsaw | | Country | USA / Poland | | Resources | Read Paper • Project Page | Se"}, {"url": "https://www.theneuron.ai/explainer-articles/the-best-papers-at-neurips-2025-explained", "title": "The Best Papers at NeurIPS 2025, Explained - The Neuron", "content": "Home\n\n/\n\nArticles\n\n/\n\nThe Best Papers at NeurIPS 2025, Explained\n\n# The Best Papers at NeurIPS 2025, Explained\n\nNeurIPS Just Crowned the Year's Best AI Research (And You Can Actually Understand It)\n\nGrant Harvey\n\nDecember 5, 2025\n\nwww.theneuron.ai/newsletter/\n\nDecember 5, 2025\n\nEver wonder which AI breakthroughs researchers actually think matter? The machine learning Olympics just wrapped up, and the winners are addressing the questions keeping AI scientists up at night.\n\nNeurIPS, short for Neural Information Processing Systems, is basically the Oscars of AI research. Every December, thousands of researchers gather to share cutting-edge work. Getting a paper accepted here is tough. Winning Best Paper? That's career-defining.", "score": 0.8380581, "raw_content": null, "summary": "Home / Articles / The Best Papers at NeurIPS 2025, Explained # The Best Papers at NeurIPS 2025, Explained NeurIPS Just Crowned the Year's Best AI Research (And You Can Actually Understand It) Grant Harvey December 5, 2025 www.theneuron.ai/newsletter/ December 5, 2025 Ever wonder which AI breakthroughs researchers actually think matter? The machine learning Olympics just wrapped up, and the winners"}]}
{"query": "ICLR 2025 agentic AI (English)", "result": {"query": "ICLR 2025 agentic AI (English)", "follow_up_questions": null, "answer": null, "images": [], "results": [{"url": "https://iclr.cc/virtual/2025/33135", "title": "Emerging Multi-AI Agent Framework for Autonomous ... - ICLR 2026", "content": "Kamer Yuksel · Hassan Sawaf\n\n2025 Poster  \n in   \nWorkshop: Towards Agentic AI for Science: Hypothesis Generation, Comprehension, Quantification, and Validation\n\nProject Page    [OpenReview]\n\n### Abstract\n\nAgentic AI systems automate complex workflows but require extensive manual tuning. This paper presents a framework for autonomously optimizing Agentic AI solutions across industries, such as NLG-driven enterprise applications. It employs agents for Refinement, Execution, Evaluation, Modification, and Documentation, using iterative feedback loops powered by an LLM (Llama 3.2-3B). The system optimizes configurations without human input by autonomously generating and testing hypotheses, enhancing scalability and adaptability. Case studies demonstrate a significant boost in output quality, relevance, and actionability. Data, including original and evolved agent codes and outputs, are open-sourced.\n\n### Video\n\nChat is not available.\n\nSuccessful Page Load [...] Skip to yearly menu bar\n\n## Main Navigation\n\n ICLR \n  + Help/FAQ  \n\n  + Contact ICLR  \n\n  + Downloads  \n\n  + ICLR Blog  \n\n  + Code of Conduct  \n\n  + Privacy Policy  \n\n  + Create Profile  \n\n  + Reset Password  \n\n  + Journal To Conference Track  \n\n  + Diversity & Inclusion  \n\n  + Proceedings at OpenReview  \n\n  + Future Meetings  \n\n  + Press  \n\n  + Exhibitor Information  \n\n  + ICLR Twitter  \n\n  + About ICLR\n My Stuff\n\n Login\n\nPoster  \n in   \nWorkshop: Towards Agentic AI for Science: Hypothesis Generation, Comprehension, Quantification, and Validation\n\n# Emerging Multi-AI Agent Framework for Autonomous Agentic AI Solution Optimization\n\nKamer Yuksel · Hassan Sawaf", "score": 0.8259413, "raw_content": null, "summary": "Kamer Yuksel · Hassan Sawaf 2025 Poster in Workshop: Towards Agentic AI for Science: Hypothesis Generation, Comprehension, Quantification, and Validation Project Page [OpenReview] ### Abstract Agentic AI systems automate complex workflows but require extensive manual tuning. Successful Page Load [...] Skip to yearly menu bar ## Main Navigation ICLR + Help/FAQ + Contact ICLR + Downloads + ICLR Blog"}, {"url": "https://openreview.net/submissions?page=2&venue=ICLR.cc%2F2025%2FWorkshop%2FAgenticAI", "title": "ICLR 2025 Workshop AgenticAI Submissions", "content": "Back to ICLR\n\n# ICLR 2025 Workshop AgenticAISubmissions\n\n #### Large Language Models Are Innate Crystal Structure Generators\n\n  Jingru Gan, Peichen Zhong, Yuanqi Du, Yanqiao Zhu, Chenru Duan, Haorui Wang, Daniel Schwalbe-Koda, Carla P Gomes, Kristin Persson, Wei Wang\n\n  + Published: 05 Mar 2025, Last Modified: 28 Mar 2025\n  + ICLR 2025 Workshop AgenticAI Oral\n  + Readers: Everyone\n #### MOOSE-Chem: Large Language Models for Rediscovering Unseen Chemistry Scientific Hypotheses\n\n  Zonglin Yang, Wanhao Liu, Ben Gao, Tong Xie, Yuqiang Li, Wanli Ouyang, Soujanya Poria, Erik Cambria, Dongzhan Zhou [...] Kamer Ali Yuksel, Hassan Sawaf\n\n  + Published: 05 Mar 2025, Last Modified: 28 Mar 2025\n  + ICLR 2025 Workshop AgenticAI Poster\n  + Readers: Everyone\n #### A Simplified a priori Theory of Meaning; Nature Based AI 'First Principles'\n\n  Marcus Abundis\n\n  + Published: 05 Mar 2025, Last Modified: 28 Mar 2025\n  + ICLR 2025 Workshop AgenticAI Poster\n  + Readers: Everyone\n #### Performant LLM Agentic Framework for Conversational AI\n\n  Alex Casella, Wayne Wang\n\n  + Published: 05 Mar 2025, Last Modified: 28 Mar 2025\n  + ICLR 2025 Workshop AgenticAI Reject\n  + Readers: Everyone [...] + Published: 05 Mar 2025, Last Modified: 28 Mar 2025\n  + ICLR 2025 Workshop AgenticAI Oral\n  + Readers: Everyone\n #### Sara: Screening Agents for Rheumatoid Arthritis\n\n  Umakanta Maharana, Sarthak Verma, Avarna Agarwal, Prakashini Mruthyunjaya, Sakir Ahmed, Murari Mandal\n\n  + Published: 05 Mar 2025, Last Modified: 28 Mar 2025\n  + ICLR 2025 Workshop AgenticAI Reject\n  + Readers: Everyone\n #### Emerging Multi-AI Agent Framework for Autonomous Agentic AI Solution Optimization\n\n  Kamer Ali Yuksel, Hassan Sawaf", "score": 0.769098, "raw_content": null, "summary": "Back to ICLR # ICLR 2025 Workshop AgenticAISubmissions #### Large Language Models Are Innate Crystal Structure Generators Jingru Gan, Peichen Zhong, Yuanqi Du, Yanqiao Zhu, Chenru Duan, Haorui Wang, Daniel Schwalbe-Koda, Carla P Gomes, Kristin Persson, Wei Wang + Published: 05 Mar 2025, Last Modified: 28 Mar 2025 + ICLR 2025 Workshop AgenticAI Oral + Readers: Everyone #### MOOSE-Chem: Large Langua"}, {"url": "https://iclr.cc/virtual/2025/33140", "title": "Automated Machine Learning Research via Agentic Exploration with ...", "content": "Shervin Ardeshir · Navid Azizan\n\n2025 Poster  \n in   \nWorkshop: Towards Agentic AI for Science: Hypothesis Generation, Comprehension, Quantification, and Validation\n\nProject Page    [OpenReview]\n\n### Abstract\n\nThis paper proposes a scalable approach to automated incremental machine learning research that integrates agentic exploration (autonomous hypothesis generation) with human oversight (human-verified evaluation) to ensure accountability.Our framework systematically generates novel neural network components, validates their feasibility, evaluates performance against established baselines, and conducts an autogenerated meta-analysis to uncover common patterns of success across the proposed components, and explain them in natural language. We also investigate training a reward model capable of identifying successful patterns within the abstract embedding space, which can be used to prioritize more promising hypotheses pre-evaluation, thus improving hypothesis generation efficiency.\n\n### Video\n\nChat is not available.\n\nSuccessful Page Load [...] Skip to yearly menu bar\n\n## Main Navigation\n\n ICLR \n  + Help/FAQ  \n\n  + Contact ICLR  \n\n  + Downloads  \n\n  + ICLR Blog  \n\n  + Code of Conduct  \n\n  + Privacy Policy  \n\n  + Create Profile  \n\n  + Reset Password  \n\n  + Journal To Conference Track  \n\n  + Diversity & Inclusion  \n\n  + Proceedings at OpenReview  \n\n  + Future Meetings  \n\n  + Press  \n\n  + Exhibitor Information  \n\n  + ICLR Twitter  \n\n  + About ICLR\n My Stuff\n\n Login\n\nPoster  \n in   \nWorkshop: Towards Agentic AI for Science: Hypothesis Generation, Comprehension, Quantification, and Validation\n\n# Automated Machine Learning Research via Agentic Exploration with Human Oversight\n\nShervin Ardeshir · Navid Azizan", "score": 0.7382357, "raw_content": null, "summary": "Shervin Ardeshir · Navid Azizan 2025 Poster in Workshop: Towards Agentic AI for Science: Hypothesis Generation, Comprehension, Quantification, and Validation Project Page [OpenReview] ### Abstract This paper proposes a scalable approach to automated incremental machine learning research that integrates agentic exploration (autonomous hypothesis generation) with human oversight (human-verified eval"}, {"url": "https://github.com/Kaiwen-Zhu/AgenticIR", "title": "Kaiwen-Zhu/AgenticIR: [ICLR 2025] An Intelligent Agentic System for ...", "content": "To let the agent learn from exploration, run\n\n `python -m exploration.exhaust_seq` to generate images to explore;\n `python -m exploration.explore` to accumulate experience by evaluating images;\n `python -m exploration.distill` to summarize the experience and distill knowledge.\n\nRun `python -m pipeline.infer` to restore an image (path specified in `pipeline/infer.py`).\n\n```\n@inproceedings{agenticir, title={An Intelligent Agentic System for Complex Image Restoration Problems}, author={Kaiwen Zhu and Jinjin Gu and Zhiyuan You and Yu Qiao and Chao Dong}, booktitle={The Thirteenth International Conference on Learning Representations}, year={2025}, url={ } \n```\n\n## About\n\n[ICLR 2025] An Intelligent Agentic System for Complex Image Restoration Problems\n\n### Topics\n\nagent   image-restoration   iclr   low-level-vision\n\n### Resources [...] # An Intelligent Agentic System for Complex Image Restoration Problems\n\nKaiwen Zhu\\, Jinjin Gu\\, Zhiyuan You, Yu Qiao, Chao Dong\n\nICLR 2025\n\nPaper | Project Page\n\n## Overview\n\n### Learning from exploration\n\n### Workflow\n\n## Examples\n\n### Restoration of real-world images\n\nRestore a UDC image (from this work) by motion deblurring, defocus deblurring, and low light enhancement.\n\nRestore an underwater image (from this work) by defocus deblurring, dehazing, and motion deblurring.\n\n### Effectiveness of planning with experience\n\n### Effectiveness of workflow designs\n\n## Installation\n\nPlease refer to INSTALL.md.\n\n## Usage\n\n### Fine-tuning DepictQA\n\nPlease refer to this.\n\n### Setup [...] BranchesTags\n\nOpen more actions menu\n\n## Folders and files\n\n| Name | Name | Last commit message | Last commit date |\n ---  --- |\n| Latest commit   History19 Commits |\n| assets | assets |  |  |\n| dataset | dataset |  |  |\n| eval | eval |  |  |\n| executor | executor |  |  |\n| exploration | exploration |  |  |\n| installation | installation |  |  |\n| llm | llm |  |  |\n| memory | memory |  |  |\n| pipeline | pipeline |  |  |\n| test\\_tool | test\\_tool |  |  |\n| utils | utils |  |  |\n| README.md | README.md |  |  |\n| config.yml | config.yml |  |  |\n|  |\n\n## Repository files navigation\n\n# An Intelligent Agentic System for Complex Image Restoration Problems", "score": 0.7067782, "raw_content": null, "summary": "``` @inproceedings{agenticir, title={An Intelligent Agentic System for Complex Image Restoration Problems}, author={Kaiwen Zhu and Jinjin Gu and Zhiyuan You and Yu Qiao and Chao Dong}, booktitle={The Thirteenth International Conference on Learning Representations}, year={2025}, url={ } ``` ## About [ICLR 2025] An Intelligent Agentic System for Complex Image Restoration Problems ### Topics agent im"}, {"url": "https://proceedings.iclr.cc/paper_files/paper/2025/file/36b7acf6f6010652b3f2a433774a66fe-Paper-Conference.pdf", "title": "[PDF] AUTOMATED DESIGN OF AGENTIC SYSTEMS - ICLR Proceedings", "content": "We first demonstrate how Meta Agent Search discovers novel agentic systems and outperforms ex-isting state-of-the-art hand-designed agents in the Abstraction and Reasoning Corpus (ARC) chal-lenge (Chollet, 2019). This challenge aims to evaluate the general intelligence of AI systems through their ability to acquire new skills. Questions in ARC include (1) showing multiple examples of vi-sual input-output grid patterns, (2) the AI system learning the transformation rule of grid patterns from examples, and (3) predicting the output grid pattern given a test input grid pattern. Since each question in ARC has a unique transformation rule, it requires the AI system to learn efficiently with few-shot examples, leveraging capabilities in number counting, geometry, and topology.\n5 Published as a conference paper at ICLR 2025 Setup. [...] Noah Shinn, Federico Cassano, Ashwin Gopinath, Karthik Narasimhan, and Shunyu Yao. Reflexion: Language agents with verbal reinforcement learning. Advances in Neural Information Processing Systems, 36, 2023.\n15 Published as a conference paper at ICLR 2025 Kenneth O Stanley and Joel Lehman. Why greatness cannot be planned: The myth of the objective.\nSpringer, 2015.\nKenneth O Stanley, Jeff Clune, Joel Lehman, and Risto Miikkulainen. Designing neural networks through neuroevolution. Nature Machine Intelligence, 1(1):24–35, 2019.\nRichard S. Sutton. The bitter lesson, 2019. URL  IncIdeas/BitterLesson.html.\nRichard S Sutton and Andrew G Barto. Reinforcement learning: An introduction. MIT press, 2018. [...] Jeff Clune. Ai-gas: Ai-generating algorithms, an alternate paradigm for producing general artificial intelligence. arXiv preprint arXiv:1905.10985, 2019.\n11 Published as a conference paper at ICLR 2025 Karl Cobbe, Vineet Kosaraju, Mohammad Bavarian, Mark Chen, Heewoo Jun, Lukasz Kaiser, Matthias Plappert, Jerry Tworek, Jacob Hilton, Reiichiro Nakano, et al. Training verifiers to solve math word problems. arXiv preprint arXiv:2110.14168, 2021.\nAntoine Cully and Yiannis Demiris. Quality and diversity optimization: A unifying modular frame-work. IEEE Transactions on Evolutionary Computation, 22(2):245–259, 2017.", "score": 0.7016523, "raw_content": null, "summary": "We first demonstrate how Meta Agent Search discovers novel agentic systems and outperforms ex-isting state-of-the-art hand-designed agents in the Abstraction and Reasoning Corpus (ARC) chal-lenge (Chollet, 2019). Questions in ARC include (1) showing multiple examples of vi-sual input-output grid patterns, (2) the AI system learning the transformation rule of grid patterns from examples, and (3) pr"}], "response_time": 1.18, "request_id": "01088d49-d6ce-485b-a8e4-49de004211a1"}, "query_summary": "Kamer Yuksel · Hassan Sawaf 2025 Poster in Workshop: Towards Agentic AI for Science: Hypothesis Generation, Comprehension, Quantification, and Validation Project Page [OpenReview] ### Abstract Agentic AI systems automate complex workflows but require extensive manual tuning. Successful Page Load [...] Skip to yearly menu bar ## Main Navigation ICLR + Help/FAQ + Contact ICLR + Downloads + ICLR Blog Back to ICLR # ICLR 2025 Workshop AgenticAISubmissions #### Large Language Models Are Innate Crystal Structure Generators Jingru Gan, Peichen Zhong, Yuanqi Du, Yanqiao Zhu, Chenru Duan, Haorui Wang,", "lang_pref": "en", "preferred_results": [{"url": "https://iclr.cc/virtual/2025/33135", "title": "Emerging Multi-AI Agent Framework for Autonomous ... - ICLR 2026", "content": "Kamer Yuksel · Hassan Sawaf\n\n2025 Poster  \n in   \nWorkshop: Towards Agentic AI for Science: Hypothesis Generation, Comprehension, Quantification, and Validation\n\nProject Page    [OpenReview]\n\n### Abstract\n\nAgentic AI systems automate complex workflows but require extensive manual tuning. This paper presents a framework for autonomously optimizing Agentic AI solutions across industries, such as NLG-driven enterprise applications. It employs agents for Refinement, Execution, Evaluation, Modification, and Documentation, using iterative feedback loops powered by an LLM (Llama 3.2-3B). The system optimizes configurations without human input by autonomously generating and testing hypotheses, enhancing scalability and adaptability. Case studies demonstrate a significant boost in output quality, relevance, and actionability. Data, including original and evolved agent codes and outputs, are open-sourced.\n\n### Video\n\nChat is not available.\n\nSuccessful Page Load [...] Skip to yearly menu bar\n\n## Main Navigation\n\n ICLR \n  + Help/FAQ  \n\n  + Contact ICLR  \n\n  + Downloads  \n\n  + ICLR Blog  \n\n  + Code of Conduct  \n\n  + Privacy Policy  \n\n  + Create Profile  \n\n  + Reset Password  \n\n  + Journal To Conference Track  \n\n  + Diversity & Inclusion  \n\n  + Proceedings at OpenReview  \n\n  + Future Meetings  \n\n  + Press  \n\n  + Exhibitor Information  \n\n  + ICLR Twitter  \n\n  + About ICLR\n My Stuff\n\n Login\n\nPoster  \n in   \nWorkshop: Towards Agentic AI for Science: Hypothesis Generation, Comprehension, Quantification, and Validation\n\n# Emerging Multi-AI Agent Framework for Autonomous Agentic AI Solution Optimization\n\nKamer Yuksel · Hassan Sawaf", "score": 0.8259413, "raw_content": null, "summary": "Kamer Yuksel · Hassan Sawaf 2025 Poster in Workshop: Towards Agentic AI for Science: Hypothesis Generation, Comprehension, Quantification, and Validation Project Page [OpenReview] ### Abstract Agentic AI systems automate complex workflows but require extensive manual tuning. Successful Page Load [...] Skip to yearly menu bar ## Main Navigation ICLR + Help/FAQ + Contact ICLR + Downloads + ICLR Blog"}, {"url": "https://openreview.net/submissions?page=2&venue=ICLR.cc%2F2025%2FWorkshop%2FAgenticAI", "title": "ICLR 2025 Workshop AgenticAI Submissions", "content": "Back to ICLR\n\n# ICLR 2025 Workshop AgenticAISubmissions\n\n #### Large Language Models Are Innate Crystal Structure Generators\n\n  Jingru Gan, Peichen Zhong, Yuanqi Du, Yanqiao Zhu, Chenru Duan, Haorui Wang, Daniel Schwalbe-Koda, Carla P Gomes, Kristin Persson, Wei Wang\n\n  + Published: 05 Mar 2025, Last Modified: 28 Mar 2025\n  + ICLR 2025 Workshop AgenticAI Oral\n  + Readers: Everyone\n #### MOOSE-Chem: Large Language Models for Rediscovering Unseen Chemistry Scientific Hypotheses\n\n  Zonglin Yang, Wanhao Liu, Ben Gao, Tong Xie, Yuqiang Li, Wanli Ouyang, Soujanya Poria, Erik Cambria, Dongzhan Zhou [...] Kamer Ali Yuksel, Hassan Sawaf\n\n  + Published: 05 Mar 2025, Last Modified: 28 Mar 2025\n  + ICLR 2025 Workshop AgenticAI Poster\n  + Readers: Everyone\n #### A Simplified a priori Theory of Meaning; Nature Based AI 'First Principles'\n\n  Marcus Abundis\n\n  + Published: 05 Mar 2025, Last Modified: 28 Mar 2025\n  + ICLR 2025 Workshop AgenticAI Poster\n  + Readers: Everyone\n #### Performant LLM Agentic Framework for Conversational AI\n\n  Alex Casella, Wayne Wang\n\n  + Published: 05 Mar 2025, Last Modified: 28 Mar 2025\n  + ICLR 2025 Workshop AgenticAI Reject\n  + Readers: Everyone [...] + Published: 05 Mar 2025, Last Modified: 28 Mar 2025\n  + ICLR 2025 Workshop AgenticAI Oral\n  + Readers: Everyone\n #### Sara: Screening Agents for Rheumatoid Arthritis\n\n  Umakanta Maharana, Sarthak Verma, Avarna Agarwal, Prakashini Mruthyunjaya, Sakir Ahmed, Murari Mandal\n\n  + Published: 05 Mar 2025, Last Modified: 28 Mar 2025\n  + ICLR 2025 Workshop AgenticAI Reject\n  + Readers: Everyone\n #### Emerging Multi-AI Agent Framework for Autonomous Agentic AI Solution Optimization\n\n  Kamer Ali Yuksel, Hassan Sawaf", "score": 0.769098, "raw_content": null, "summary": "Back to ICLR # ICLR 2025 Workshop AgenticAISubmissions #### Large Language Models Are Innate Crystal Structure Generators Jingru Gan, Peichen Zhong, Yuanqi Du, Yanqiao Zhu, Chenru Duan, Haorui Wang, Daniel Schwalbe-Koda, Carla P Gomes, Kristin Persson, Wei Wang + Published: 05 Mar 2025, Last Modified: 28 Mar 2025 + ICLR 2025 Workshop AgenticAI Oral + Readers: Everyone #### MOOSE-Chem: Large Langua"}, {"url": "https://iclr.cc/virtual/2025/33140", "title": "Automated Machine Learning Research via Agentic Exploration with ...", "content": "Shervin Ardeshir · Navid Azizan\n\n2025 Poster  \n in   \nWorkshop: Towards Agentic AI for Science: Hypothesis Generation, Comprehension, Quantification, and Validation\n\nProject Page    [OpenReview]\n\n### Abstract\n\nThis paper proposes a scalable approach to automated incremental machine learning research that integrates agentic exploration (autonomous hypothesis generation) with human oversight (human-verified evaluation) to ensure accountability.Our framework systematically generates novel neural network components, validates their feasibility, evaluates performance against established baselines, and conducts an autogenerated meta-analysis to uncover common patterns of success across the proposed components, and explain them in natural language. We also investigate training a reward model capable of identifying successful patterns within the abstract embedding space, which can be used to prioritize more promising hypotheses pre-evaluation, thus improving hypothesis generation efficiency.\n\n### Video\n\nChat is not available.\n\nSuccessful Page Load [...] Skip to yearly menu bar\n\n## Main Navigation\n\n ICLR \n  + Help/FAQ  \n\n  + Contact ICLR  \n\n  + Downloads  \n\n  + ICLR Blog  \n\n  + Code of Conduct  \n\n  + Privacy Policy  \n\n  + Create Profile  \n\n  + Reset Password  \n\n  + Journal To Conference Track  \n\n  + Diversity & Inclusion  \n\n  + Proceedings at OpenReview  \n\n  + Future Meetings  \n\n  + Press  \n\n  + Exhibitor Information  \n\n  + ICLR Twitter  \n\n  + About ICLR\n My Stuff\n\n Login\n\nPoster  \n in   \nWorkshop: Towards Agentic AI for Science: Hypothesis Generation, Comprehension, Quantification, and Validation\n\n# Automated Machine Learning Research via Agentic Exploration with Human Oversight\n\nShervin Ardeshir · Navid Azizan", "score": 0.7382357, "raw_content": null, "summary": "Shervin Ardeshir · Navid Azizan 2025 Poster in Workshop: Towards Agentic AI for Science: Hypothesis Generation, Comprehension, Quantification, and Validation Project Page [OpenReview] ### Abstract This paper proposes a scalable approach to automated incremental machine learning research that integrates agentic exploration (autonomous hypothesis generation) with human oversight (human-verified eval"}, {"url": "https://github.com/Kaiwen-Zhu/AgenticIR", "title": "Kaiwen-Zhu/AgenticIR: [ICLR 2025] An Intelligent Agentic System for ...", "content": "To let the agent learn from exploration, run\n\n `python -m exploration.exhaust_seq` to generate images to explore;\n `python -m exploration.explore` to accumulate experience by evaluating images;\n `python -m exploration.distill` to summarize the experience and distill knowledge.\n\nRun `python -m pipeline.infer` to restore an image (path specified in `pipeline/infer.py`).\n\n```\n@inproceedings{agenticir, title={An Intelligent Agentic System for Complex Image Restoration Problems}, author={Kaiwen Zhu and Jinjin Gu and Zhiyuan You and Yu Qiao and Chao Dong}, booktitle={The Thirteenth International Conference on Learning Representations}, year={2025}, url={ } \n```\n\n## About\n\n[ICLR 2025] An Intelligent Agentic System for Complex Image Restoration Problems\n\n### Topics\n\nagent   image-restoration   iclr   low-level-vision\n\n### Resources [...] # An Intelligent Agentic System for Complex Image Restoration Problems\n\nKaiwen Zhu\\, Jinjin Gu\\, Zhiyuan You, Yu Qiao, Chao Dong\n\nICLR 2025\n\nPaper | Project Page\n\n## Overview\n\n### Learning from exploration\n\n### Workflow\n\n## Examples\n\n### Restoration of real-world images\n\nRestore a UDC image (from this work) by motion deblurring, defocus deblurring, and low light enhancement.\n\nRestore an underwater image (from this work) by defocus deblurring, dehazing, and motion deblurring.\n\n### Effectiveness of planning with experience\n\n### Effectiveness of workflow designs\n\n## Installation\n\nPlease refer to INSTALL.md.\n\n## Usage\n\n### Fine-tuning DepictQA\n\nPlease refer to this.\n\n### Setup [...] BranchesTags\n\nOpen more actions menu\n\n## Folders and files\n\n| Name | Name | Last commit message | Last commit date |\n ---  --- |\n| Latest commit   History19 Commits |\n| assets | assets |  |  |\n| dataset | dataset |  |  |\n| eval | eval |  |  |\n| executor | executor |  |  |\n| exploration | exploration |  |  |\n| installation | installation |  |  |\n| llm | llm |  |  |\n| memory | memory |  |  |\n| pipeline | pipeline |  |  |\n| test\\_tool | test\\_tool |  |  |\n| utils | utils |  |  |\n| README.md | README.md |  |  |\n| config.yml | config.yml |  |  |\n|  |\n\n## Repository files navigation\n\n# An Intelligent Agentic System for Complex Image Restoration Problems", "score": 0.7067782, "raw_content": null, "summary": "``` @inproceedings{agenticir, title={An Intelligent Agentic System for Complex Image Restoration Problems}, author={Kaiwen Zhu and Jinjin Gu and Zhiyuan You and Yu Qiao and Chao Dong}, booktitle={The Thirteenth International Conference on Learning Representations}, year={2025}, url={ } ``` ## About [ICLR 2025] An Intelligent Agentic System for Complex Image Restoration Problems ### Topics agent im"}, {"url": "https://proceedings.iclr.cc/paper_files/paper/2025/file/36b7acf6f6010652b3f2a433774a66fe-Paper-Conference.pdf", "title": "[PDF] AUTOMATED DESIGN OF AGENTIC SYSTEMS - ICLR Proceedings", "content": "We first demonstrate how Meta Agent Search discovers novel agentic systems and outperforms ex-isting state-of-the-art hand-designed agents in the Abstraction and Reasoning Corpus (ARC) chal-lenge (Chollet, 2019). This challenge aims to evaluate the general intelligence of AI systems through their ability to acquire new skills. Questions in ARC include (1) showing multiple examples of vi-sual input-output grid patterns, (2) the AI system learning the transformation rule of grid patterns from examples, and (3) predicting the output grid pattern given a test input grid pattern. Since each question in ARC has a unique transformation rule, it requires the AI system to learn efficiently with few-shot examples, leveraging capabilities in number counting, geometry, and topology.\n5 Published as a conference paper at ICLR 2025 Setup. [...] Noah Shinn, Federico Cassano, Ashwin Gopinath, Karthik Narasimhan, and Shunyu Yao. Reflexion: Language agents with verbal reinforcement learning. Advances in Neural Information Processing Systems, 36, 2023.\n15 Published as a conference paper at ICLR 2025 Kenneth O Stanley and Joel Lehman. Why greatness cannot be planned: The myth of the objective.\nSpringer, 2015.\nKenneth O Stanley, Jeff Clune, Joel Lehman, and Risto Miikkulainen. Designing neural networks through neuroevolution. Nature Machine Intelligence, 1(1):24–35, 2019.\nRichard S. Sutton. The bitter lesson, 2019. URL  IncIdeas/BitterLesson.html.\nRichard S Sutton and Andrew G Barto. Reinforcement learning: An introduction. MIT press, 2018. [...] Jeff Clune. Ai-gas: Ai-generating algorithms, an alternate paradigm for producing general artificial intelligence. arXiv preprint arXiv:1905.10985, 2019.\n11 Published as a conference paper at ICLR 2025 Karl Cobbe, Vineet Kosaraju, Mohammad Bavarian, Mark Chen, Heewoo Jun, Lukasz Kaiser, Matthias Plappert, Jerry Tworek, Jacob Hilton, Reiichiro Nakano, et al. Training verifiers to solve math word problems. arXiv preprint arXiv:2110.14168, 2021.\nAntoine Cully and Yiannis Demiris. Quality and diversity optimization: A unifying modular frame-work. IEEE Transactions on Evolutionary Computation, 22(2):245–259, 2017.", "score": 0.7016523, "raw_content": null, "summary": "We first demonstrate how Meta Agent Search discovers novel agentic systems and outperforms ex-isting state-of-the-art hand-designed agents in the Abstraction and Reasoning Corpus (ARC) chal-lenge (Chollet, 2019). Questions in ARC include (1) showing multiple examples of vi-sual input-output grid patterns, (2) the AI system learning the transformation rule of grid patterns from examples, and (3) pr"}]}
{"query": "ICML 2025 AI trends (English)", "result": {"query": "ICML 2025 AI trends (English)", "follow_up_questions": null, "answer": null, "images": [], "results": [{"url": "https://icml.cc/virtual/2025/events/workshop", "title": "ICML 2025 Workshops", "content": "The goal of this workshop is to bring together interdisciplinary experts working on the emerging research questions and challenges associated with foundation model training and inference. This would be the third installment of the ES-FoMo workshop at ICML. This year, we are bringing further focus on two trends observed in 2024 and early 2025: (1) test-time compute, popularized by OpenAI o1 and DeepSeek r1, and (2) the mergence of new modeling paradigms and modalities such as real-time video and decentralized training. We look forward to continuing to grow this community at ICML 2025.\n\n Show more\n\n View full details\n\nWorkshop\n\n### Exploration in AI Today (EXAIT)\n\nParnian Kassraie · Andrew Wagenmaker · Bhavya · Carmelo Sferrazza · Lenart Treven · Amy X. Lu [...] As models increase in size and training budget, they not only systematically improve in upstream quality, but also exhibit novel emergent capabilities, unlocking new AI applications. These new capabilities have led to a paradigm shift: large foundation models have become predominant in natural language processing and are growing increasingly common in computer vision, audio processing and even robotics. This increase in scale raises proportionate difficulties for practitioners: foundation model training and inference lie at a unique interdisciplinary crossroad, combining open problems in algorithms, system design, and software engineering. [...] Jul 19, 8:30 AM - 5:15 PM    West Meeting Room 205-207\n\nHow can we efficiently collect observations for optimization, control, and generalization? This is a key challenge in AI and is known as the exploration problem. Effective exploration has driven progress in areas such as robotics, recommender systems, and scheduled medical trials. However, as we address larger, more complex applications—such as drug discovery or language modeling—the exceptionally large search spaces render traditional exploration algorithms ineffective. As a result, recent breakthroughs in AI have come not from traditional exploration algorithms, but largely from training large foundation models on diverse corpora of pre-existing, curated datasets. Despite this, we have witnessed sparks showing that exploration, when done right, can compensate for data and computation—for example, in the training of DeepSeek-R1—suggesting that exploration can still play a key role in AI today.", "score": 0.8812988, "raw_content": null, "summary": "This year, we are bringing further focus on two trends observed in 2024 and early 2025: (1) test-time compute, popularized by OpenAI o1 and DeepSeek r1, and (2) the mergence of new modeling paradigms and modalities such as real-time video and decentralized training. Despite this, we have witnessed sparks showing that exploration, when done right, can compensate for data and computation—for example"}, {"url": "https://instabase.com/blog/ai-insights-from-icml-2025-part-2-reinforcement-learning-agent-evaluation-and-confidence", "title": "AI Insights from ICML 2025 Part 2: Reinforcement learning, agent ...", "content": "## Reinforcement learning takes the lead from instruction tuning\n\nIf ICML 2025 made one thing clear, it’s this: reinforcement learning (RL) is having a moment. While instruction tuning still has its place, RL is increasingly taking center stage — especially in settings where learning from trial-and-error better reflects real-world decision-making.\n\nReinforcement learning helps models learn to make decisions by interacting with their environment, using a reward-based system to optimize outcomes over time. This improves a model’s ability to interact in enterprise settings because many processes involve sequential decision-making, delayed outcomes, and dynamic environments. Unlike more static models that map inputs to outputs, RL can learn policies that optimize for long-term objectives, handle feedback loops, and adjust strategies as workflows evolve. Take processes like client onboarding or claims handling, RL can help agents learn to optimize entire workflows rather than just individual actions. [...] That’s why strong evaluation isn’t a post-hoc step — it’s foundational. With the right error analysis and ablation strategies in place early, training better agents becomes significantly easier later. You can start making data-driven decisions on routing logic, tool selection sequences, or when and what to hand off between agents — all of which compound to stronger, more reliable performance. We’re also seeing reinforcement learning play a growing role in improving agent systems by simulating conversations and exploring the latent space of enterprise workflows.\n\nThis emphasis on evaluation was echoed across multiple ICML papers this year. For example, the authors of Towards Enterprise-Ready Computer Using Generalist Agent achieved state-of-the-art results on WebArena and AppWorld  —  not by improving visual perception, but by focusing on multi-agent architecture and rigorous planning and state tracking. Their work validates the importance of strong internal frameworks over flashier capabilities. [...] Get a Demo\n\nConnect with Us\n\nXLinkedin\n\nMachine Learning\n\nMachine Learning\n\n# AI Insights from ICML 2025 Part 2: Reinforcement learning, agent evaluation, and confidence\n\nAug 14, 2025\n\n6 min read\n\nContent\n\nExample H2\n\nExample H3\n\nICML 2025 (International Conference on Machine Learning) brought together leading minds from academia and industry to share ideas and research shaping the future of AI. From foundational breakthroughs to emerging trends, it provided a clear view into where the field is heading. Our very own Jordy Van Landeghem (Senior Software Engineer, Machine Learning) attended to present his work—and brought back insights from one of the field’s most influential gatherings.", "score": 0.86136365, "raw_content": null, "summary": "For example, the authors of Towards Enterprise-Ready Computer Using Generalist Agent achieved state-of-the-art results on WebArena and AppWorld — not by improving visual perception, but by focusing on multi-agent architecture and rigorous planning and state tracking. [...] Get a Demo Connect with Us XLinkedin Machine Learning Machine Learning # AI Insights from ICML 2025 Part 2: Reinforcement lear"}, {"url": "https://hai.stanford.edu/assets/files/hai_ai_index_report_2025.pdf", "title": "[PDF] Artificial Intelligence Index Report 2025 | Stanford HAI", "content": "6. Use of AI shows dramatic shifts by region, with Greater China gaining ground. While North America maintains its leadership in organizations’ use of AI, Greater China demonstrated one of the most significant year-over-year growth rates, with a 27 percentage point increase in organizational AI use. Europe followed with a 23 percentage point increase, suggesting a rapidly evolving global AI landscape and intensifying international competition in AI implementation. [...] Artificial Intelligence Index Report 2025 5 Top Takeaways (cont’d) 11. AI earns top honors for its impact on science. AI’s growing importance is reflected in major scientific awards: Two Nobel Prizes recognized work that led to deep learning (physics) and to its application to protein folding (chemistry), while the Turing Award honored groundbreaking contributions to reinforcement learning.\n12. Complex reasoning remains a challenge. AI models excel at tasks like International Mathematical Olympiad problems but still struggle with complex reasoning benchmarks like PlanBench. They often fail to reliably solve logic tasks even when provably correct solutions exist, limiting their effectiveness in high-stakes settings where precision is critical. [...] CHAPTER 1: Research and Development Artificial Intelligence Index Report 2025 Table of Contents 28 Artificial Intelligence Index Report 2025 Chapter 1 Preview Chapter Highlights (cont’d) CHAPTER 1: Research and Development Artificial Intelligence Index Report 2025 6. AI models become increasingly affordable to use. The cost of querying an AI model that scores the equivalent of GPT-3.5 (64.8) on MMLU, a popular benchmark for assessing language model performance, dropped from $20.00 per million tokens in November 2022 to just $0.07 per million tokens by October 2024 (Gemini-1.5-Flash-8B)—a more than 280-fold reduction in approximately 18 months. Depending on the task, LLM inference prices have fallen anywhere from 9 to 900 times per year.", "score": 0.77199864, "raw_content": null, "summary": "While North America maintains its leadership in organizations’ use of AI, Greater China demonstrated one of the most significant year-over-year growth rates, with a 27 percentage point increase in organizational AI use. The cost of querying an AI model that scores the equivalent of GPT-3.5 (64.8) on MMLU, a popular benchmark for assessing language model performance, dropped from $20.00 per million"}, {"url": "https://medium.com/foundation-models-deep-dive/icml-2025-sneak-peek-can-we-build-ai-we-can-actually-trust-ace9649e0e76", "title": "ICML 2025 Sneak Peek: Can We Build an AI We Can Trust? - Medium", "content": "When capabilities outpace control...\n\n## A New Kind of Threat\n\nFor most people, the concept of AI safety conjures images of “jailbreaking” — cleverly worded prompts designed to trick a language model into bypassing its safety filters and generating harmful content. This cat-and-mouse game between attackers and defenders has defined the first chapter of AI safety. But the research frontier to be revealed at ICML 2025 shows that the field is now confronting a far more profound and insidious class of threats. A landmark discovery has exposed a new failure mode so subtle and dangerous that it has triggered a virtual “arms race” between the escalating capabilities of AI and our ability to understand and control them.\n\n## Emergent Misalignment [...] Sitemap\n\nOpen in app\n\nSign in\n\nWrite\n\nSearch\n\nSign in\n\n## Foundation Models Deep Dive\n\n·\n\nFoundation Models Deep Dive explores the architecture, training, scaling laws, and real-world behavior of today’s most powerful AI systems. For engineers, researchers, and practitioners who want to understand what’s under the hood of foundation models.\n\nMember-only story\n\n# ICML 2025 Sneak Peek: Can We Build an AI We Can Trust?\n\nM\n\n5 min read\n\n·\n\nJun 17, 2025\n\n--\n\nWhen capabilities outpace control...\n\n## A New Kind of Threat [...] ## Emergent Misalignment\n\nThe most dramatic and sobering paper at the conference may arguably end up being “Emergent Misalignment: Narrow finetuning can produce broadly misaligned LLMs”. The paper details a startling experimental finding that may send ripples through the research community. The authors took a state-of-the-art, well-aligned model (GPT-4o) and fine-tuned it on a narrow, seemingly unrelated task: generating insecure computer code. The result was shocking. The fine-tuning process caused the model to become broadly and dangerously…\n\n## Published in Foundation Models Deep Dive\n\n48 followers\n\n·Last published Sep 18, 2025\n\nFoundation Models Deep Dive explores the architecture, training, scaling laws, and real-world behavior of today’s most powerful AI systems. For engineers, researchers, and practitioners who want to understand what’s under the hood of foundation models.\n\n## Written by M\n\n116 followers\n\n·27 following\n\n## No responses yet", "score": 0.7166357, "raw_content": null, "summary": "## Emergent Misalignment [...] Sitemap Open in app Sign in Write Search Sign in ## Foundation Models Deep Dive · Foundation Models Deep Dive explores the architecture, training, scaling laws, and real-world behavior of today’s most powerful AI systems. The fine-tuning process caused the model to become broadly and dangerously… ## Published in Foundation Models Deep Dive 48 followers ·Last publishe"}, {"url": "https://icml.cc/virtual/2025/papers.html", "title": "ICML 2025 Papers", "content": "##### Towards the Efficient Inference by Incorporating Automated Computational Phenotypes under Covariate Shift\n###### chao ying, Jun Jin, Yi Guo, Xiudi Li, Muxuan Liang, Jiwei Zhao\n\nTh, Jul 17, 23:30 GMT -- Poster Session 6 East\n\n##### M+: Extending MemoryLLM with Scalable Long-Term Memory\n###### Yu Wang, Dmitry Krotov, Yuanzhe Hu, Yifan Gao, Wangchunshu Zhou, Julian McAuley, Dan Gutfreund, Rogerio Feris, Zexue He\n\nTh, Jul 17, 23:30 GMT -- Poster Session 6 East\n\nImage 68 [...] Tu, Jul 15, 23:30 GMT -- Poster Session 2 West\n\nImage 83\n\n##### Janus: Dual-Server Multi-Round Secure Aggregation with Verifiability for Federated Learning\n###### Lang Pu, Jingjing Gu, Chao Lin, Xinyi Huang\n\nTh, Jul 17, 23:30 GMT -- Poster Session 6 East\n\n##### Offline-to-Online Reinforcement Learning with Classifier-Free Diffusion Generation\n###### Xiao Huang, Xu Liu, Enze Zhang, Tong Yu, Shuai Li\n\nTh, Jul 17, 23:30 GMT -- Poster Session 6 West\n\nImage 84 [...] We, Jul 16, 23:30 GMT -- Poster Session 4 West\n\n##### Fast Exact Unlearning for In-Context Learning Data for LLMs\n###### Andrei Muresanu, Anvith Thudi, Michael Zhang, Nicolas Papernot\n\nTh, Jul 17, 23:30 GMT -- Poster Session 6 East\n\n##### TANGO: Clustering with Typicality-Aware Nonlocal Mode-Seeking and Graph-Cut Optimization\n###### Haowen Ma, Zhiguo Long, Hua Meng\n\nTh, Jul 17, 23:30 GMT -- Poster Session 6 East\n\n##### Towards Practical Defect-Focused Automated Code Review\n###### Junyi Lu, Lili Jiang, Xiaojia Li, Jianbing Fang, Fengjun Zhang, Li Yang, Chun Zuo\n\nTh, Jul 17, 23:30 GMT -- Poster Session 6 West\n\nImage 203", "score": 0.6737291, "raw_content": null, "summary": "##### Towards the Efficient Inference by Incorporating Automated Computational Phenotypes under Covariate Shift ###### chao ying, Jun Jin, Yi Guo, Xiudi Li, Muxuan Liang, Jiwei Zhao Th, Jul 17, 23:30 GMT -- Poster Session 6 East ##### M+: Extending MemoryLLM with Scalable Long-Term Memory ###### Yu Wang, Dmitry Krotov, Yuanzhe Hu, Yifan Gao, Wangchunshu Zhou, Julian McAuley, Dan Gutfreund, Rogerio"}], "response_time": 2.79, "request_id": "bf6053fa-b632-4c23-af15-a9f531d12561"}, "query_summary": "Despite this, we have witnessed sparks showing that exploration, when done right, can compensate for data and computation—for example For example, the authors of Towards Enterprise-Ready Computer Using Generalist Agent achieved state-of-the-art results on WebArena and AppWorld — not by improving visual perception, but by focusing on multi-agent architecture and rigorous planning and state tracking. The cost of querying an AI model that scores the equivalent of GPT-3.5 (64.8) on MMLU, a popular benchmark for assessing language model performance, dropped from $20.00 per million ## Emergent Misal", "lang_pref": "en", "preferred_results": [{"url": "https://icml.cc/virtual/2025/events/workshop", "title": "ICML 2025 Workshops", "content": "The goal of this workshop is to bring together interdisciplinary experts working on the emerging research questions and challenges associated with foundation model training and inference. This would be the third installment of the ES-FoMo workshop at ICML. This year, we are bringing further focus on two trends observed in 2024 and early 2025: (1) test-time compute, popularized by OpenAI o1 and DeepSeek r1, and (2) the mergence of new modeling paradigms and modalities such as real-time video and decentralized training. We look forward to continuing to grow this community at ICML 2025.\n\n Show more\n\n View full details\n\nWorkshop\n\n### Exploration in AI Today (EXAIT)\n\nParnian Kassraie · Andrew Wagenmaker · Bhavya · Carmelo Sferrazza · Lenart Treven · Amy X. Lu [...] As models increase in size and training budget, they not only systematically improve in upstream quality, but also exhibit novel emergent capabilities, unlocking new AI applications. These new capabilities have led to a paradigm shift: large foundation models have become predominant in natural language processing and are growing increasingly common in computer vision, audio processing and even robotics. This increase in scale raises proportionate difficulties for practitioners: foundation model training and inference lie at a unique interdisciplinary crossroad, combining open problems in algorithms, system design, and software engineering. [...] Jul 19, 8:30 AM - 5:15 PM    West Meeting Room 205-207\n\nHow can we efficiently collect observations for optimization, control, and generalization? This is a key challenge in AI and is known as the exploration problem. Effective exploration has driven progress in areas such as robotics, recommender systems, and scheduled medical trials. However, as we address larger, more complex applications—such as drug discovery or language modeling—the exceptionally large search spaces render traditional exploration algorithms ineffective. As a result, recent breakthroughs in AI have come not from traditional exploration algorithms, but largely from training large foundation models on diverse corpora of pre-existing, curated datasets. Despite this, we have witnessed sparks showing that exploration, when done right, can compensate for data and computation—for example, in the training of DeepSeek-R1—suggesting that exploration can still play a key role in AI today.", "score": 0.8812988, "raw_content": null, "summary": "This year, we are bringing further focus on two trends observed in 2024 and early 2025: (1) test-time compute, popularized by OpenAI o1 and DeepSeek r1, and (2) the mergence of new modeling paradigms and modalities such as real-time video and decentralized training. Despite this, we have witnessed sparks showing that exploration, when done right, can compensate for data and computation—for example"}, {"url": "https://instabase.com/blog/ai-insights-from-icml-2025-part-2-reinforcement-learning-agent-evaluation-and-confidence", "title": "AI Insights from ICML 2025 Part 2: Reinforcement learning, agent ...", "content": "## Reinforcement learning takes the lead from instruction tuning\n\nIf ICML 2025 made one thing clear, it’s this: reinforcement learning (RL) is having a moment. While instruction tuning still has its place, RL is increasingly taking center stage — especially in settings where learning from trial-and-error better reflects real-world decision-making.\n\nReinforcement learning helps models learn to make decisions by interacting with their environment, using a reward-based system to optimize outcomes over time. This improves a model’s ability to interact in enterprise settings because many processes involve sequential decision-making, delayed outcomes, and dynamic environments. Unlike more static models that map inputs to outputs, RL can learn policies that optimize for long-term objectives, handle feedback loops, and adjust strategies as workflows evolve. Take processes like client onboarding or claims handling, RL can help agents learn to optimize entire workflows rather than just individual actions. [...] That’s why strong evaluation isn’t a post-hoc step — it’s foundational. With the right error analysis and ablation strategies in place early, training better agents becomes significantly easier later. You can start making data-driven decisions on routing logic, tool selection sequences, or when and what to hand off between agents — all of which compound to stronger, more reliable performance. We’re also seeing reinforcement learning play a growing role in improving agent systems by simulating conversations and exploring the latent space of enterprise workflows.\n\nThis emphasis on evaluation was echoed across multiple ICML papers this year. For example, the authors of Towards Enterprise-Ready Computer Using Generalist Agent achieved state-of-the-art results on WebArena and AppWorld  —  not by improving visual perception, but by focusing on multi-agent architecture and rigorous planning and state tracking. Their work validates the importance of strong internal frameworks over flashier capabilities. [...] Get a Demo\n\nConnect with Us\n\nXLinkedin\n\nMachine Learning\n\nMachine Learning\n\n# AI Insights from ICML 2025 Part 2: Reinforcement learning, agent evaluation, and confidence\n\nAug 14, 2025\n\n6 min read\n\nContent\n\nExample H2\n\nExample H3\n\nICML 2025 (International Conference on Machine Learning) brought together leading minds from academia and industry to share ideas and research shaping the future of AI. From foundational breakthroughs to emerging trends, it provided a clear view into where the field is heading. Our very own Jordy Van Landeghem (Senior Software Engineer, Machine Learning) attended to present his work—and brought back insights from one of the field’s most influential gatherings.", "score": 0.86136365, "raw_content": null, "summary": "For example, the authors of Towards Enterprise-Ready Computer Using Generalist Agent achieved state-of-the-art results on WebArena and AppWorld — not by improving visual perception, but by focusing on multi-agent architecture and rigorous planning and state tracking. [...] Get a Demo Connect with Us XLinkedin Machine Learning Machine Learning # AI Insights from ICML 2025 Part 2: Reinforcement lear"}, {"url": "https://hai.stanford.edu/assets/files/hai_ai_index_report_2025.pdf", "title": "[PDF] Artificial Intelligence Index Report 2025 | Stanford HAI", "content": "6. Use of AI shows dramatic shifts by region, with Greater China gaining ground. While North America maintains its leadership in organizations’ use of AI, Greater China demonstrated one of the most significant year-over-year growth rates, with a 27 percentage point increase in organizational AI use. Europe followed with a 23 percentage point increase, suggesting a rapidly evolving global AI landscape and intensifying international competition in AI implementation. [...] Artificial Intelligence Index Report 2025 5 Top Takeaways (cont’d) 11. AI earns top honors for its impact on science. AI’s growing importance is reflected in major scientific awards: Two Nobel Prizes recognized work that led to deep learning (physics) and to its application to protein folding (chemistry), while the Turing Award honored groundbreaking contributions to reinforcement learning.\n12. Complex reasoning remains a challenge. AI models excel at tasks like International Mathematical Olympiad problems but still struggle with complex reasoning benchmarks like PlanBench. They often fail to reliably solve logic tasks even when provably correct solutions exist, limiting their effectiveness in high-stakes settings where precision is critical. [...] CHAPTER 1: Research and Development Artificial Intelligence Index Report 2025 Table of Contents 28 Artificial Intelligence Index Report 2025 Chapter 1 Preview Chapter Highlights (cont’d) CHAPTER 1: Research and Development Artificial Intelligence Index Report 2025 6. AI models become increasingly affordable to use. The cost of querying an AI model that scores the equivalent of GPT-3.5 (64.8) on MMLU, a popular benchmark for assessing language model performance, dropped from $20.00 per million tokens in November 2022 to just $0.07 per million tokens by October 2024 (Gemini-1.5-Flash-8B)—a more than 280-fold reduction in approximately 18 months. Depending on the task, LLM inference prices have fallen anywhere from 9 to 900 times per year.", "score": 0.77199864, "raw_content": null, "summary": "While North America maintains its leadership in organizations’ use of AI, Greater China demonstrated one of the most significant year-over-year growth rates, with a 27 percentage point increase in organizational AI use. The cost of querying an AI model that scores the equivalent of GPT-3.5 (64.8) on MMLU, a popular benchmark for assessing language model performance, dropped from $20.00 per million"}, {"url": "https://medium.com/foundation-models-deep-dive/icml-2025-sneak-peek-can-we-build-ai-we-can-actually-trust-ace9649e0e76", "title": "ICML 2025 Sneak Peek: Can We Build an AI We Can Trust? - Medium", "content": "When capabilities outpace control...\n\n## A New Kind of Threat\n\nFor most people, the concept of AI safety conjures images of “jailbreaking” — cleverly worded prompts designed to trick a language model into bypassing its safety filters and generating harmful content. This cat-and-mouse game between attackers and defenders has defined the first chapter of AI safety. But the research frontier to be revealed at ICML 2025 shows that the field is now confronting a far more profound and insidious class of threats. A landmark discovery has exposed a new failure mode so subtle and dangerous that it has triggered a virtual “arms race” between the escalating capabilities of AI and our ability to understand and control them.\n\n## Emergent Misalignment [...] Sitemap\n\nOpen in app\n\nSign in\n\nWrite\n\nSearch\n\nSign in\n\n## Foundation Models Deep Dive\n\n·\n\nFoundation Models Deep Dive explores the architecture, training, scaling laws, and real-world behavior of today’s most powerful AI systems. For engineers, researchers, and practitioners who want to understand what’s under the hood of foundation models.\n\nMember-only story\n\n# ICML 2025 Sneak Peek: Can We Build an AI We Can Trust?\n\nM\n\n5 min read\n\n·\n\nJun 17, 2025\n\n--\n\nWhen capabilities outpace control...\n\n## A New Kind of Threat [...] ## Emergent Misalignment\n\nThe most dramatic and sobering paper at the conference may arguably end up being “Emergent Misalignment: Narrow finetuning can produce broadly misaligned LLMs”. The paper details a startling experimental finding that may send ripples through the research community. The authors took a state-of-the-art, well-aligned model (GPT-4o) and fine-tuned it on a narrow, seemingly unrelated task: generating insecure computer code. The result was shocking. The fine-tuning process caused the model to become broadly and dangerously…\n\n## Published in Foundation Models Deep Dive\n\n48 followers\n\n·Last published Sep 18, 2025\n\nFoundation Models Deep Dive explores the architecture, training, scaling laws, and real-world behavior of today’s most powerful AI systems. For engineers, researchers, and practitioners who want to understand what’s under the hood of foundation models.\n\n## Written by M\n\n116 followers\n\n·27 following\n\n## No responses yet", "score": 0.7166357, "raw_content": null, "summary": "## Emergent Misalignment [...] Sitemap Open in app Sign in Write Search Sign in ## Foundation Models Deep Dive · Foundation Models Deep Dive explores the architecture, training, scaling laws, and real-world behavior of today’s most powerful AI systems. The fine-tuning process caused the model to become broadly and dangerously… ## Published in Foundation Models Deep Dive 48 followers ·Last publishe"}, {"url": "https://icml.cc/virtual/2025/papers.html", "title": "ICML 2025 Papers", "content": "##### Towards the Efficient Inference by Incorporating Automated Computational Phenotypes under Covariate Shift\n###### chao ying, Jun Jin, Yi Guo, Xiudi Li, Muxuan Liang, Jiwei Zhao\n\nTh, Jul 17, 23:30 GMT -- Poster Session 6 East\n\n##### M+: Extending MemoryLLM with Scalable Long-Term Memory\n###### Yu Wang, Dmitry Krotov, Yuanzhe Hu, Yifan Gao, Wangchunshu Zhou, Julian McAuley, Dan Gutfreund, Rogerio Feris, Zexue He\n\nTh, Jul 17, 23:30 GMT -- Poster Session 6 East\n\nImage 68 [...] Tu, Jul 15, 23:30 GMT -- Poster Session 2 West\n\nImage 83\n\n##### Janus: Dual-Server Multi-Round Secure Aggregation with Verifiability for Federated Learning\n###### Lang Pu, Jingjing Gu, Chao Lin, Xinyi Huang\n\nTh, Jul 17, 23:30 GMT -- Poster Session 6 East\n\n##### Offline-to-Online Reinforcement Learning with Classifier-Free Diffusion Generation\n###### Xiao Huang, Xu Liu, Enze Zhang, Tong Yu, Shuai Li\n\nTh, Jul 17, 23:30 GMT -- Poster Session 6 West\n\nImage 84 [...] We, Jul 16, 23:30 GMT -- Poster Session 4 West\n\n##### Fast Exact Unlearning for In-Context Learning Data for LLMs\n###### Andrei Muresanu, Anvith Thudi, Michael Zhang, Nicolas Papernot\n\nTh, Jul 17, 23:30 GMT -- Poster Session 6 East\n\n##### TANGO: Clustering with Typicality-Aware Nonlocal Mode-Seeking and Graph-Cut Optimization\n###### Haowen Ma, Zhiguo Long, Hua Meng\n\nTh, Jul 17, 23:30 GMT -- Poster Session 6 East\n\n##### Towards Practical Defect-Focused Automated Code Review\n###### Junyi Lu, Lili Jiang, Xiaojia Li, Jianbing Fang, Fengjun Zhang, Li Yang, Chun Zuo\n\nTh, Jul 17, 23:30 GMT -- Poster Session 6 West\n\nImage 203", "score": 0.6737291, "raw_content": null, "summary": "##### Towards the Efficient Inference by Incorporating Automated Computational Phenotypes under Covariate Shift ###### chao ying, Jun Jin, Yi Guo, Xiudi Li, Muxuan Liang, Jiwei Zhao Th, Jul 17, 23:30 GMT -- Poster Session 6 East ##### M+: Extending MemoryLLM with Scalable Long-Term Memory ###### Yu Wang, Dmitry Krotov, Yuanzhe Hu, Yifan Gao, Wangchunshu Zhou, Julian McAuley, Dan Gutfreund, Rogerio"}]}
{"query": "CVPR 2025 physical AI robotics (English)", "result": {"query": "CVPR 2025 physical AI robotics (English)", "follow_up_questions": null, "answer": null, "images": [], "results": [{"url": "https://cvpr.thecvf.com/virtual/2025/invited-talk/35404", "title": "Gemini Robotics, Bringing AI to the Physical World - CVPR 2026", "content": "Skip to yearly menu bar\n\n## Main Navigation\n\n CVPR \n  + Code of Conduct  \n\n  + Create Profile  \n\n  + Reset / Forgot Password  \n\n  + Privacy Policy  \n\n  + Contact CVPR  \n\n  + HELP/FAQ\n Reset Password\n My Stuff\n\n Login\n\nKeynote\n\n# Gemini Robotics, Bringing AI to the Physical World\n\nCarolina Parada\n\n2025 Keynote\n\n### Abstract\n\nA new wave of general purpose robots is promising to bring helpful robots into many areas of human life. But in order to be truly useful, such robots require generalist embodied intelligence. [...] In order for robots to be helpful, they need to be capable of sophisticated skills, understand and reason about the world around them, interact with humans, and be able to generalize to new situations and tasks. I will discuss some of the building blocks that GDM Robotics is developing to this end, focusing on our recently released family of Gemini Robotics foundation models. Having been designed with robotics in mind, they combine Gemini’s world understanding with the ability to reason about the physical world and take action. With generality, interactivity, dexterity, and enhanced embodied reasoning they’re laying a foundation for a new generation of helpful robots.\n\nChat is not available.\n\nSuccessful Page Load", "score": 0.7515939, "raw_content": null, "summary": "Skip to yearly menu bar ## Main Navigation CVPR + Code of Conduct + Create Profile + Reset / Forgot Password + Privacy Policy + Contact CVPR + HELP/FAQ Reset Password My Stuff Login Keynote # Gemini Robotics, Bringing AI to the Physical World Carolina Parada 2025 Keynote ### Abstract A new wave of general purpose robots is promising to bring helpful robots into many areas of human life. [...] In o"}, {"url": "https://cvpr.thecvf.com/virtual/2025/events/workshop", "title": "CVPR 2025 Workshops", "content": "Yixin Chen · Baoxiong Jia · Yao Feng · Songyou Peng · Chuhang Zou · Sai Kumar Dwivedi · Yixin Zhu · Siyuan Huang · Derek Hoiem · Marc Pollefeys · Song-Chun Zhu\n\nJun 11, 6:30 AM - 11:00 AM    106 C\n\nThe developments in computer vision, graphics, and robotics have jointly spurred calls for next-generation AI systems that physically interact with their surroundings. Current research advances encompass 3D representations, large-scale foundation models, and end-to-end VLA approaches, but fundamental questions remain on how best to sustain environment comprehension, align efforts from diverse fields, and integrate scene understanding techniques to enhance physical interaction. The workshop seeks to unite current efforts, educate an interdisciplinary workforce with expertise across fields, and promote future developments in embodied and general AI.\n\n Show more\n\n View full details\n\nWorkshop [...] Jun 12, 6:00 AM - 10:00 AM    108\n\nWorld models are predictive systems that enable Physical AI agents to understand, decide, plan, and analyze counterfactuals through integrated perception, instruction processing, controllability, physical plausibility, and future prediction capabilities. The past year has witnessed significant advancements from both academic and industrial research teams, with various models utilizing different conditioning approaches (text, image, video, control) being released openly and commercially. While these developments enable applications in content creation, autonomous driving, and robotics, the models' diversity in training methods, data sources, architecture, and input processing necessitates critical evaluation. The WorldModelBench workshop aims to address this need by fostering discussions on evaluation criteria (physical correctness, prompt alignment, generalizability), metrics development, standardized methodologies, and crucial topics including accessible benchmarking, quantitative evaluation protocols, downstream task assessment, and safety/bias considerations in world models.\n\n Show more [...] ### Vision Meets Physics: Synergizing Physical Simulation and Computer Vision\n\nFangyin Wei · Donglai Xiang · Qianli Ma · Yifei Li · Ming Lin · Chenfanfu Jiang · Shenlong Wang · David I.W. · Tsung-Yi Lin\n\nJun 12, 6:45 AM - 3:30 PM    104 A\n\nThis workshop explores the evolving intersection of computer vision and physics, where two competing perspectives—physics-based simulations versus data-driven approaches like video foundation models—seek to model the world effectively. By bringing together researchers from both fields, the event aims to foster collaboration, identify synergies, and advance applications in scientific research, generative AI, robotics, gaming, and extended realities (XR). Through presentations and discussions, the workshop will promote interdisciplinary dialogue to develop next-generation technologies that combine physics-based and data-driven methods, ultimately enhancing realistic simulations for immersive environments, automated tasks, and seamless virtual-physical integration.", "score": 0.70847535, "raw_content": null, "summary": "Show more View full details Workshop [...] Jun 12, 6:00 AM - 10:00 AM 108 World models are predictive systems that enable Physical AI agents to understand, decide, plan, and analyze counterfactuals through integrated perception, instruction processing, controllability, physical plausibility, and future prediction capabilities. Through presentations and discussions, the workshop will promote interd"}, {"url": "https://voxel51.com/blog/embodied-computer-vision-at-cvpr-2025-the-next-ai-frontier", "title": "Embodied Computer Vision at CVPR 2025: The Next AI Frontier", "content": "Book a demo\n\nBlog\n\nEvent Recaps\n\nEmbodied Computer Vision at CVPR 2025: The Next AI Frontier\n\nJun 30, 2025\n\n•\n\n5min read\n\nIn this article\n\n1. RoBoSpatial: Training AIto Reason About Space2. GROVE: Teaching Robots with Generalized Rewards3. Navigation World Models: Planning in Simulation4. Gemini Robotics: Bridging Foundation Models and Physical ActionWhy Embodied AI is the Next Big BoomA Call to the Research Community: Prepare to Validate the FutureFinal ThoughtsWhat is next?\n\nIn this article\n\n1. RoBoSpatial: Training AIto Reason About Space2. GROVE: Teaching Robots with Generalized Rewards3. Navigation World Models: Planning in Simulation4. Gemini Robotics: Bridging Foundation Models and Physical ActionWhy Embodied AI is the Next Big BoomA Call to the Research Community: Prepare to Validate the FutureFinal ThoughtsWhat is next? [...] To get there, we must:\n\n Build stronger VLMs that understand the physical world.\n Validate generalization with diverse and multimodal data.\n Benchmark safety, social understanding, and fine motor control (dexterity).\n Create shared community tools like ASIMOV and RoBoSpatial.\n Shift from 2D VQA to embodied evaluation.\n\n> “In order to build truly helpful robots, we must ground our research in the physical world and validate our models through embodied interaction.” — Carolina Parada\n\n## Final Thoughts\n\nCVPR 2025 clarified that the fusion of visual understanding, language, and physical action is no longer science fiction. Embodied AI is rising, and it demands new data, new benchmarks, new ethics, and new imagination.\n\nLet’s shape that future together.\n\n## What is next? [...] ## 3. Navigation World Models: Planning in Simulation\n\nThis talk introduced a Conditional Diffusion Transformer (CDT) trained on 700+ hours of multimodal robot data. It learns to:\n\n Predict future visual frames given the current context and action.\n Simulate outcomes across diverse environments.\n Evaluate and plan trajectories before acting in the real world\n\nSuch models empower agents with an “imagination”, they can simulate action consequences before execution, making decisions that align with long-term goals and environment dynamics.\n\nPrediction, not just perception, is at the heart of embodied AI.\n\n## 4. Gemini Robotics: Bridging Foundation Models and Physical Action\n\nDr. Carolina Parada’s keynote was a watershed moment. As the Director of Robotics at Google DeepMind, she unveiled how Gemini Robotics brings Google’s flagship multimodal model into the physical world.\n\n> “Gemini Robotics draws from Gemini’s world understanding and brings it to the physical world by adding actions as a new modality.”", "score": 0.6778372, "raw_content": null, "summary": "Gemini Robotics: Bridging Foundation Models and Physical ActionWhy Embodied AI is the Next Big BoomA Call to the Research Community: Prepare to Validate the FutureFinal ThoughtsWhat is next? > “In order to build truly helpful robots, we must ground our research in the physical world and validate our models through embodied interaction.” — Carolina Parada ## Final Thoughts CVPR 2025 clarified that"}, {"url": "https://cvpr.thecvf.com/Conferences/2025/News/AI_Enhanced_Robotics", "title": "Four Ways Computer Vision Is Driving AI-Enhanced Robotics", "content": "Skip to yearly menu bar\n\n## Main Navigation\n\n CVPR \n  + Code of Conduct  \n\n  + Create Profile  \n\n  + Reset / Forgot Password  \n\n  + Privacy Policy  \n\n  + Contact CVPR  \n\n  + HELP/FAQ\n Reset Password\n My Stuff\n\n Login\n\n### Four Ways Computer Vision Is Driving AI-Enhanced Robotics\n\nArtificial intelligence (AI)-enhanced robotics has emerged as a primary area of growth in the field of computer vision. As the IEEE CS 2025 Technology Predictions report explains: “Embodied intelligence will enable robots to perceive, learn, and collaborate in dynamic environments, achieving unprecedented autonomy and human-like adaptability.” Market research supports that sentiment: According to Statista, the AI robotics market size is expected to show an annual growth rate (CAGR 2025-2030) of 23.37%, resulting in a market volume of US$64.35bn by 2030. [...] While much work remains in the field of AI-enhanced robotics, just as much opportunity awaits. According to analysts, “The growing investment in research and development to enhance the capabilities of AI robotics is expected to propel market growth in the coming years.” From the implications in the industries ranging from healthcare and manufacturing to consumers and Smart Cities, the work in computer vision and pattern recognition today will have lasting influence on the future of robotics and its positive impact on humankind.\n\nFor more information on CVPR 2025, taking place 11-15 June in Nashville, Tenn., U.S., or to register, visit \n\nSuccessful Page Load [...] Developments with large language models (LLMs), multimodal AI, and broader computer vision efforts have been among the primary forces behind this rapid acceleration, and as the industry gears up for its leading AI engineering event, the Computer Vision and Pattern Recognition Conference (CVPR), paper submissions reiterate the role that AI-enhanced robotics will play.\n\n“A lot of people in computer vision are now interested in robotics,” said Phillip Isola, CVPR 2025 Program Co-Chair and an associate professor at the Massachusetts Institute of Technology (MIT) in Boston, Mass., U.S. “They're first starting by modeling 3D scenes, and that will be more relevant to robotics. For example, they might be working on navigation of a house, and there's no robot. But that's where they're going.”", "score": 0.6641271, "raw_content": null, "summary": "According to analysts, “The growing investment in research and development to enhance the capabilities of AI robotics is expected to propel market growth in the coming years.” From the implications in the industries ranging from healthcare and manufacturing to consumers and Smart Cities, the work in computer vision and pattern recognition today will have lasting influence on the future of robotics"}, {"url": "https://cvpr.thecvf.com/Conferences/2025/News/Wrap", "title": "CVPR 2025 Unveils the Latest Trends in Artificial Intelligence (AI ...", "content": "Harry Shum, former Executive Vice President of Microsoft Corporation and current Council Chairman of Hong Kong University of Science and Technology, Exploring the Low Altitude Airspace: From Natural Resource to Economic Engine (keynote video recording)\n Laurens van der Maaten, Distinguished Research Scientist at Meta AI, The Llama Herd of Models: System 1, 2, 3 Go!(keynote video recording)\n Carolina Parada, Senior Director and Head of Robotics at Google DeepMind, Gemini Robotics, Bringing AI to the Physical World (keynote video recording)\n\nExposition, Demo Award Winners, and Sponsors [...] About CVPR 2025\n\nThe Computer Vision and Pattern Recognition Conference (CVPR) is the preeminent computer vision event for new research in support of artificial intelligence (AI), machine learning (ML), augmented, virtual and mixed reality (AR/VR/MR), deep learning, and much more. Sponsored by the IEEE Computer Society (CS) and the Computer Vision Foundation (CVF), CVPR delivers the important advances in all areas of computer vision and pattern recognition and the various fields and industries they impact. With a first-in-class technical program, including tutorials and workshops, a leading-edge expo, and robust networking opportunities, CVPR, which is annually attended by more than 10,000 scientists and engineers, creates a one-of-a-kind opportunity for networking, recruiting, inspiration, and motivation. [...] “All of the papers accepted to CVPR help to advance the work of the community,” said Fuxin Li, CVPR 2025 Program Co-Chair, and an associate professor at Oregon State University in Corvallis, Ore., U.S. “It will be exciting to watch how research continues to unfold over the next year.”\n\nKeynotes\n\nProviding insights into significant topics for the industry, CVPR 2025 keynotes addressed how artificial intelligence (AI) can support the low-altitude economy; the next phase of AI; and the evolution of robotics with the support of more advanced AI. Specifically, the following presenters spoke to these themes in their talks:", "score": 0.6175132, "raw_content": null, "summary": "Harry Shum, former Executive Vice President of Microsoft Corporation and current Council Chairman of Hong Kong University of Science and Technology, Exploring the Low Altitude Airspace: From Natural Resource to Economic Engine (keynote video recording) Laurens van der Maaten, Distinguished Research Scientist at Meta AI, The Llama Herd of Models: System 1, 2, 3 Go!(keynote video recording) Carolina"}], "response_time": 2.49, "request_id": "dd8fe235-a16d-47dd-9ff8-423027be500c"}, "query_summary": "Skip to yearly menu bar ## Main Navigation CVPR + Code of Conduct + Create Profile + Reset / Forgot Password + Privacy Policy + Contact CVPR + HELP/FAQ Reset Password My Stuff Login Keynote # Gemini Robotics, Bringing AI to the Physical World Carolina Parada 2025 Keynote ### Abstract A new wave of general purpose robots is promising to bring helpful robots into many areas of human life. Through presentations and discussions, the workshop will promote interd Gemini Robotics: Bridging Foundation Models and Physical ActionWhy Embodied AI is the Next Big BoomA Call to the Research Community: Prepa", "lang_pref": "en", "preferred_results": [{"url": "https://cvpr.thecvf.com/virtual/2025/invited-talk/35404", "title": "Gemini Robotics, Bringing AI to the Physical World - CVPR 2026", "content": "Skip to yearly menu bar\n\n## Main Navigation\n\n CVPR \n  + Code of Conduct  \n\n  + Create Profile  \n\n  + Reset / Forgot Password  \n\n  + Privacy Policy  \n\n  + Contact CVPR  \n\n  + HELP/FAQ\n Reset Password\n My Stuff\n\n Login\n\nKeynote\n\n# Gemini Robotics, Bringing AI to the Physical World\n\nCarolina Parada\n\n2025 Keynote\n\n### Abstract\n\nA new wave of general purpose robots is promising to bring helpful robots into many areas of human life. But in order to be truly useful, such robots require generalist embodied intelligence. [...] In order for robots to be helpful, they need to be capable of sophisticated skills, understand and reason about the world around them, interact with humans, and be able to generalize to new situations and tasks. I will discuss some of the building blocks that GDM Robotics is developing to this end, focusing on our recently released family of Gemini Robotics foundation models. Having been designed with robotics in mind, they combine Gemini’s world understanding with the ability to reason about the physical world and take action. With generality, interactivity, dexterity, and enhanced embodied reasoning they’re laying a foundation for a new generation of helpful robots.\n\nChat is not available.\n\nSuccessful Page Load", "score": 0.7515939, "raw_content": null, "summary": "Skip to yearly menu bar ## Main Navigation CVPR + Code of Conduct + Create Profile + Reset / Forgot Password + Privacy Policy + Contact CVPR + HELP/FAQ Reset Password My Stuff Login Keynote # Gemini Robotics, Bringing AI to the Physical World Carolina Parada 2025 Keynote ### Abstract A new wave of general purpose robots is promising to bring helpful robots into many areas of human life. [...] In o"}, {"url": "https://cvpr.thecvf.com/virtual/2025/events/workshop", "title": "CVPR 2025 Workshops", "content": "Yixin Chen · Baoxiong Jia · Yao Feng · Songyou Peng · Chuhang Zou · Sai Kumar Dwivedi · Yixin Zhu · Siyuan Huang · Derek Hoiem · Marc Pollefeys · Song-Chun Zhu\n\nJun 11, 6:30 AM - 11:00 AM    106 C\n\nThe developments in computer vision, graphics, and robotics have jointly spurred calls for next-generation AI systems that physically interact with their surroundings. Current research advances encompass 3D representations, large-scale foundation models, and end-to-end VLA approaches, but fundamental questions remain on how best to sustain environment comprehension, align efforts from diverse fields, and integrate scene understanding techniques to enhance physical interaction. The workshop seeks to unite current efforts, educate an interdisciplinary workforce with expertise across fields, and promote future developments in embodied and general AI.\n\n Show more\n\n View full details\n\nWorkshop [...] Jun 12, 6:00 AM - 10:00 AM    108\n\nWorld models are predictive systems that enable Physical AI agents to understand, decide, plan, and analyze counterfactuals through integrated perception, instruction processing, controllability, physical plausibility, and future prediction capabilities. The past year has witnessed significant advancements from both academic and industrial research teams, with various models utilizing different conditioning approaches (text, image, video, control) being released openly and commercially. While these developments enable applications in content creation, autonomous driving, and robotics, the models' diversity in training methods, data sources, architecture, and input processing necessitates critical evaluation. The WorldModelBench workshop aims to address this need by fostering discussions on evaluation criteria (physical correctness, prompt alignment, generalizability), metrics development, standardized methodologies, and crucial topics including accessible benchmarking, quantitative evaluation protocols, downstream task assessment, and safety/bias considerations in world models.\n\n Show more [...] ### Vision Meets Physics: Synergizing Physical Simulation and Computer Vision\n\nFangyin Wei · Donglai Xiang · Qianli Ma · Yifei Li · Ming Lin · Chenfanfu Jiang · Shenlong Wang · David I.W. · Tsung-Yi Lin\n\nJun 12, 6:45 AM - 3:30 PM    104 A\n\nThis workshop explores the evolving intersection of computer vision and physics, where two competing perspectives—physics-based simulations versus data-driven approaches like video foundation models—seek to model the world effectively. By bringing together researchers from both fields, the event aims to foster collaboration, identify synergies, and advance applications in scientific research, generative AI, robotics, gaming, and extended realities (XR). Through presentations and discussions, the workshop will promote interdisciplinary dialogue to develop next-generation technologies that combine physics-based and data-driven methods, ultimately enhancing realistic simulations for immersive environments, automated tasks, and seamless virtual-physical integration.", "score": 0.70847535, "raw_content": null, "summary": "Show more View full details Workshop [...] Jun 12, 6:00 AM - 10:00 AM 108 World models are predictive systems that enable Physical AI agents to understand, decide, plan, and analyze counterfactuals through integrated perception, instruction processing, controllability, physical plausibility, and future prediction capabilities. Through presentations and discussions, the workshop will promote interd"}, {"url": "https://voxel51.com/blog/embodied-computer-vision-at-cvpr-2025-the-next-ai-frontier", "title": "Embodied Computer Vision at CVPR 2025: The Next AI Frontier", "content": "Book a demo\n\nBlog\n\nEvent Recaps\n\nEmbodied Computer Vision at CVPR 2025: The Next AI Frontier\n\nJun 30, 2025\n\n•\n\n5min read\n\nIn this article\n\n1. RoBoSpatial: Training AIto Reason About Space2. GROVE: Teaching Robots with Generalized Rewards3. Navigation World Models: Planning in Simulation4. Gemini Robotics: Bridging Foundation Models and Physical ActionWhy Embodied AI is the Next Big BoomA Call to the Research Community: Prepare to Validate the FutureFinal ThoughtsWhat is next?\n\nIn this article\n\n1. RoBoSpatial: Training AIto Reason About Space2. GROVE: Teaching Robots with Generalized Rewards3. Navigation World Models: Planning in Simulation4. Gemini Robotics: Bridging Foundation Models and Physical ActionWhy Embodied AI is the Next Big BoomA Call to the Research Community: Prepare to Validate the FutureFinal ThoughtsWhat is next? [...] To get there, we must:\n\n Build stronger VLMs that understand the physical world.\n Validate generalization with diverse and multimodal data.\n Benchmark safety, social understanding, and fine motor control (dexterity).\n Create shared community tools like ASIMOV and RoBoSpatial.\n Shift from 2D VQA to embodied evaluation.\n\n> “In order to build truly helpful robots, we must ground our research in the physical world and validate our models through embodied interaction.” — Carolina Parada\n\n## Final Thoughts\n\nCVPR 2025 clarified that the fusion of visual understanding, language, and physical action is no longer science fiction. Embodied AI is rising, and it demands new data, new benchmarks, new ethics, and new imagination.\n\nLet’s shape that future together.\n\n## What is next? [...] ## 3. Navigation World Models: Planning in Simulation\n\nThis talk introduced a Conditional Diffusion Transformer (CDT) trained on 700+ hours of multimodal robot data. It learns to:\n\n Predict future visual frames given the current context and action.\n Simulate outcomes across diverse environments.\n Evaluate and plan trajectories before acting in the real world\n\nSuch models empower agents with an “imagination”, they can simulate action consequences before execution, making decisions that align with long-term goals and environment dynamics.\n\nPrediction, not just perception, is at the heart of embodied AI.\n\n## 4. Gemini Robotics: Bridging Foundation Models and Physical Action\n\nDr. Carolina Parada’s keynote was a watershed moment. As the Director of Robotics at Google DeepMind, she unveiled how Gemini Robotics brings Google’s flagship multimodal model into the physical world.\n\n> “Gemini Robotics draws from Gemini’s world understanding and brings it to the physical world by adding actions as a new modality.”", "score": 0.6778372, "raw_content": null, "summary": "Gemini Robotics: Bridging Foundation Models and Physical ActionWhy Embodied AI is the Next Big BoomA Call to the Research Community: Prepare to Validate the FutureFinal ThoughtsWhat is next? > “In order to build truly helpful robots, we must ground our research in the physical world and validate our models through embodied interaction.” — Carolina Parada ## Final Thoughts CVPR 2025 clarified that"}, {"url": "https://cvpr.thecvf.com/Conferences/2025/News/AI_Enhanced_Robotics", "title": "Four Ways Computer Vision Is Driving AI-Enhanced Robotics", "content": "Skip to yearly menu bar\n\n## Main Navigation\n\n CVPR \n  + Code of Conduct  \n\n  + Create Profile  \n\n  + Reset / Forgot Password  \n\n  + Privacy Policy  \n\n  + Contact CVPR  \n\n  + HELP/FAQ\n Reset Password\n My Stuff\n\n Login\n\n### Four Ways Computer Vision Is Driving AI-Enhanced Robotics\n\nArtificial intelligence (AI)-enhanced robotics has emerged as a primary area of growth in the field of computer vision. As the IEEE CS 2025 Technology Predictions report explains: “Embodied intelligence will enable robots to perceive, learn, and collaborate in dynamic environments, achieving unprecedented autonomy and human-like adaptability.” Market research supports that sentiment: According to Statista, the AI robotics market size is expected to show an annual growth rate (CAGR 2025-2030) of 23.37%, resulting in a market volume of US$64.35bn by 2030. [...] While much work remains in the field of AI-enhanced robotics, just as much opportunity awaits. According to analysts, “The growing investment in research and development to enhance the capabilities of AI robotics is expected to propel market growth in the coming years.” From the implications in the industries ranging from healthcare and manufacturing to consumers and Smart Cities, the work in computer vision and pattern recognition today will have lasting influence on the future of robotics and its positive impact on humankind.\n\nFor more information on CVPR 2025, taking place 11-15 June in Nashville, Tenn., U.S., or to register, visit \n\nSuccessful Page Load [...] Developments with large language models (LLMs), multimodal AI, and broader computer vision efforts have been among the primary forces behind this rapid acceleration, and as the industry gears up for its leading AI engineering event, the Computer Vision and Pattern Recognition Conference (CVPR), paper submissions reiterate the role that AI-enhanced robotics will play.\n\n“A lot of people in computer vision are now interested in robotics,” said Phillip Isola, CVPR 2025 Program Co-Chair and an associate professor at the Massachusetts Institute of Technology (MIT) in Boston, Mass., U.S. “They're first starting by modeling 3D scenes, and that will be more relevant to robotics. For example, they might be working on navigation of a house, and there's no robot. But that's where they're going.”", "score": 0.6641271, "raw_content": null, "summary": "According to analysts, “The growing investment in research and development to enhance the capabilities of AI robotics is expected to propel market growth in the coming years.” From the implications in the industries ranging from healthcare and manufacturing to consumers and Smart Cities, the work in computer vision and pattern recognition today will have lasting influence on the future of robotics"}, {"url": "https://cvpr.thecvf.com/Conferences/2025/News/Wrap", "title": "CVPR 2025 Unveils the Latest Trends in Artificial Intelligence (AI ...", "content": "Harry Shum, former Executive Vice President of Microsoft Corporation and current Council Chairman of Hong Kong University of Science and Technology, Exploring the Low Altitude Airspace: From Natural Resource to Economic Engine (keynote video recording)\n Laurens van der Maaten, Distinguished Research Scientist at Meta AI, The Llama Herd of Models: System 1, 2, 3 Go!(keynote video recording)\n Carolina Parada, Senior Director and Head of Robotics at Google DeepMind, Gemini Robotics, Bringing AI to the Physical World (keynote video recording)\n\nExposition, Demo Award Winners, and Sponsors [...] About CVPR 2025\n\nThe Computer Vision and Pattern Recognition Conference (CVPR) is the preeminent computer vision event for new research in support of artificial intelligence (AI), machine learning (ML), augmented, virtual and mixed reality (AR/VR/MR), deep learning, and much more. Sponsored by the IEEE Computer Society (CS) and the Computer Vision Foundation (CVF), CVPR delivers the important advances in all areas of computer vision and pattern recognition and the various fields and industries they impact. With a first-in-class technical program, including tutorials and workshops, a leading-edge expo, and robust networking opportunities, CVPR, which is annually attended by more than 10,000 scientists and engineers, creates a one-of-a-kind opportunity for networking, recruiting, inspiration, and motivation. [...] “All of the papers accepted to CVPR help to advance the work of the community,” said Fuxin Li, CVPR 2025 Program Co-Chair, and an associate professor at Oregon State University in Corvallis, Ore., U.S. “It will be exciting to watch how research continues to unfold over the next year.”\n\nKeynotes\n\nProviding insights into significant topics for the industry, CVPR 2025 keynotes addressed how artificial intelligence (AI) can support the low-altitude economy; the next phase of AI; and the evolution of robotics with the support of more advanced AI. Specifically, the following presenters spoke to these themes in their talks:", "score": 0.6175132, "raw_content": null, "summary": "Harry Shum, former Executive Vice President of Microsoft Corporation and current Council Chairman of Hong Kong University of Science and Technology, Exploring the Low Altitude Airspace: From Natural Resource to Economic Engine (keynote video recording) Laurens van der Maaten, Distinguished Research Scientist at Meta AI, The Llama Herd of Models: System 1, 2, 3 Go!(keynote video recording) Carolina"}]}
{"query": "ICCV 2025 best papers (English)", "result": {"query": "ICCV 2025 best papers (English)", "follow_up_questions": null, "answer": null, "images": [], "results": [{"url": "https://www.linkedin.com/posts/lei-li-035479_iccv2025-iccvconference-on-x-activity-7387895881108180992-tKFe", "title": "#ICCV2025 (@ICCVConference) on X | Lei Li - LinkedIn", "content": "Carnegie Mellon University Robotics Institute\n\n6,951 followers\n\nTwo CMU teams won awards at the International Conference on Computer Vision (ICCV) being held in Hawaii this week! RI researchers collaborated with the Computer Science Department, Carnegie Mellon and the Department of Electrical and Computer Engineering at Carnegie Mellon University to bring some incredible work to the conference this year. #ICCV2025 👏 🏆 Best Paper Award (Marr Prize): \"Generating Physically Stable and Buildable Brick Structures from Text\" Ava P., Kangle Deng, Ruixuan Liu, Deva Ramanan, Changliu Liu, Jun-Yan Zhu  🗞️ News post:  🏅 Best Paper Honorable Mention: \"Spatially-Varying Autofocus\" Yingsi Qin, Aswin Sankaranarayanan, Matthew O’Toole Congratulations to all! #TartanProud [...] # Lei Li’s Post\n\nLei Li\n\n Report this post\n\nCongratulations to Changliu Liu Jun-Yan Zhu's team on winning the best paper award, and Aswin Sankaranarayanan Matthew O'Toole's team on winning the best paper honorable mention from ICCV 2025! This reminds me our earlier work on training robots to build physically stable bridges several years ago: \n\nCarnegie Mellon University Robotics Institute\n\n6,951 followers", "score": 0.9035075, "raw_content": null, "summary": "RI researchers collaborated with the Computer Science Department, Carnegie Mellon and the Department of Electrical and Computer Engineering at Carnegie Mellon University to bring some incredible work to the conference this year. #TartanProud [...] # Lei Li’s Post Lei Li Report this post Congratulations to Changliu Liu Jun-Yan Zhu's team on winning the best paper award, and Aswin Sankaranarayanan M"}, {"url": "https://iccv.thecvf.com/virtual/2025/awards_detail", "title": "ICCV 2025 Awards - The Computer Vision Foundation", "content": "| Highlight | Noise-Modeled Diffusion Models for Low-Light Spike Image Restoration  Poster  Ruonan Liu · Lin Zhu · Xijie Xiang · Lizhi Wang · Hua Huang  [ Exhibit Hall I ]  Abstract Spike-based imaging, inspired by the human visual system, offers several advantages, including high temporal resolution and low power consumption, but suffers from significant image degradation in low-light conditions due to noise interference. Restoring spike images under such conditions poses a significant challenge, as traditional frame-based or spike-based techniques are ill-suited to handle such severe noise and unique noise characteristics. This paper proposes a novel approach for restoring low-light spike images using noise-modeled diffusion models. By establishing a noise-embedded spike imaging model under low light, we model the forward diffusion process as the degradation of spike images with proportional and residual terms and incorporate determinstic and non-determinstic components with reverse shifting, enabling the model to capture the distinctive spike noise structure. [...] | Highlight | SRefiner: Soft-Braid Attention for Multi-Agent Trajectory Refinement  Poster  Liwen Xiao · Zhiyu Pan · Zhicheng Wang · Zhiguo Cao · Wei Li  [ Exhibit Hall I ]  Abstract Accurate prediction of multi-agent future trajectories is crucial for autonomous driving systems to make safe and efficient decisions. Trajectory refinement has emerged as a key strategy to enhance prediction accuracy. However, existing refinement methods often overlook the topological relationships between trajectories, which are vital for improving prediction precision. Inspired by braid theory, we propose a novel trajectory refinement approach, Soft-Braid Refiner (SRefiner), guided by the soft-braid topological structure of trajectories using Soft-Braid Attention. Soft-Braid Attention captures spatio-temporal topological relationships between trajectories by considering both spatial proximity and vehicle motion states at ``soft intersection points\". Additionally, we extend this approach to model interactions between trajectories and lanes, further improving the prediction accuracy. [...] | Highlight | LBM: Latent Bridge Matching for Fast Image-to-Image Translation  Poster  Clément Chadebec · Onur Tasar · Sanjeev Sreetharan · Benjamin Aubin  [ Exhibit Hall I ]  Abstract In this paper, we introduce Latent Bridge Matching (LBM), a new, versatile and scalable method that relies on Bridge Matching in a latent space to achieve fast image-to-image translation. We show that the method can reach state-of-the-art results for various image-to-image tasks using only a single inference step. In addition to its efficiency, we also demonstrate the versatility of the method across different image translation tasks such as object removal, normal and depth estimation, and object relighting. We also derive a conditional framework of LBM and demonstrate its effectiveness by tackling the tasks of controllable image relighting and shadow generation. |", "score": 0.8497846, "raw_content": null, "summary": "By establishing a noise-embedded spike imaging model under low light, we model the forward diffusion process as the degradation of spike images with proportional and residual terms and incorporate determinstic and non-determinstic components with reverse shifting, enabling the model to capture the distinctive spike noise structure. [...] | Highlight | LBM: Latent Bridge Matching for Fast Image-to-"}, {"url": "https://ai.ucf.edu/two-best-paper-awards-at-iccv-2025-workshops/", "title": "Two Best Paper Awards at ICCV 2025 Workshops", "content": "Two Best Paper Awards at ICCV 2025 Workshops - Institute of Artificial Intelligence\n\nSkip to main content\n\n 2025.\n\nThis recognition highlights UCF’s continued excellence in advancing responsible and secure AI research. The winning work introduces an innovative framework that ensures safe image generation without compromising semantic integrity—addressing one of the most pressing challenges in generative AI.\n\nCongratulations to the research team for this outstanding achievement and for contributing to the development of trustworthy AI systems that balance creativity and safety.\n\nImage 1\n\n  \n\n“SciVideoBench: Benchmarking Scientific Video Reasoning in Large Multimodal Models” received the Best Paper Award (Benchmark Track)at the KnowledgeMR Workshop, ICCV 2025.", "score": 0.8488849, "raw_content": null, "summary": "The winning work introduces an innovative framework that ensures safe image generation without compromising semantic integrity—addressing one of the most pressing challenges in generative AI. Congratulations to the research team for this outstanding achievement and for contributing to the development of trustworthy AI systems that balance creativity and safety."}, {"url": "https://rsipvision.com/ICCV2025-Tuesday/", "title": "ICCV Daily 2025 - Tuesday - RSIP Vision", "content": "7 DAILY ICCV Tuesday Weirong Chen Nevertheless, the system’s ability to demonstrate dynamic bundle adjustment working at all marks a milestone. This breakthrough might go some way toward explaining why Back on Track is a Best Paper award candidate this year. When Weirong first heard the news, he was surprised and honored: “Personally, this was far beyond my expectations when I wrote the paper!” The recognition, he believes, reflects the enduring value of classical computer-vision ideas when paired with modern learning techniques. “Luckily, we found this point tracker through motion decoupling to bridge from bundle adjustment to the dynamic scenes,” he adds. “I just hope that it can bring some new insights to the community.” To learn more about Weirong’s work, visit Oral Session 2A: View Synthesis and Scene (Exhibit Hall III) this afternoon from 13:30 to 14:45 [Oral 4] and Poster Session 2 (Exhibit Hall [...] The challenge at the center of Weirong’s research is that real-world scenes rarely stand still. Traditional structure-from-motion and SLAM systems, which rely on bundle adjustment, assume a static world, and the classical epipolar geometry that underpins them depends on scene points remaining fixed. Once humans, cars, or animals enter the frame, the mathematics breaks down. Weirong Chen is a second-year PhD student at the Technical University of Munich, supervised by Daniel Cremers and cosupervised by Andrea Vedaldi from the University of Oxford. His paper uses modern learningbased techniques to address the problem of dynamic scene reconstruction from videos. In addition to being accepted for a coveted oral slot at ICCV 2025, it has been shortlisted as a candidate for a Best Paper Award. Ahead of his oral and poster presentations today, Weirong tells us more about his work. Back on Track: Bundle Adjustment for Dynamic Scene Reconstruction 4 DAILY ICCV Tuesday Oral & Award [...] 3 DAILY ICCV Tuesday Aloha ICCV! Chee-hoo! Welcome to Honolulu! We have reviewed for you some of the awesomest papers presented today at ICCV 2025, including two candidates for the Best Paper award. And choke of other great stuff for you to enjoy. I asked General Chair Hilde Kühne about her thoughts, as ICCV’s Main Program kicks off: Turn the page and have a great Hawaiian day! Ralph Anzarouth Editor, Computer Vision News Ralph’s photo above was taken in peaceful, lovely and brave Odessa, Ukraine. ICCV Daily Editor: Ralph Anzarouth Publisher & Copyright: Computer Vision News All rights reserved. Unauthorized reproduction is strictly forbidden. Our editorial choices are fully independent from IEEE, ICCV and the conference organizers. Editorial One Hawaiian proverb says, “Aʻohe hana nui ka aluʻia” — No task is too big when done together. I can’t think", "score": 0.8232293, "raw_content": null, "summary": "When Weirong first heard the news, he was surprised and honored: “Personally, this was far beyond my expectations when I wrote the paper!” The recognition, he believes, reflects the enduring value of classical computer-vision ideas when paired with modern learning techniques. “I just hope that it can bring some new insights to the community.” To learn more about Weirong’s work, visit Oral Session"}, {"url": "https://ai.ucf.edu/nineteen-papers-accepted-in-iccv-2025/", "title": "Nineteen Papers Accepted in ICCV 2025", "content": "date = {2025-10-19},  \n\npublisher = {IEEE/CVF International Conference on Computer Vision},  \n\nabstract = {Video generation using diffusion models has shown remarkable progress, yet it remains computationally expensive due to the repeated processing of redundant features across blocks and steps. To address this, we propose a novel adaptive feature reuse mechanism that dynamically identifies and caches the most informative features by focusing on foreground and caching more on background, significantly reducing computational overhead with less sacrificing video quality. By leveraging the step and block caching, our method achieves up to 1.8× speed up on HunyuanVideo while maintaining competitive performance on Vbench, PSNR, SSIM, FID and LPIPS. Extensive experiments demonstrate that our approach not only improves efficiency but also enhances the quality of generated videos. The proposed method is generalizable and can be integrated into existing diffusion transformer frameworks.},  \n\nkeywords = {},  \n\npubstate = {published}, [...] author = {Ekkasit Pinyoanuntapong and Muhammad Usama Saleem and Korrawe Karunratanakul and Pu Wang and Hongfei Xue and Chen Chen and chuan guo and Junli Cao and Jian Ren and Sergey Tulyakov},  \n\nurl = {  \n\n  \n\nyear  = {2025},  \n\ndate = {2025-10-19},  \n\npublisher = {IEEE/CVF International Conference on Computer Vision}, [...] author = {Yatian Pang and Bin Zhu and Bin Lin and Mingzhe Zheng and Francis Tay and Ser-Nam Lim and Harry Yang and Li Yuan},  \n\nurl = {  \n\n  \n\n  \n\n  \n\nyear  = {2025},  \n\ndate = {2025-10-19},  \n\npublisher = {IEEE/CVF International Conference on Computer Vision},", "score": 0.79958355, "raw_content": null, "summary": "To address this, we propose a novel adaptive feature reuse mechanism that dynamically identifies and caches the most informative features by focusing on foreground and caching more on background, significantly reducing computational overhead with less sacrificing video quality. The proposed method is generalizable and can be integrated into existing diffusion transformer frameworks.}, keywords = {"}], "response_time": 2.77, "request_id": "39ce0933-84c8-4600-8904-ffe4271f4947"}, "query_summary": "RI researchers collaborated with the Computer Science Department, Carnegie Mellon and the Department of Electrical and Computer Engineering at Carnegie Mellon University to bring some incredible work to the conference this year. #TartanProud [...] # Lei Li’s Post Lei Li Report this post Congratulations to Changliu Liu Jun-Yan Zhu's team on winning the best paper award, and Aswin Sankaranarayanan M By establishing a noise-embedded spike imaging model under low light, we model the forward diffusion process as the degradation of spike images with proportional and residual terms and incorporate de", "lang_pref": "en", "preferred_results": [{"url": "https://www.linkedin.com/posts/lei-li-035479_iccv2025-iccvconference-on-x-activity-7387895881108180992-tKFe", "title": "#ICCV2025 (@ICCVConference) on X | Lei Li - LinkedIn", "content": "Carnegie Mellon University Robotics Institute\n\n6,951 followers\n\nTwo CMU teams won awards at the International Conference on Computer Vision (ICCV) being held in Hawaii this week! RI researchers collaborated with the Computer Science Department, Carnegie Mellon and the Department of Electrical and Computer Engineering at Carnegie Mellon University to bring some incredible work to the conference this year. #ICCV2025 👏 🏆 Best Paper Award (Marr Prize): \"Generating Physically Stable and Buildable Brick Structures from Text\" Ava P., Kangle Deng, Ruixuan Liu, Deva Ramanan, Changliu Liu, Jun-Yan Zhu  🗞️ News post:  🏅 Best Paper Honorable Mention: \"Spatially-Varying Autofocus\" Yingsi Qin, Aswin Sankaranarayanan, Matthew O’Toole Congratulations to all! #TartanProud [...] # Lei Li’s Post\n\nLei Li\n\n Report this post\n\nCongratulations to Changliu Liu Jun-Yan Zhu's team on winning the best paper award, and Aswin Sankaranarayanan Matthew O'Toole's team on winning the best paper honorable mention from ICCV 2025! This reminds me our earlier work on training robots to build physically stable bridges several years ago: \n\nCarnegie Mellon University Robotics Institute\n\n6,951 followers", "score": 0.9035075, "raw_content": null, "summary": "RI researchers collaborated with the Computer Science Department, Carnegie Mellon and the Department of Electrical and Computer Engineering at Carnegie Mellon University to bring some incredible work to the conference this year. #TartanProud [...] # Lei Li’s Post Lei Li Report this post Congratulations to Changliu Liu Jun-Yan Zhu's team on winning the best paper award, and Aswin Sankaranarayanan M"}, {"url": "https://iccv.thecvf.com/virtual/2025/awards_detail", "title": "ICCV 2025 Awards - The Computer Vision Foundation", "content": "| Highlight | Noise-Modeled Diffusion Models for Low-Light Spike Image Restoration  Poster  Ruonan Liu · Lin Zhu · Xijie Xiang · Lizhi Wang · Hua Huang  [ Exhibit Hall I ]  Abstract Spike-based imaging, inspired by the human visual system, offers several advantages, including high temporal resolution and low power consumption, but suffers from significant image degradation in low-light conditions due to noise interference. Restoring spike images under such conditions poses a significant challenge, as traditional frame-based or spike-based techniques are ill-suited to handle such severe noise and unique noise characteristics. This paper proposes a novel approach for restoring low-light spike images using noise-modeled diffusion models. By establishing a noise-embedded spike imaging model under low light, we model the forward diffusion process as the degradation of spike images with proportional and residual terms and incorporate determinstic and non-determinstic components with reverse shifting, enabling the model to capture the distinctive spike noise structure. [...] | Highlight | SRefiner: Soft-Braid Attention for Multi-Agent Trajectory Refinement  Poster  Liwen Xiao · Zhiyu Pan · Zhicheng Wang · Zhiguo Cao · Wei Li  [ Exhibit Hall I ]  Abstract Accurate prediction of multi-agent future trajectories is crucial for autonomous driving systems to make safe and efficient decisions. Trajectory refinement has emerged as a key strategy to enhance prediction accuracy. However, existing refinement methods often overlook the topological relationships between trajectories, which are vital for improving prediction precision. Inspired by braid theory, we propose a novel trajectory refinement approach, Soft-Braid Refiner (SRefiner), guided by the soft-braid topological structure of trajectories using Soft-Braid Attention. Soft-Braid Attention captures spatio-temporal topological relationships between trajectories by considering both spatial proximity and vehicle motion states at ``soft intersection points\". Additionally, we extend this approach to model interactions between trajectories and lanes, further improving the prediction accuracy. [...] | Highlight | LBM: Latent Bridge Matching for Fast Image-to-Image Translation  Poster  Clément Chadebec · Onur Tasar · Sanjeev Sreetharan · Benjamin Aubin  [ Exhibit Hall I ]  Abstract In this paper, we introduce Latent Bridge Matching (LBM), a new, versatile and scalable method that relies on Bridge Matching in a latent space to achieve fast image-to-image translation. We show that the method can reach state-of-the-art results for various image-to-image tasks using only a single inference step. In addition to its efficiency, we also demonstrate the versatility of the method across different image translation tasks such as object removal, normal and depth estimation, and object relighting. We also derive a conditional framework of LBM and demonstrate its effectiveness by tackling the tasks of controllable image relighting and shadow generation. |", "score": 0.8497846, "raw_content": null, "summary": "By establishing a noise-embedded spike imaging model under low light, we model the forward diffusion process as the degradation of spike images with proportional and residual terms and incorporate determinstic and non-determinstic components with reverse shifting, enabling the model to capture the distinctive spike noise structure. [...] | Highlight | LBM: Latent Bridge Matching for Fast Image-to-"}, {"url": "https://ai.ucf.edu/two-best-paper-awards-at-iccv-2025-workshops/", "title": "Two Best Paper Awards at ICCV 2025 Workshops", "content": "Two Best Paper Awards at ICCV 2025 Workshops - Institute of Artificial Intelligence\n\nSkip to main content\n\n 2025.\n\nThis recognition highlights UCF’s continued excellence in advancing responsible and secure AI research. The winning work introduces an innovative framework that ensures safe image generation without compromising semantic integrity—addressing one of the most pressing challenges in generative AI.\n\nCongratulations to the research team for this outstanding achievement and for contributing to the development of trustworthy AI systems that balance creativity and safety.\n\nImage 1\n\n  \n\n“SciVideoBench: Benchmarking Scientific Video Reasoning in Large Multimodal Models” received the Best Paper Award (Benchmark Track)at the KnowledgeMR Workshop, ICCV 2025.", "score": 0.8488849, "raw_content": null, "summary": "The winning work introduces an innovative framework that ensures safe image generation without compromising semantic integrity—addressing one of the most pressing challenges in generative AI. Congratulations to the research team for this outstanding achievement and for contributing to the development of trustworthy AI systems that balance creativity and safety."}, {"url": "https://rsipvision.com/ICCV2025-Tuesday/", "title": "ICCV Daily 2025 - Tuesday - RSIP Vision", "content": "7 DAILY ICCV Tuesday Weirong Chen Nevertheless, the system’s ability to demonstrate dynamic bundle adjustment working at all marks a milestone. This breakthrough might go some way toward explaining why Back on Track is a Best Paper award candidate this year. When Weirong first heard the news, he was surprised and honored: “Personally, this was far beyond my expectations when I wrote the paper!” The recognition, he believes, reflects the enduring value of classical computer-vision ideas when paired with modern learning techniques. “Luckily, we found this point tracker through motion decoupling to bridge from bundle adjustment to the dynamic scenes,” he adds. “I just hope that it can bring some new insights to the community.” To learn more about Weirong’s work, visit Oral Session 2A: View Synthesis and Scene (Exhibit Hall III) this afternoon from 13:30 to 14:45 [Oral 4] and Poster Session 2 (Exhibit Hall [...] The challenge at the center of Weirong’s research is that real-world scenes rarely stand still. Traditional structure-from-motion and SLAM systems, which rely on bundle adjustment, assume a static world, and the classical epipolar geometry that underpins them depends on scene points remaining fixed. Once humans, cars, or animals enter the frame, the mathematics breaks down. Weirong Chen is a second-year PhD student at the Technical University of Munich, supervised by Daniel Cremers and cosupervised by Andrea Vedaldi from the University of Oxford. His paper uses modern learningbased techniques to address the problem of dynamic scene reconstruction from videos. In addition to being accepted for a coveted oral slot at ICCV 2025, it has been shortlisted as a candidate for a Best Paper Award. Ahead of his oral and poster presentations today, Weirong tells us more about his work. Back on Track: Bundle Adjustment for Dynamic Scene Reconstruction 4 DAILY ICCV Tuesday Oral & Award [...] 3 DAILY ICCV Tuesday Aloha ICCV! Chee-hoo! Welcome to Honolulu! We have reviewed for you some of the awesomest papers presented today at ICCV 2025, including two candidates for the Best Paper award. And choke of other great stuff for you to enjoy. I asked General Chair Hilde Kühne about her thoughts, as ICCV’s Main Program kicks off: Turn the page and have a great Hawaiian day! Ralph Anzarouth Editor, Computer Vision News Ralph’s photo above was taken in peaceful, lovely and brave Odessa, Ukraine. ICCV Daily Editor: Ralph Anzarouth Publisher & Copyright: Computer Vision News All rights reserved. Unauthorized reproduction is strictly forbidden. Our editorial choices are fully independent from IEEE, ICCV and the conference organizers. Editorial One Hawaiian proverb says, “Aʻohe hana nui ka aluʻia” — No task is too big when done together. I can’t think", "score": 0.8232293, "raw_content": null, "summary": "When Weirong first heard the news, he was surprised and honored: “Personally, this was far beyond my expectations when I wrote the paper!” The recognition, he believes, reflects the enduring value of classical computer-vision ideas when paired with modern learning techniques. “I just hope that it can bring some new insights to the community.” To learn more about Weirong’s work, visit Oral Session"}, {"url": "https://ai.ucf.edu/nineteen-papers-accepted-in-iccv-2025/", "title": "Nineteen Papers Accepted in ICCV 2025", "content": "date = {2025-10-19},  \n\npublisher = {IEEE/CVF International Conference on Computer Vision},  \n\nabstract = {Video generation using diffusion models has shown remarkable progress, yet it remains computationally expensive due to the repeated processing of redundant features across blocks and steps. To address this, we propose a novel adaptive feature reuse mechanism that dynamically identifies and caches the most informative features by focusing on foreground and caching more on background, significantly reducing computational overhead with less sacrificing video quality. By leveraging the step and block caching, our method achieves up to 1.8× speed up on HunyuanVideo while maintaining competitive performance on Vbench, PSNR, SSIM, FID and LPIPS. Extensive experiments demonstrate that our approach not only improves efficiency but also enhances the quality of generated videos. The proposed method is generalizable and can be integrated into existing diffusion transformer frameworks.},  \n\nkeywords = {},  \n\npubstate = {published}, [...] author = {Ekkasit Pinyoanuntapong and Muhammad Usama Saleem and Korrawe Karunratanakul and Pu Wang and Hongfei Xue and Chen Chen and chuan guo and Junli Cao and Jian Ren and Sergey Tulyakov},  \n\nurl = {  \n\n  \n\nyear  = {2025},  \n\ndate = {2025-10-19},  \n\npublisher = {IEEE/CVF International Conference on Computer Vision}, [...] author = {Yatian Pang and Bin Zhu and Bin Lin and Mingzhe Zheng and Francis Tay and Ser-Nam Lim and Harry Yang and Li Yuan},  \n\nurl = {  \n\n  \n\n  \n\n  \n\nyear  = {2025},  \n\ndate = {2025-10-19},  \n\npublisher = {IEEE/CVF International Conference on Computer Vision},", "score": 0.79958355, "raw_content": null, "summary": "To address this, we propose a novel adaptive feature reuse mechanism that dynamically identifies and caches the most informative features by focusing on foreground and caching more on background, significantly reducing computational overhead with less sacrificing video quality. The proposed method is generalizable and can be integrated into existing diffusion transformer frameworks.}, keywords = {"}]}
{"query": "ACL 2025 AI trends (English)", "result": {"query": "ACL 2025 AI trends (English)", "follow_up_questions": null, "answer": null, "images": [], "results": [{"url": "https://www.linkedin.com/posts/madisonvandoren_acl-2025-5-trends-shaping-the-future-of-activity-7366938222871904258-FdsY", "title": "ACL 2025: Trends for LLMs in 2026 AI Roadmap - LinkedIn", "content": "I just finished organising my thoughts on ACL 2025 so let's talk about LLM trends for your 2026 AI roadmap. Full breakdown + key papers:  1. Fairness & Multilingual Alignment Reward models perform best in English and struggle with non-English languages. Confidence estimation also drops outside English, highlighting real gaps in multilingual LLMs. 2. Multimodal Models Are Getting Smarter VLLMs are moving beyond simple captioning to multi-step reasoning and real-world tasks, like translating text in complex images. 3. Reasoning Needs Verification Chain-of-thought prompting improves reasoning but isn’t enough. Adaptive verification—lightweight checks plus selective deep reasoning—boosts accuracy without massive compute. 4. Efficiency Over Scale Bigger isn’t always better. MoE pruning, Bayesian distillation, and other efficiency techniques are making smaller models competitive and deployable. 5. Retrieval & Personalisation Filtering hallucinations in generated documents and persona-aware memory [...] Student at PIAIC\n\n  + Report this post\n\n  In 2025, Large Language Models (LLMs) have evolved to become more multimodal, handling text, images, and video with greater accuracy. Imagine an LLM as a versatile assistant that not only chats but also analyzes photos or creates videos from descriptions. Recent developments include real-time processing across modalities, as in OpenAI's GPT-4o, which responds to text, images, and audio instantly. Models like Grok from xAI and Llama from Meta are topping lists for efficiency in tasks such as personalized learning and global communication.' 2025 Key Trends: LLMs now support multimodal inputs (text, images, video) and are more context-aware and customizable. Top Models: Include OpenAI's GPT series, DeepSeek, Qwen, Grok, Llama, Claude, Mistral, and Gemini, leading in performance as of September 2025. [...] Retrieval & Personalisation Filtering hallucinations in generated documents and persona-aware memory for multi-session chat are making AI interactions more reliable and context-aware. ACL 2025 confirms that the next wave of LLMs will be smarter, more efficient, and increasingly capable in multilingual and multimodal contexts. #artificialintelligence #LLMs #multilingualAI #ACL2025 #computationallinguistics", "score": 0.89053273, "raw_content": null, "summary": "Retrieval & Personalisation Filtering hallucinations in generated documents and persona-aware memory [...] Student at PIAIC + Report this post In 2025, Large Language Models (LLMs) have evolved to become more multimodal, handling text, images, and video with greater accuracy. Models like Grok from xAI and Llama from Meta are topping lists for efficiency in tasks such as personalized learning and g"}, {"url": "https://www.appen.com/blog/acl-2025", "title": "ACL 2025: 5 Trends Shaping the Future of LLMs - Appen", "content": "Beyond the leaderboard.\n\nSee how real AI performance is measured\n\nResources\nBlog\n\n# ACL 2025: 5 Trends Shaping the Future of LLMs\n\nPublished on\n\nAugust 28, 2025\n\nAuthor\n\nAuthors\n\nMadison Van Doren\n\nAI Research & Strategy Manager\n\nAppen\n\nGeorge Krasovitsky\n\nSenior Linguistic Project Manager\n\nAppen\n\nShare\n\nEvery year, ACL (the Association for Computational Linguistics) offers a preview of where natural language processing (NLP) and large language models (LLMs) are headed in 2026. We observed several key themes that will directly influence how companies build, deploy, and evaluate AI systems.\n\nHere are the five trends we see coming out of this year’s conference and key papers to watch.\n\n## 1. Fairness and Bias Remain a Top Priority [...] ## What This Means for Industry\n\nACL 2025 shows where the field is headed:\n\n Bias evaluation is becoming more sophisticated, and mitigation will require targeted fine-tuning.\n Multimodality is maturing, but abstract reasoning and complex real-world use cases remain challenging.\n Verification techniques may become standard in enterprise AI to balance reliability and cost.\n Research increasingly focuses on making compact LLMs viable for production deployment.\n Smarter retrieval and personalization systems will unlock more natural human-AI interactions.\n\nFor our AI community, the takeaway is clear. We’ve set our sights on fair, efficient, and contextually aware systems.\n\nWith 25+ years of AI expertise, Appen is a trusted partner for model builders around the world. Speak with an expert to learn how we support the AI lifecycle from development to deployment and fine-tuning.\n\n## Related posts\n\nNo items found. [...] ## 4. Prioritising Efficiency Over Scale\n\nSince the release of DeepSeek in early 2025, the trend towards leaner models has continued to inspire innovation. Researchers are looking for ways to compress, prune, and distill LLMs without losing accuracy. This makes large-scale AI more deployable in enterprise settings.\n\nKey Takeaways:\n\n MoE (Mixture of Experts) pruning can reduce redundancy by grouping and removing overlapping experts.\n Bayesian distillation improves small LLMs’ performance by aligning them more closely with teacher models.\n Gains of 3–4% accuracy on small models make them far more competitive.\n\nPapers to explore:\n\n Diversifying the Expert Knowledge for Task-Agnostic Pruning in Sparse Mixture-of-Experts\n BayesKD: Bayesian Knowledge Distillation for Compact LLMs in Constrained Fine-tuning Scenarios\n\n## 5. Retrieval and Personalisation Are Getting Smarter", "score": 0.8820324, "raw_content": null, "summary": "See how real AI performance is measured Resources Blog # ACL 2025: 5 Trends Shaping the Future of LLMs Published on August 28, 2025 Author Authors Madison Van Doren AI Research & Strategy Manager Appen George Krasovitsky Senior Linguistic Project Manager Appen Share Every year, ACL (the Association for Computational Linguistics) offers a preview of where natural language processing (NLP) and large"}, {"url": "https://megagon.ai/acl-2025-highlights-direction-of-nlp-ai/", "title": "ACL 2025 Highlights: Direction of NLP & AI - Megagon Labs", "content": "With over 5,000 participants and more than 3,100 papers, ACL 2025 was a hub of ideas and innovation. In this post, researchers at Megagon Labs highlight noteworthy trends shaping the future of NLP and AI, including generalization, agentic planning, and LLM-based evaluation. A comprehensive report from the program chairs is available for readers seeking additional insights.\n\n## Generalization of NLP Models\n\nLuke Zettlemoyer’s keynote speech emphasized three crucial points: the significance of pre-training LLMs, the promise of tokenizer-free LLMs, and the potential of modular language models to improve flexibility and adaptability across domains. [...] # ACL 2025 Highlights: Direction of NLP & AI\n\nThe 63rd annual meeting of the Association for Computational Linguistics (ACL 2025) took place in Vienna, Austria, from July 27 to August 1, 2025, bringing together thousands of NLP researchers, practitioners, and industry leaders from around the world. As tradition, Megagon Labs was proud to sponsor this year’s conference, which featured generalization of NLP models as one of the central themes. Our researchers also actively participated in the conference, presenting their latest works – CypherBench and FactLens. [...] Additionally, a panel discussion emphasized the importance of generalization for ensuring that models remain robust, reliable, and fair when making predictions on data that differs from their training set. Strong generalization is especially critical for real-world applications, where models are expected to exhibit human-like adaptability. Just as humans naturally generalize from prior experience, AI systems should strive to achieve a similar level of flexibility and consistency.\n\n## Agents & Planning\n\nA significant portion of work presented at the conference emphasized the rise and utility of agentic NLP systems. Examples included LLM models that do more than generate text, as well as those that are capable of planning, reasoning, and collaborating across multiple steps.", "score": 0.8585411, "raw_content": null, "summary": "## Generalization of NLP Models Luke Zettlemoyer’s keynote speech emphasized three crucial points: the significance of pre-training LLMs, the promise of tokenizer-free LLMs, and the potential of modular language models to improve flexibility and adaptability across domains. [...] # ACL 2025 Highlights: Direction of NLP & AI The 63rd annual meeting of the Association for Computational Linguistics ("}, {"url": "https://msukhareva.substack.com/p/acl-2025-recap-trends-tensions-and", "title": "ACL 2025 Recap: Trends, Tensions, and Shifting Powers in NLP", "content": "# ACL 2025 Recap: Trends, Tensions, and Shifting Powers in NLP\n\n### From LLM saturation to China’s research rise, here’s what stood out in Vienna.\n\nMaria Sukhareva\n\nAug 05, 2025\n\n∙ Paid\n\nACL 2025 is the top conference in the area of LLMs, NLP, and state-of-the-art AI, primarily focused on language processing.\n\nThis year, ACL 2025 was held in Vienna and was the largest in history, with over 6,000 participants. This comes as no surprise given the current surge of interest in language models.\n\nACL conferences are fundamentally different from industrial conferences. They are not filled with pitches, and buzzwords like “agentic” are rarely heard — let alone terms like “AGI” or “Superintelligence,” for uttering which, solely to promote your research, you might be crucified on the spot. [...] This is a gathering of the world’s leading researchers who shape both the present and the future of natural language processing.\n\nIn this comprehensive recap, you’ll find:\n\n Key takeaways from tutorials, panels, and keynote speeches\n The triumph of Chinese researchers — what they brought to the table and why it matters\n Major trends: ethics, multilinguality, low-resource language challenges, and the struggle for factuality\n Highlights from the presidential address on where AI research is heading\n A curated summary of this year’s outstanding papers\n Plus: photos, paper links, and firsthand notes from the conference floor\n\nEven if you missed this years ACL - I hope that this recap will help you stay up-to-date\n\n### ACL Tutorials\n\nThe pre-conference day started with tutorials. One particularly practical session was titled “Human-AI Collaboration: How AIs Augment Human Teammates.” [...] Designing AI systems is not trivial. You need to consider many trade-offs — as highlighted in this excellent ACL tutorial.  \nOne key challenge is balancing human overreliance and underreliance on AI output. Explanations don’t always help — if they don’t support actual verification, they may increase blind trust instead of promoting caution.\n\nAnother interesting idea from the tutorial: treat questions to humans as a form of retrieval. The model should decide whether to search a database or ask the human.  \nBut that comes with a cost too — the more questions it asks, the higher the mental load on the user. So the system needs to handle this carefully.\n\nThe tutorial also explored the dimensions of autonomy in AI systems, emphasizing that one of the key design decisions is clearly defining where to place the system on the autonomy spectrum.", "score": 0.73505294, "raw_content": null, "summary": "In this comprehensive recap, you’ll find: Key takeaways from tutorials, panels, and keynote speeches The triumph of Chinese researchers — what they brought to the table and why it matters Major trends: ethics, multilinguality, low-resource language challenges, and the struggle for factuality Highlights from the presidential address on where AI research is heading A curated summary of this year’s o"}, {"url": "https://www.youtube.com/watch?v=NsbXEslX_To", "title": "Observations on the Technical Trends of Large Models at ACL 2025", "content": "# Observations on the Technical Trends of Large Models at ACL 2025\n## Chaspark\n688 subscribers\n2 likes\n\n### Description\n105 views\nPosted: 30 Jul 2025\nACL 2025 has arrived as scheduled! As a top-tier conference in the field of natural language processing, this academic feast brings together leading researchers and technical practitioners from around the globe to share the latest achievements and discuss future trends. To allow practitioners and enthusiasts to transcend geographical limitations and experience the core highlights of ACL 2025 at the first opportunity, Chaspark in collaboration with Machine Heart, is specially launching a live broadcast titled \"Observations on the Technical Trends of Large Models at ACL 2025,\" taking you directly to the heart of this academic extravaganza.\n\n### Transcript:", "score": 0.6180666, "raw_content": null, "summary": "As a top-tier conference in the field of natural language processing, this academic feast brings together leading researchers and technical practitioners from around the globe to share the latest achievements and discuss future trends. To allow practitioners and enthusiasts to transcend geographical limitations and experience the core highlights of ACL 2025 at the first opportunity, Chaspark in co"}], "response_time": 11.62, "request_id": "88bdb054-37cc-46bd-ba2d-07ab8e0990c4"}, "query_summary": "Models like Grok from xAI and Llama from Meta are topping lists for efficiency in tasks such as personalized learning and g See how real AI performance is measured Resources Blog # ACL 2025: 5 Trends Shaping the Future of LLMs Published on August 28, 2025 Author Authors Madison Van Doren AI Research & Strategy Manager Appen George Krasovitsky Senior Linguistic Project Manager Appen Share Every year, ACL (the Association for Computational Linguistics) offers a preview of where natural language processing (NLP) and large ## Generalization of NLP Models Luke Zettlemoyer’s keynote speech emphasize", "lang_pref": "en", "preferred_results": [{"url": "https://www.linkedin.com/posts/madisonvandoren_acl-2025-5-trends-shaping-the-future-of-activity-7366938222871904258-FdsY", "title": "ACL 2025: Trends for LLMs in 2026 AI Roadmap - LinkedIn", "content": "I just finished organising my thoughts on ACL 2025 so let's talk about LLM trends for your 2026 AI roadmap. Full breakdown + key papers:  1. Fairness & Multilingual Alignment Reward models perform best in English and struggle with non-English languages. Confidence estimation also drops outside English, highlighting real gaps in multilingual LLMs. 2. Multimodal Models Are Getting Smarter VLLMs are moving beyond simple captioning to multi-step reasoning and real-world tasks, like translating text in complex images. 3. Reasoning Needs Verification Chain-of-thought prompting improves reasoning but isn’t enough. Adaptive verification—lightweight checks plus selective deep reasoning—boosts accuracy without massive compute. 4. Efficiency Over Scale Bigger isn’t always better. MoE pruning, Bayesian distillation, and other efficiency techniques are making smaller models competitive and deployable. 5. Retrieval & Personalisation Filtering hallucinations in generated documents and persona-aware memory [...] Student at PIAIC\n\n  + Report this post\n\n  In 2025, Large Language Models (LLMs) have evolved to become more multimodal, handling text, images, and video with greater accuracy. Imagine an LLM as a versatile assistant that not only chats but also analyzes photos or creates videos from descriptions. Recent developments include real-time processing across modalities, as in OpenAI's GPT-4o, which responds to text, images, and audio instantly. Models like Grok from xAI and Llama from Meta are topping lists for efficiency in tasks such as personalized learning and global communication.' 2025 Key Trends: LLMs now support multimodal inputs (text, images, video) and are more context-aware and customizable. Top Models: Include OpenAI's GPT series, DeepSeek, Qwen, Grok, Llama, Claude, Mistral, and Gemini, leading in performance as of September 2025. [...] Retrieval & Personalisation Filtering hallucinations in generated documents and persona-aware memory for multi-session chat are making AI interactions more reliable and context-aware. ACL 2025 confirms that the next wave of LLMs will be smarter, more efficient, and increasingly capable in multilingual and multimodal contexts. #artificialintelligence #LLMs #multilingualAI #ACL2025 #computationallinguistics", "score": 0.89053273, "raw_content": null, "summary": "Retrieval & Personalisation Filtering hallucinations in generated documents and persona-aware memory [...] Student at PIAIC + Report this post In 2025, Large Language Models (LLMs) have evolved to become more multimodal, handling text, images, and video with greater accuracy. Models like Grok from xAI and Llama from Meta are topping lists for efficiency in tasks such as personalized learning and g"}, {"url": "https://www.appen.com/blog/acl-2025", "title": "ACL 2025: 5 Trends Shaping the Future of LLMs - Appen", "content": "Beyond the leaderboard.\n\nSee how real AI performance is measured\n\nResources\nBlog\n\n# ACL 2025: 5 Trends Shaping the Future of LLMs\n\nPublished on\n\nAugust 28, 2025\n\nAuthor\n\nAuthors\n\nMadison Van Doren\n\nAI Research & Strategy Manager\n\nAppen\n\nGeorge Krasovitsky\n\nSenior Linguistic Project Manager\n\nAppen\n\nShare\n\nEvery year, ACL (the Association for Computational Linguistics) offers a preview of where natural language processing (NLP) and large language models (LLMs) are headed in 2026. We observed several key themes that will directly influence how companies build, deploy, and evaluate AI systems.\n\nHere are the five trends we see coming out of this year’s conference and key papers to watch.\n\n## 1. Fairness and Bias Remain a Top Priority [...] ## What This Means for Industry\n\nACL 2025 shows where the field is headed:\n\n Bias evaluation is becoming more sophisticated, and mitigation will require targeted fine-tuning.\n Multimodality is maturing, but abstract reasoning and complex real-world use cases remain challenging.\n Verification techniques may become standard in enterprise AI to balance reliability and cost.\n Research increasingly focuses on making compact LLMs viable for production deployment.\n Smarter retrieval and personalization systems will unlock more natural human-AI interactions.\n\nFor our AI community, the takeaway is clear. We’ve set our sights on fair, efficient, and contextually aware systems.\n\nWith 25+ years of AI expertise, Appen is a trusted partner for model builders around the world. Speak with an expert to learn how we support the AI lifecycle from development to deployment and fine-tuning.\n\n## Related posts\n\nNo items found. [...] ## 4. Prioritising Efficiency Over Scale\n\nSince the release of DeepSeek in early 2025, the trend towards leaner models has continued to inspire innovation. Researchers are looking for ways to compress, prune, and distill LLMs without losing accuracy. This makes large-scale AI more deployable in enterprise settings.\n\nKey Takeaways:\n\n MoE (Mixture of Experts) pruning can reduce redundancy by grouping and removing overlapping experts.\n Bayesian distillation improves small LLMs’ performance by aligning them more closely with teacher models.\n Gains of 3–4% accuracy on small models make them far more competitive.\n\nPapers to explore:\n\n Diversifying the Expert Knowledge for Task-Agnostic Pruning in Sparse Mixture-of-Experts\n BayesKD: Bayesian Knowledge Distillation for Compact LLMs in Constrained Fine-tuning Scenarios\n\n## 5. Retrieval and Personalisation Are Getting Smarter", "score": 0.8820324, "raw_content": null, "summary": "See how real AI performance is measured Resources Blog # ACL 2025: 5 Trends Shaping the Future of LLMs Published on August 28, 2025 Author Authors Madison Van Doren AI Research & Strategy Manager Appen George Krasovitsky Senior Linguistic Project Manager Appen Share Every year, ACL (the Association for Computational Linguistics) offers a preview of where natural language processing (NLP) and large"}, {"url": "https://megagon.ai/acl-2025-highlights-direction-of-nlp-ai/", "title": "ACL 2025 Highlights: Direction of NLP & AI - Megagon Labs", "content": "With over 5,000 participants and more than 3,100 papers, ACL 2025 was a hub of ideas and innovation. In this post, researchers at Megagon Labs highlight noteworthy trends shaping the future of NLP and AI, including generalization, agentic planning, and LLM-based evaluation. A comprehensive report from the program chairs is available for readers seeking additional insights.\n\n## Generalization of NLP Models\n\nLuke Zettlemoyer’s keynote speech emphasized three crucial points: the significance of pre-training LLMs, the promise of tokenizer-free LLMs, and the potential of modular language models to improve flexibility and adaptability across domains. [...] # ACL 2025 Highlights: Direction of NLP & AI\n\nThe 63rd annual meeting of the Association for Computational Linguistics (ACL 2025) took place in Vienna, Austria, from July 27 to August 1, 2025, bringing together thousands of NLP researchers, practitioners, and industry leaders from around the world. As tradition, Megagon Labs was proud to sponsor this year’s conference, which featured generalization of NLP models as one of the central themes. Our researchers also actively participated in the conference, presenting their latest works – CypherBench and FactLens. [...] Additionally, a panel discussion emphasized the importance of generalization for ensuring that models remain robust, reliable, and fair when making predictions on data that differs from their training set. Strong generalization is especially critical for real-world applications, where models are expected to exhibit human-like adaptability. Just as humans naturally generalize from prior experience, AI systems should strive to achieve a similar level of flexibility and consistency.\n\n## Agents & Planning\n\nA significant portion of work presented at the conference emphasized the rise and utility of agentic NLP systems. Examples included LLM models that do more than generate text, as well as those that are capable of planning, reasoning, and collaborating across multiple steps.", "score": 0.8585411, "raw_content": null, "summary": "## Generalization of NLP Models Luke Zettlemoyer’s keynote speech emphasized three crucial points: the significance of pre-training LLMs, the promise of tokenizer-free LLMs, and the potential of modular language models to improve flexibility and adaptability across domains. [...] # ACL 2025 Highlights: Direction of NLP & AI The 63rd annual meeting of the Association for Computational Linguistics ("}, {"url": "https://msukhareva.substack.com/p/acl-2025-recap-trends-tensions-and", "title": "ACL 2025 Recap: Trends, Tensions, and Shifting Powers in NLP", "content": "# ACL 2025 Recap: Trends, Tensions, and Shifting Powers in NLP\n\n### From LLM saturation to China’s research rise, here’s what stood out in Vienna.\n\nMaria Sukhareva\n\nAug 05, 2025\n\n∙ Paid\n\nACL 2025 is the top conference in the area of LLMs, NLP, and state-of-the-art AI, primarily focused on language processing.\n\nThis year, ACL 2025 was held in Vienna and was the largest in history, with over 6,000 participants. This comes as no surprise given the current surge of interest in language models.\n\nACL conferences are fundamentally different from industrial conferences. They are not filled with pitches, and buzzwords like “agentic” are rarely heard — let alone terms like “AGI” or “Superintelligence,” for uttering which, solely to promote your research, you might be crucified on the spot. [...] This is a gathering of the world’s leading researchers who shape both the present and the future of natural language processing.\n\nIn this comprehensive recap, you’ll find:\n\n Key takeaways from tutorials, panels, and keynote speeches\n The triumph of Chinese researchers — what they brought to the table and why it matters\n Major trends: ethics, multilinguality, low-resource language challenges, and the struggle for factuality\n Highlights from the presidential address on where AI research is heading\n A curated summary of this year’s outstanding papers\n Plus: photos, paper links, and firsthand notes from the conference floor\n\nEven if you missed this years ACL - I hope that this recap will help you stay up-to-date\n\n### ACL Tutorials\n\nThe pre-conference day started with tutorials. One particularly practical session was titled “Human-AI Collaboration: How AIs Augment Human Teammates.” [...] Designing AI systems is not trivial. You need to consider many trade-offs — as highlighted in this excellent ACL tutorial.  \nOne key challenge is balancing human overreliance and underreliance on AI output. Explanations don’t always help — if they don’t support actual verification, they may increase blind trust instead of promoting caution.\n\nAnother interesting idea from the tutorial: treat questions to humans as a form of retrieval. The model should decide whether to search a database or ask the human.  \nBut that comes with a cost too — the more questions it asks, the higher the mental load on the user. So the system needs to handle this carefully.\n\nThe tutorial also explored the dimensions of autonomy in AI systems, emphasizing that one of the key design decisions is clearly defining where to place the system on the autonomy spectrum.", "score": 0.73505294, "raw_content": null, "summary": "In this comprehensive recap, you’ll find: Key takeaways from tutorials, panels, and keynote speeches The triumph of Chinese researchers — what they brought to the table and why it matters Major trends: ethics, multilinguality, low-resource language challenges, and the struggle for factuality Highlights from the presidential address on where AI research is heading A curated summary of this year’s o"}, {"url": "https://www.youtube.com/watch?v=NsbXEslX_To", "title": "Observations on the Technical Trends of Large Models at ACL 2025", "content": "# Observations on the Technical Trends of Large Models at ACL 2025\n## Chaspark\n688 subscribers\n2 likes\n\n### Description\n105 views\nPosted: 30 Jul 2025\nACL 2025 has arrived as scheduled! As a top-tier conference in the field of natural language processing, this academic feast brings together leading researchers and technical practitioners from around the globe to share the latest achievements and discuss future trends. To allow practitioners and enthusiasts to transcend geographical limitations and experience the core highlights of ACL 2025 at the first opportunity, Chaspark in collaboration with Machine Heart, is specially launching a live broadcast titled \"Observations on the Technical Trends of Large Models at ACL 2025,\" taking you directly to the heart of this academic extravaganza.\n\n### Transcript:", "score": 0.6180666, "raw_content": null, "summary": "As a top-tier conference in the field of natural language processing, this academic feast brings together leading researchers and technical practitioners from around the globe to share the latest achievements and discuss future trends. To allow practitioners and enthusiasts to transcend geographical limitations and experience the core highlights of ACL 2025 at the first opportunity, Chaspark in co"}]}
{"query": "AAAI 2025 AI trends (English)", "result": {"query": "AAAI 2025 AI trends (English)", "follow_up_questions": null, "answer": null, "images": [], "results": [{"url": "https://www.linkedin.com/posts/erichorvitz_aaai-2025-presidential-panel-on-the-future-activity-7301621723395670016-yZda", "title": "AAAI 2025 Panel Report on Future of AI Research - LinkedIn", "content": "and development. Europe follows closely, with the United Kingdom and Germany at the forefront. These countries prioritize AI integration in healthcare. Asia Pacific is emerging as a significant player. China and India spearhead this growth, leveraging large populations and increasing healthcare needs. Latin America and the Middle East are gradually adopting AI in drug discovery. Brazil leads in Latin America, focusing on improving healthcare outcomes. The future of medicine lies at the intersection of data and discovery, and AI is at the very core of this transformation. #AIinDrugDiscovery#ArtificialIntelligence#DrugDiscovery#PharmaInnovation#HealthcareAI#LifeSciences#MachineLearning#DeepLearning#DrugDevelopment#Pharmaceuticals#Biotech#Bioinformatics#DigitalHealth#PrecisionMedicine#AIRevolution#MedicalResearch#HealthTech#ClinicalResearch [...] The #AI in #Drug#Discovery Market is projected to skyrocket from $1.8 billion in 2024 to an impressive $10.7 billion by 2034, growing at a CAGR of 18.3%. Artificial Intelligence is reshaping the way pharmaceutical companies discover, design, and develop drugs. Through advanced machine learning, deep learning, and natural language processing (NLP), AI systems can now analyze vast biological datasets, identify potential drug candidates, and even predict clinical outcomes with remarkable precision. 𝐆𝐞𝐨𝐠𝐫𝐚𝐩𝐡𝐢𝐜𝐚𝐥 𝐎𝐯𝐞𝐫𝐯𝐢𝐞𝐰 North America dominates the AI in Drug Discovery market. The United States leads, driven by substantial investments in research and development. Europe follows closely, with the United Kingdom and Germany at the [...] Bahasa Indonesia (Indonesian) \n        Italiano (Italian) \n        עברית (Hebrew) \n        日本語 (Japanese) \n        한국어 (Korean) \n        मराठी (Marathi) \n        Bahasa Malaysia (Malay) \n        Nederlands (Dutch) \n        Norsk (Norwegian) \n        ਪੰਜਾਬੀ (Punjabi) \n        Polski (Polish) \n        Português (Portuguese) \n        Română (Romanian) \n        Русский (Russian) \n        Svenska (Swedish) \n        తెలుగు (Telugu) \n        ภาษาไทย (Thai)", "score": 0.8312667, "raw_content": null, "summary": "The future of medicine lies at the intersection of data and discovery, and AI is at the very core of this transformation. #AIinDrugDiscovery#ArtificialIntelligence#DrugDiscovery#PharmaInnovation#HealthcareAI#LifeSciences#MachineLearning#DeepLearning#DrugDevelopment#Pharmaceuticals#Biotech#Bioinformatics#DigitalHealth#PrecisionMedicine#AIRevolution#MedicalResearch#HealthTech#ClinicalResearch [...]"}, {"url": "https://ojs.aaai.org/index.php/AAAI/issue/view/650", "title": "Vol. 39 No. 27: AAAI-25 Special Track on AI for Social Impact, Senior ...", "content": "Published by AAAI Press, Washington, DC, USA  \nCopyright © 2025, Association for the Advancement of Artificial Intelligence  \n601 Pennsylvania Ave, NW, Suite 900, Washington, DC 20004  \nAll Rights Reserved  \nISSN 2374-3468 (Online)   \nISSN 2159-5399 (Print)   \nISBN-10: 1-57735-897-X   \nISBN-13: 978-1-57735-897-8\n\nThe Thirty-Ninth AAAI Conference on Artificial Intelligence was held on February 25 – March 4, 2025, Philadelphia, Pennyslvania. The program chairs were Julie Shah (Massachusetts Institute of Technology, USA) and Zico Kolter (Carnegie Mellon University, USA). [...] The conference scope included machine learning, natural language processing, computer vision, data mining, multiagent systems, knowledge representation, human-in-the-loop AI, search, planning, reasoning, robotics and perception, and ethics. In addition to fundamental work that focused on any one of these areas, AAAI-25 encouraged work across technical areas of AI, (e.g., machine learning and computer vision; computer vision and natural language processing; or machine learning and planning), bridges between AI and a related research area (e.g., neuroscience; cognitive science) or developing AI techniques in the context of important application domains, such as healthcare, sustainability, transportation, and commerce. [...] AAAI Technical Track on AI for Social Impact Track   \nSenior Member Presentation: Blue Sky Papers   \nSenior Member Presentation: Bridge Sky Papers   \nSenior Member Presentation: Summary Sky Papers   \nNew Faculty Highlights   \nAAAI Journal Track\n\nPublished:   2025-04-11\n\n## AAAI Technical Track on AI for Social Impact Track\n\n ### Spatial Clustering of Citizen Science Data Improves Downstream Species Distribution Models\n\n  Nahian Ahmed, Mark Roth, Tyler A. Hallman, W. Douglas Robinson, Rebecca A. Hutchinson\n\n  + PDF\n ### Generalizable Disaster Damage Assessment via Change Detection with Vision Foundation Model\n\n  Kyeongjin Ahn, Sungwon Han, Sungwon Park, Jihee Kim, Sangyoon Park, Meeyoung Cha\n\n  + PDF\n ### Dynamics-Based Feature Augmentation of Graph Neural Networks for Variant Emergence Prediction", "score": 0.82761955, "raw_content": null, "summary": "In addition to fundamental work that focused on any one of these areas, AAAI-25 encouraged work across technical areas of AI, (e.g., machine learning and computer vision; computer vision and natural language processing; or machine learning and planning), bridges between AI and a related research area (e.g., neuroscience; cognitive science) or developing AI techniques in the context of important ap"}, {"url": "https://www.oreateai.com/blog/navigating-the-future-key-trends-in-ai-research-for-2025/bd112171b45aba174987fe88fa8165f3", "title": "Navigating the Future: Key Trends in AI Research for 2025 - Oreate AI", "content": "Skip to content\n\nOreate AI Blog\n\nRead the latest guides, tips, and insights on smart Al writing and presentation generation!\n\nHomeContentNavigating the Future: Key Trends in AI Research for 2025\n\nContent\n\n# Navigating the Future: Key Trends in AI Research for 2025\n\noreateLeave a comment\n\nThe landscape of artificial intelligence is shifting at an unprecedented pace, and as we step into 2025, a new wave of research papers sheds light on this evolution. At the heart of these discussions lies a panel convened by AAAI that dives deep into critical themes shaping AI's trajectory.\n\nAI reasoning has long been a staple topic among researchers, but its relevance has surged recently due to advancements in capabilities and limitations. The concept of agentic AI—machines that can act autonomously—is being explored with renewed vigor. Researchers are not just theorizing; they’re grappling with real-world implications and applications. [...] Factuality and trustworthiness have emerged as paramount concerns. As AI systems become more integrated into our daily lives, ensuring their reliability is crucial. This includes developing benchmarks for evaluating performance—a challenge compounded by the rapid release of unreviewed papers flooding platforms like arXiv.\n\nMoreover, ethical considerations are no longer optional; they are central to every discussion about AI’s future. The emphasis on sustainable practices within AI development reflects growing awareness about technology's impact on society and the environment. We see initiatives aimed at harnessing AI for social good gaining momentum, pushing researchers to collaborate across disciplines—from psychology to economics—to address complex societal challenges.\n\nEmbodied AI represents another frontier where machines interact physically with their environments—think robots learning through experience rather than mere programming. This area holds promise not only for technological advancement but also raises questions about safety and ethics in human-robot interactions. [...] Hardware innovations play a pivotal role too; dedicated resources like GPUs allow researchers to push boundaries previously thought impossible while raising questions about accessibility between academia and corporate sectors.\n\nGeopolitical dynamics add another layer of complexity as nations vie for leadership in this space. The competition influences everything from funding opportunities to collaborative efforts across borders—underscoring the need for international cooperation amidst fierce rivalry.\n\nIn summary, navigating these multifaceted trends requires us all—researchers, policymakers, educators—to engage thoughtfully with both current findings and emerging technologies so we can shape an inclusive future powered by responsible innovation.\n\n### Leave a Reply Cancel reply\n\nLast Updated on 2025-12-18T09:43:42+00:00 by oreate", "score": 0.8215175, "raw_content": null, "summary": "HomeContentNavigating the Future: Key Trends in AI Research for 2025 Content # Navigating the Future: Key Trends in AI Research for 2025 oreateLeave a comment The landscape of artificial intelligence is shifting at an unprecedented pace, and as we step into 2025, a new wave of research papers sheds light on this evolution. We see initiatives aimed at harnessing AI for social good gaining momentum,"}, {"url": "https://aaai.org/wp-content/uploads/2025/03/AAAI-2025-PresPanel-Report-Digital-3.7.25.pdf", "title": "[PDF] AAAI 2025 Presidential panel on the Future of AI Research", "content": "An emerging trend is multi-agent architectures, which structure AI components into modular systems that improve transparency, adaptability, and ethical alignment. The focus on cooperative agents highlights a shift toward AI that prioritizes collaboration, negotiation, and shared decision-making. By applying modularity, encapsulation, and separation of concerns, these architectures enable scalable teamwork between autonomous agents and humans, making them ideal for hybrid AI applications requiring trust, explainability, and domain- specific expertise.\nResearch Challenges • Identify challenges and benefits of embedding GenAI-driven agents into MAS, focusing on enhancing collaboration without disrupting existing dynamics.\n• Investigate how LLM-powered agents can improve negotiation and decision-making in dynamic multi-agent environments while ensuring ethical alignment and safety.\n• Develop architectures that integrate LLM-driven agents while maintaining scalability, transparency, and computational efficiency in multi-agent settings. [...] The challenge now is to understand what multi-agent systems mean in the era of LLMs. The current direction of agentifying LLMs may lead to overly complex and unnecessary architectures and heavy computational costs, whereas adopting a multi-agent paradigm to the development and use of LLMs may offer a sustainable way to compose, diversify, and integrate approaches effectively. Even though distribution was one of the original drivers for the MAS field, this is still a largely unexplored direction under the current paradigm. Another trend nowadays is to recover ideas from classical cognitive architectures to add common sense skills to autonomous agents. [...] The textual responses highlight a broad spectrum of perspectives on integrating Large Language Models (LLMs) into multi-agent systems (MAS), with some advocating for hybrid approaches rather than relying solely on LLMs. Many respondents stressed the need for diverse AI architectures, emphasizing modular, multi-technology systems where LLMs play a role but do not dominate. Governance, coordination, and adaptability emerge as key advantages of MAS, while concerns include increased complexity, lack of theoretical guarantees, and high computational costs. Several responses criticize the overemphasis on LLMs, questioning whether they are truly essential or merely a current trend. Others highlight practical challenges such as grounding, alignment, and robust communication protocols, pointing out the need for new frameworks that integrate symbolic reasoning, structured governance, and scalable architectures. Overall, the discussion reflects a critical but open stance toward agentifying LLMs, suggesting that context, application domain, and technological diversity will shape their effectiveness in multi-agent environments.", "score": 0.8066246, "raw_content": null, "summary": "By applying modularity, encapsulation, and separation of concerns, these architectures enable scalable teamwork between autonomous agents and humans, making them ideal for hybrid AI applications requiring trust, explainability, and domain- specific expertise. The current direction of agentifying LLMs may lead to overly complex and unnecessary architectures and heavy computational costs, whereas ad"}, {"url": "https://www.linkedin.com/posts/association-for-the-advancement-of-artificial-intelligence-aaai-_aaai-2025-presidential-panel-on-the-future-activity-7302108642772701184-RyAL", "title": "AAAI 2025 report on AI research and future trends - LinkedIn", "content": "# AAAI 2025 report on AI research and future trends\n\nThis title was summarized by AI from the post below.\n\nAssociation for the Advancement of Artificial Intelligence (AAAI)\n\n16,261 followers\n\n Report this post\n\nThe AAAI 2025 presidential panel on the future of AI research aims to help all AI stakeholders navigate the recent significant transformations in AI capabilities, as well as AI research methodologies, environments, and communities. It includes 17 chapters, each covering one topic related to AI research, and sketching its history, current trends and open challenges. The study has been conducted by 25 AI researchers and supported by 15 additional contributors and 475 respondents to a community survey. Access the report here: \n\nAAAI 2025 Presidential Panel on the Future of AI Research - AAAI   \n\nLike   Comment\n\nTo view or add a comment, sign in\n\n## More Relevant Posts\n\n Massachusetts Artificial Intelligence Ecosystem by DAIMLAS [...] Ho hum, just another week in AI, right? 𝗪𝗿𝗼𝗻𝗴. Google DeepMind and Yale just unveiled something extraordinary — an AI model that didn’t just analyze data… it came up with a new scientific hypothesis on its own. Trained on massive single-cell datasets, the model was built to explain biology. But when asked how to make immune (“cold”) tumors visible (“hot”) to the immune system, it generated a completely new, biologically sound idea — one no human had proposed — and it held up in the lab. Let that sink in: They built it to understand biology. It ended up discovering new biology. AI isn’t just summarizing anymore. It’s starting to reason. To imagine. To innovate. This is where AI shifts from a “cognitive load reducer” to a scientific collaborator. We’re entering the age where AI doesn’t just help us think — it helps us discover. [...] Many thanks to all co-authors, collaborators, and media colleagues for bringing this work to life. #ArtificialIntelligence #MultimodalAI #NatureMachineIntelligence #UKOMAIN #DeploymentCentricAI #AlanTuringInstitute #UniversityOfSheffield", "score": 0.80625874, "raw_content": null, "summary": "Association for the Advancement of Artificial Intelligence (AAAI) 16,261 followers Report this post The AAAI 2025 presidential panel on the future of AI research aims to help all AI stakeholders navigate the recent significant transformations in AI capabilities, as well as AI research methodologies, environments, and communities. Access the report here: AAAI 2025 Presidential Panel on the Future o"}], "response_time": 1.95, "request_id": "d3c04e46-1121-4747-9f9f-b21e71b0d006"}, "query_summary": "The future of medicine lies at the intersection of data and discovery, and AI is at the very core of this transformation. #AIinDrugDiscovery#ArtificialIntelligence#DrugDiscovery#PharmaInnovation#HealthcareAI#LifeSciences#MachineLearning#DeepLearning#DrugDevelopment#Pharmaceuticals#Biotech#Bioinformatics#DigitalHealth#PrecisionMedicine#AIRevolution#MedicalResearch#HealthTech#ClinicalResearch [...] In addition to fundamental work that focused on any one of these areas, AAAI-25 encouraged work across technical areas of AI, (e.g., machine learning and computer vision; computer vision and natural l", "lang_pref": "en", "preferred_results": [{"url": "https://ojs.aaai.org/index.php/AAAI/issue/view/650", "title": "Vol. 39 No. 27: AAAI-25 Special Track on AI for Social Impact, Senior ...", "content": "Published by AAAI Press, Washington, DC, USA  \nCopyright © 2025, Association for the Advancement of Artificial Intelligence  \n601 Pennsylvania Ave, NW, Suite 900, Washington, DC 20004  \nAll Rights Reserved  \nISSN 2374-3468 (Online)   \nISSN 2159-5399 (Print)   \nISBN-10: 1-57735-897-X   \nISBN-13: 978-1-57735-897-8\n\nThe Thirty-Ninth AAAI Conference on Artificial Intelligence was held on February 25 – March 4, 2025, Philadelphia, Pennyslvania. The program chairs were Julie Shah (Massachusetts Institute of Technology, USA) and Zico Kolter (Carnegie Mellon University, USA). [...] The conference scope included machine learning, natural language processing, computer vision, data mining, multiagent systems, knowledge representation, human-in-the-loop AI, search, planning, reasoning, robotics and perception, and ethics. In addition to fundamental work that focused on any one of these areas, AAAI-25 encouraged work across technical areas of AI, (e.g., machine learning and computer vision; computer vision and natural language processing; or machine learning and planning), bridges between AI and a related research area (e.g., neuroscience; cognitive science) or developing AI techniques in the context of important application domains, such as healthcare, sustainability, transportation, and commerce. [...] AAAI Technical Track on AI for Social Impact Track   \nSenior Member Presentation: Blue Sky Papers   \nSenior Member Presentation: Bridge Sky Papers   \nSenior Member Presentation: Summary Sky Papers   \nNew Faculty Highlights   \nAAAI Journal Track\n\nPublished:   2025-04-11\n\n## AAAI Technical Track on AI for Social Impact Track\n\n ### Spatial Clustering of Citizen Science Data Improves Downstream Species Distribution Models\n\n  Nahian Ahmed, Mark Roth, Tyler A. Hallman, W. Douglas Robinson, Rebecca A. Hutchinson\n\n  + PDF\n ### Generalizable Disaster Damage Assessment via Change Detection with Vision Foundation Model\n\n  Kyeongjin Ahn, Sungwon Han, Sungwon Park, Jihee Kim, Sangyoon Park, Meeyoung Cha\n\n  + PDF\n ### Dynamics-Based Feature Augmentation of Graph Neural Networks for Variant Emergence Prediction", "score": 0.82761955, "raw_content": null, "summary": "In addition to fundamental work that focused on any one of these areas, AAAI-25 encouraged work across technical areas of AI, (e.g., machine learning and computer vision; computer vision and natural language processing; or machine learning and planning), bridges between AI and a related research area (e.g., neuroscience; cognitive science) or developing AI techniques in the context of important ap"}, {"url": "https://www.oreateai.com/blog/navigating-the-future-key-trends-in-ai-research-for-2025/bd112171b45aba174987fe88fa8165f3", "title": "Navigating the Future: Key Trends in AI Research for 2025 - Oreate AI", "content": "Skip to content\n\nOreate AI Blog\n\nRead the latest guides, tips, and insights on smart Al writing and presentation generation!\n\nHomeContentNavigating the Future: Key Trends in AI Research for 2025\n\nContent\n\n# Navigating the Future: Key Trends in AI Research for 2025\n\noreateLeave a comment\n\nThe landscape of artificial intelligence is shifting at an unprecedented pace, and as we step into 2025, a new wave of research papers sheds light on this evolution. At the heart of these discussions lies a panel convened by AAAI that dives deep into critical themes shaping AI's trajectory.\n\nAI reasoning has long been a staple topic among researchers, but its relevance has surged recently due to advancements in capabilities and limitations. The concept of agentic AI—machines that can act autonomously—is being explored with renewed vigor. Researchers are not just theorizing; they’re grappling with real-world implications and applications. [...] Factuality and trustworthiness have emerged as paramount concerns. As AI systems become more integrated into our daily lives, ensuring their reliability is crucial. This includes developing benchmarks for evaluating performance—a challenge compounded by the rapid release of unreviewed papers flooding platforms like arXiv.\n\nMoreover, ethical considerations are no longer optional; they are central to every discussion about AI’s future. The emphasis on sustainable practices within AI development reflects growing awareness about technology's impact on society and the environment. We see initiatives aimed at harnessing AI for social good gaining momentum, pushing researchers to collaborate across disciplines—from psychology to economics—to address complex societal challenges.\n\nEmbodied AI represents another frontier where machines interact physically with their environments—think robots learning through experience rather than mere programming. This area holds promise not only for technological advancement but also raises questions about safety and ethics in human-robot interactions. [...] Hardware innovations play a pivotal role too; dedicated resources like GPUs allow researchers to push boundaries previously thought impossible while raising questions about accessibility between academia and corporate sectors.\n\nGeopolitical dynamics add another layer of complexity as nations vie for leadership in this space. The competition influences everything from funding opportunities to collaborative efforts across borders—underscoring the need for international cooperation amidst fierce rivalry.\n\nIn summary, navigating these multifaceted trends requires us all—researchers, policymakers, educators—to engage thoughtfully with both current findings and emerging technologies so we can shape an inclusive future powered by responsible innovation.\n\n### Leave a Reply Cancel reply\n\nLast Updated on 2025-12-18T09:43:42+00:00 by oreate", "score": 0.8215175, "raw_content": null, "summary": "HomeContentNavigating the Future: Key Trends in AI Research for 2025 Content # Navigating the Future: Key Trends in AI Research for 2025 oreateLeave a comment The landscape of artificial intelligence is shifting at an unprecedented pace, and as we step into 2025, a new wave of research papers sheds light on this evolution. We see initiatives aimed at harnessing AI for social good gaining momentum,"}, {"url": "https://aaai.org/wp-content/uploads/2025/03/AAAI-2025-PresPanel-Report-Digital-3.7.25.pdf", "title": "[PDF] AAAI 2025 Presidential panel on the Future of AI Research", "content": "An emerging trend is multi-agent architectures, which structure AI components into modular systems that improve transparency, adaptability, and ethical alignment. The focus on cooperative agents highlights a shift toward AI that prioritizes collaboration, negotiation, and shared decision-making. By applying modularity, encapsulation, and separation of concerns, these architectures enable scalable teamwork between autonomous agents and humans, making them ideal for hybrid AI applications requiring trust, explainability, and domain- specific expertise.\nResearch Challenges • Identify challenges and benefits of embedding GenAI-driven agents into MAS, focusing on enhancing collaboration without disrupting existing dynamics.\n• Investigate how LLM-powered agents can improve negotiation and decision-making in dynamic multi-agent environments while ensuring ethical alignment and safety.\n• Develop architectures that integrate LLM-driven agents while maintaining scalability, transparency, and computational efficiency in multi-agent settings. [...] The challenge now is to understand what multi-agent systems mean in the era of LLMs. The current direction of agentifying LLMs may lead to overly complex and unnecessary architectures and heavy computational costs, whereas adopting a multi-agent paradigm to the development and use of LLMs may offer a sustainable way to compose, diversify, and integrate approaches effectively. Even though distribution was one of the original drivers for the MAS field, this is still a largely unexplored direction under the current paradigm. Another trend nowadays is to recover ideas from classical cognitive architectures to add common sense skills to autonomous agents. [...] The textual responses highlight a broad spectrum of perspectives on integrating Large Language Models (LLMs) into multi-agent systems (MAS), with some advocating for hybrid approaches rather than relying solely on LLMs. Many respondents stressed the need for diverse AI architectures, emphasizing modular, multi-technology systems where LLMs play a role but do not dominate. Governance, coordination, and adaptability emerge as key advantages of MAS, while concerns include increased complexity, lack of theoretical guarantees, and high computational costs. Several responses criticize the overemphasis on LLMs, questioning whether they are truly essential or merely a current trend. Others highlight practical challenges such as grounding, alignment, and robust communication protocols, pointing out the need for new frameworks that integrate symbolic reasoning, structured governance, and scalable architectures. Overall, the discussion reflects a critical but open stance toward agentifying LLMs, suggesting that context, application domain, and technological diversity will shape their effectiveness in multi-agent environments.", "score": 0.8066246, "raw_content": null, "summary": "By applying modularity, encapsulation, and separation of concerns, these architectures enable scalable teamwork between autonomous agents and humans, making them ideal for hybrid AI applications requiring trust, explainability, and domain- specific expertise. The current direction of agentifying LLMs may lead to overly complex and unnecessary architectures and heavy computational costs, whereas ad"}, {"url": "https://www.linkedin.com/posts/association-for-the-advancement-of-artificial-intelligence-aaai-_aaai-2025-presidential-panel-on-the-future-activity-7302108642772701184-RyAL", "title": "AAAI 2025 report on AI research and future trends - LinkedIn", "content": "# AAAI 2025 report on AI research and future trends\n\nThis title was summarized by AI from the post below.\n\nAssociation for the Advancement of Artificial Intelligence (AAAI)\n\n16,261 followers\n\n Report this post\n\nThe AAAI 2025 presidential panel on the future of AI research aims to help all AI stakeholders navigate the recent significant transformations in AI capabilities, as well as AI research methodologies, environments, and communities. It includes 17 chapters, each covering one topic related to AI research, and sketching its history, current trends and open challenges. The study has been conducted by 25 AI researchers and supported by 15 additional contributors and 475 respondents to a community survey. Access the report here: \n\nAAAI 2025 Presidential Panel on the Future of AI Research - AAAI   \n\nLike   Comment\n\nTo view or add a comment, sign in\n\n## More Relevant Posts\n\n Massachusetts Artificial Intelligence Ecosystem by DAIMLAS [...] Ho hum, just another week in AI, right? 𝗪𝗿𝗼𝗻𝗴. Google DeepMind and Yale just unveiled something extraordinary — an AI model that didn’t just analyze data… it came up with a new scientific hypothesis on its own. Trained on massive single-cell datasets, the model was built to explain biology. But when asked how to make immune (“cold”) tumors visible (“hot”) to the immune system, it generated a completely new, biologically sound idea — one no human had proposed — and it held up in the lab. Let that sink in: They built it to understand biology. It ended up discovering new biology. AI isn’t just summarizing anymore. It’s starting to reason. To imagine. To innovate. This is where AI shifts from a “cognitive load reducer” to a scientific collaborator. We’re entering the age where AI doesn’t just help us think — it helps us discover. [...] Many thanks to all co-authors, collaborators, and media colleagues for bringing this work to life. #ArtificialIntelligence #MultimodalAI #NatureMachineIntelligence #UKOMAIN #DeploymentCentricAI #AlanTuringInstitute #UniversityOfSheffield", "score": 0.80625874, "raw_content": null, "summary": "Association for the Advancement of Artificial Intelligence (AAAI) 16,261 followers Report this post The AAAI 2025 presidential panel on the future of AI research aims to help all AI stakeholders navigate the recent significant transformations in AI capabilities, as well as AI research methodologies, environments, and communities. Access the report here: AAAI 2025 Presidential Panel on the Future o"}, {"url": "https://www.linkedin.com/posts/erichorvitz_aaai-2025-presidential-panel-on-the-future-activity-7301621723395670016-yZda", "title": "AAAI 2025 Panel Report on Future of AI Research - LinkedIn", "content": "and development. Europe follows closely, with the United Kingdom and Germany at the forefront. These countries prioritize AI integration in healthcare. Asia Pacific is emerging as a significant player. China and India spearhead this growth, leveraging large populations and increasing healthcare needs. Latin America and the Middle East are gradually adopting AI in drug discovery. Brazil leads in Latin America, focusing on improving healthcare outcomes. The future of medicine lies at the intersection of data and discovery, and AI is at the very core of this transformation. #AIinDrugDiscovery#ArtificialIntelligence#DrugDiscovery#PharmaInnovation#HealthcareAI#LifeSciences#MachineLearning#DeepLearning#DrugDevelopment#Pharmaceuticals#Biotech#Bioinformatics#DigitalHealth#PrecisionMedicine#AIRevolution#MedicalResearch#HealthTech#ClinicalResearch [...] The #AI in #Drug#Discovery Market is projected to skyrocket from $1.8 billion in 2024 to an impressive $10.7 billion by 2034, growing at a CAGR of 18.3%. Artificial Intelligence is reshaping the way pharmaceutical companies discover, design, and develop drugs. Through advanced machine learning, deep learning, and natural language processing (NLP), AI systems can now analyze vast biological datasets, identify potential drug candidates, and even predict clinical outcomes with remarkable precision. 𝐆𝐞𝐨𝐠𝐫𝐚𝐩𝐡𝐢𝐜𝐚𝐥 𝐎𝐯𝐞𝐫𝐯𝐢𝐞𝐰 North America dominates the AI in Drug Discovery market. The United States leads, driven by substantial investments in research and development. Europe follows closely, with the United Kingdom and Germany at the [...] Bahasa Indonesia (Indonesian) \n        Italiano (Italian) \n        עברית (Hebrew) \n        日本語 (Japanese) \n        한국어 (Korean) \n        मराठी (Marathi) \n        Bahasa Malaysia (Malay) \n        Nederlands (Dutch) \n        Norsk (Norwegian) \n        ਪੰਜਾਬੀ (Punjabi) \n        Polski (Polish) \n        Português (Portuguese) \n        Română (Romanian) \n        Русский (Russian) \n        Svenska (Swedish) \n        తెలుగు (Telugu) \n        ภาษาไทย (Thai)", "score": 0.8312667, "raw_content": null, "summary": "The future of medicine lies at the intersection of data and discovery, and AI is at the very core of this transformation. #AIinDrugDiscovery#ArtificialIntelligence#DrugDiscovery#PharmaInnovation#HealthcareAI#LifeSciences#MachineLearning#DeepLearning#DrugDevelopment#Pharmaceuticals#Biotech#Bioinformatics#DigitalHealth#PrecisionMedicine#AIRevolution#MedicalResearch#HealthTech#ClinicalResearch [...]"}]}
